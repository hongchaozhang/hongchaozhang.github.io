
<!DOCTYPE HTML>

<html>

<head>
	<meta charset="utf-8">
	<title>CNN与图像识别 - Reading Space</title>
	<meta name="author" content="Zhang Hongchao">

	
	<meta name="description" content="CNN与图像识别 卷积神经网络用于图像识别的现状。
卷积与图像处理基础知识。
卷积神经网络每一层的可视化，了解神经网络内部的物理意义。
图像卷积滤波器与神经元和权重的关系。 卷积神经网络与图像识别背景 LeNet概述
ImageNet大规模图像识别挑战赛 卷积与图像处理 卷积的定义 &hellip;">
	

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

	<link href="/atom.xml" rel="alternate" title="Reading Space" type="application/atom+xml">
	
	<link rel="canonical" href="http://hongchaozhang.github.io/blog/2018/05/02/cnn-and-image-classification/">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="/stylesheets/font-awesome.min.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<link href='http://fonts.googleapis.com/css?family=Nunito:400,300,700' rel='stylesheet' type='text/css'>
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	
  
	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-62806905-2']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>


</head>


<body>
	<div class="container">
		<div class="left-col">
			<div class="intrude-less">
			<header id="header" class="inner"><div class="profilepic">
	
	<script src="/javascripts/md5.js"></script>
	<script type="text/javascript">
		$(function(){
			$('.profilepic').append("<img src='http://www.gravatar.com/avatar/" + MD5("") + "?s=160' alt='Profile Picture' style='width: 160px;' />");
		});
	</script>
	
</div>

<nav id="main-nav"><ul class="main">
    <li><a href="/">Blog</a></li>
    <li><a href="/blog/archives">Archives</a></li>
    <li><a href="#">About</a></li>
</ul>
</nav>
<nav id="sub-nav">
	<div class="social">
		
		
		
		
		
			<a class="github" href="https://github.com/hongchaozhang" title="GitHub">GitHub</a>
		
		
		
		
		
		
		
		
		
		
    	
    	
			<a class="rss" href="/atom.xml" title="RSS">RSS</a>
		
	</div>
</nav>



<section class="categories">
          <ul id="category_cloud" class="nav nav-list"><a href='/blog/categories/algorithm' style='font-size: 101.36363636363636%'>algorithm(1)</a> <a href='/blog/categories/android' style='font-size: 108.18181818181819%'>android(6)</a> <a href='/blog/categories/android-studio' style='font-size: 101.36363636363636%'>android studio(1)</a> <a href='/blog/categories/augmented-reality' style='font-size: 105.45454545454545%'>augmented reality(4)</a> <a href='/blog/categories/css' style='font-size: 101.36363636363636%'>css(1)</a> <a href='/blog/categories/design-pattern' style='font-size: 104.0909090909091%'>design pattern(3)</a> <a href='/blog/categories/html' style='font-size: 101.36363636363636%'>html(1)</a> <a href='/blog/categories/html-css' style='font-size: 101.36363636363636%'>html css(1)</a> <a href='/blog/categories/ios' style='font-size: 160.0%'>ios(44)</a> <a href='/blog/categories/java' style='font-size: 102.72727272727273%'>java(2)</a> <a href='/blog/categories/javascript' style='font-size: 102.72727272727273%'>javascript(2)</a> <a href='/blog/categories/machine-learning' style='font-size: 112.27272727272728%'>machine learning(9)</a> <a href='/blog/categories/map-tech' style='font-size: 104.0909090909091%'>map tech(3)</a> <a href='/blog/categories/mobile' style='font-size: 101.36363636363636%'>mobile(1)</a> <a href='/blog/categories/music' style='font-size: 109.54545454545455%'>music(7)</a> <a href='/blog/categories/nlp' style='font-size: 102.72727272727273%'>nlp(2)</a> <a href='/blog/categories/nlu' style='font-size: 102.72727272727273%'>nlu(2)</a> <a href='/blog/categories/node' style='font-size: 104.0909090909091%'>node(3)</a> <a href='/blog/categories/objective-c' style='font-size: 128.63636363636363%'>objective-c(21)</a> <a href='/blog/categories/philosophy' style='font-size: 102.72727272727273%'>philosophy(2)</a> <a href='/blog/categories/productivity' style='font-size: 130.0%'>productivity(22)</a> <a href='/blog/categories/python' style='font-size: 106.81818181818181%'>python(5)</a> <a href='/blog/categories/reading' style='font-size: 136.8181818181818%'>reading(27)</a> <a href='/blog/categories/swift' style='font-size: 108.18181818181819%'>swift(6)</a> <a href='/blog/categories/web' style='font-size: 106.81818181818181%'>web(5)</a> <a href='/blog/categories/wwdc' style='font-size: 102.72727272727273%'>wwdc(2)</a> <a href='/blog/categories/xcode' style='font-size: 110.9090909090909%'>xcode(8)</a> </ul>
      </section>


</header>				
			</div>
		</div>	
		<div class="mid-col">
			
				
			
			<div class="mid-col-container">
				<div id="content" class="inner"><article class="post" itemscope itemtype="http://schema.org/BlogPosting">
	<h1 class="title" itemprop="name">CNN与图像识别</h1>
	<div class="entry-content" itemprop="articleBody"><ol>
<li>卷积神经网络用于图像识别的现状。</li>
<li>卷积与图像处理基础知识。</li>
<li>卷积神经网络每一层的可视化，了解神经网络内部的物理意义。</li>
<li>图像卷积滤波器与神经元和权重的关系。</li>
</ol>


<!-- more -->


<p><br></p>

<!-- TOC -->


<ul>
<li><a href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E8%83%8C%E6%99%AF">卷积神经网络与图像识别背景</a>

<ul>
<li><a href="#lenet%E6%A6%82%E8%BF%B0">LeNet概述</a></li>
<li><a href="#imagenet%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E6%8C%91%E6%88%98%E8%B5%9B">ImageNet大规模图像识别挑战赛</a></li>
</ul>
</li>
<li><a href="#%E5%8D%B7%E7%A7%AF%E4%B8%8E%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86">卷积与图像处理</a>

<ul>
<li><a href="#%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%AE%9A%E4%B9%89">卷积的定义</a></li>
<li><a href="#%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF%E7%9A%84%E7%89%A9%E7%90%86%E6%84%8F%E4%B9%89">图像卷积的物理意义</a></li>
</ul>
</li>
<li><a href="#lenet%E8%AF%A6%E8%A7%A3">LeNet详解</a></li>
<li><a href="#%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E8%BF%87%E7%A8%8B%E5%8F%AF%E8%A7%86%E5%8C%96">手写数字识别过程可视化</a></li>
<li><a href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%A5%9E%E7%BB%8F%E5%85%83%E5%92%8C%E6%9D%83%E9%87%8D%E5%9C%A8%E5%93%AA%E9%87%8C">神经网络中的“神经元”和“权重”在哪里？</a></li>
</ul>


<!-- /TOC -->


<p><a id="markdown-卷积神经网络与图像识别背景" name="卷积神经网络与图像识别背景"></a></p>

<h2>卷积神经网络与图像识别背景</h2>

<p><a id="markdown-lenet概述" name="lenet概述"></a></p>

<h3>LeNet概述</h3>

<p>LeNet是最早用于深度学习了领域的卷积神经网络之一。Yann LeCun的这一杰作得名于他自1988年以来的系列成功迭代。彼时LeNet架构还主要被用于识别邮政编码等任务。LeNet的基本架构如下：</p>

<p><img src="/images/201805lenet.jpg" alt="lenet" /></p>

<p>近几年已经出现了很多建立在LeNet之上的新架构，但是基本概念还是来自于LeNet。</p>

<p>卷积神经网络始自1990年代起，我们已经认识了最早的LeNet，其他一些很有影响力的架构列举如下：</p>

<ul>
<li>1990s至2012：从90年代到2010年代早期，卷积神经网络都处于孵化阶段。随着数据量增大和计算能力提高，卷积神经网络能搞定的问题也越来越有意思了。</li>
<li>AlexNet(2012)：2012年，Alex Krizhevsky发布了AlexNet，是LeNet的更深、更宽版本，并且大比分赢得了当年的ImageNet大规模图像识别挑战赛(ILSVRC)。这是一次非常重要的大突破，现在普及的卷积神经网络应用都要感谢这一壮举。</li>
<li>ZF Net(2013)：2013年的ILSVRC赢家是Matthew Zeiler和Rob Fergus的卷积网络，被称作ZF Net，这是调整过架构超参数的AlexNet改进型。</li>
<li>GoogleNet(2014)：2014的ILSVRC胜者是来自Google的Szegedy et al.。其主要贡献是研发了Inception Module，它<strong>大幅减少了网络中的参数数量（四百万，相比AlexNet的六千万）</strong>。</li>
<li>VGGNet(2014)：当年的ILSVRC亚军是VGGNet，突出贡献是展示了网络的深度（层次数量）是良好表现的关键因素。</li>
<li>ResNet(2015)： Kaiming He研发的Residual Network是2015年的ILSVRC冠军，也代表了卷积神经网络的最高水平，同时还是实践的默认选择（2016年5月）。</li>
<li>DenseNet（2016年8月）： 由Gao Huang发表，Densely Connected Convolutional Network的每一层都直接与其他各层前向连接。DenseNet已经在五个高难度的物体识别基础集上，显式出非凡的进步。</li>
</ul>


<p><a id="markdown-imagenet大规模图像识别挑战赛" name="imagenet大规模图像识别挑战赛"></a></p>

<h3>ImageNet大规模图像识别挑战赛</h3>

<p>参考<a href="http://www.sohu.com/a/143751643_473283">一个时代的终结：ImageNet竞赛2017是最后一届，WebVision 竞赛或接</a>。</p>

<p>上面的变种卷积神经网络基本上都来自一项比赛（DenseNet除外）：<strong>ImageNet大规模图像识别挑战赛</strong>(ImageNet Large Scale Visual Recognition Competition，ILSVRC)。</p>

<p>ILSVRC是基于ImageNet图像库的一个图像识别比赛。ImageNet可以说是计算机视觉研究人员进行大规模物体识别和检测时，最先想到的视觉大数据来源。ImageNet 数据集最初由斯坦福大学李飞飞等人在CVPR 2009的一篇论文中推出，并被用于替代 PASCAL数据集（后者在数据规模和多样性上都不如 ImageNet）和LabelMe数据集（在标准化上不如ImageNet）。</p>

<p>ImageNet不但是计算机视觉发展的重要推动者，也是这一波深度学习热潮的关键驱动力之一。截至2016年，ImageNet中含有超过1500万由人手工注释的图片网址，也就是带标签的图片，标签说明了图片中的内容，超过2.2万个类别。</p>

<p>CVPR2017研讨会“超越ILSVRC”将宣布今年是 ImageNet 竞赛正式组织的最后一年，2016年ILSVRC 的图像识别错误率已经达到约2.9%，不仅远远超越人类（5.1%），今后再进行这类竞赛意义也不大了。这无疑标志着一个时代的结束，但也是新征程的开始：未来，计算机视觉的重点在图像理解，而作为ILSVRC替代者的候选人之一是苏黎世理工大学和谷歌等联合提出的 WebVision Challenge，也将于CVPR2017同期举办，内容侧重于学习和理解网络数据。</p>

<p>历届ILSVRC的作品，可以参考<a href="https://blog.csdn.net/kangroger/article/details/56522132">ILSVRC历届冠军论文笔记</a>，包含模型框架和识别率等。</p>

<p><a id="markdown-卷积与图像处理" name="卷积与图像处理"></a></p>

<h2>卷积与图像处理</h2>

<p><a id="markdown-卷积的定义" name="卷积的定义"></a></p>

<h3>卷积的定义</h3>

<p><img src="/images/201805convolution_definition.gif" alt="convolution definition demo" /></p>

<p>参考<a href="https://en.wikipedia.org/wiki/Convolution">Convolution</a>。</p>

<p><a id="markdown-图像卷积的物理意义" name="图像卷积的物理意义"></a></p>

<h3>图像卷积的物理意义</h3>

<p>卷积矩阵也叫“滤波器”、“核”或“特征探测器”。</p>

<p><img src="/images/201805kernel_convolution.jpg" alt="image convolution" /></p>

<p><img src="/images/201805image_convolution.jpg" alt="image convolutioon" /></p>

<p>参考<a href="https://en.wikipedia.org/wiki/Kernel_(image_processing">Kernel (image processing)</a>)。
￼</p>

<p><a id="markdown-lenet详解" name="lenet详解"></a></p>

<h2>LeNet详解</h2>

<p>参考<a href="http://cv-tricks.com/tensorflow-tutorial/training-convolutional-neural-network-for-image-classification/">Basics of Convolutional Neural network (CNN)</a>。</p>

<ol>
<li>Convolutional Layer</li>
<li>Pooling Layer</li>
<li>Fully Connected Layer</li>
<li>Understanding Training Process</li>
</ol>


<p><a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/">An Intuitive Explanation of Convolutional Neural Networks</a>的讲解也不错，中文版在<a href="https://blog.csdn.net/lcy7289786/article/details/68958111">这里</a>。</p>

<p><a id="markdown-手写数字识别过程可视化" name="手写数字识别过程可视化"></a></p>

<h2>手写数字识别过程可视化</h2>

<p><img src="/images/201805cnn_visualization.jpg" alt="cnn visualization" /></p>

<p>官方网站：
<a href="http://scs.ryerson.ca/~aharley/vis/">http://scs.ryerson.ca/~aharley/vis/</a></p>

<p>3D可视化：
<a href="http://scs.ryerson.ca/~aharley/vis/conv/">http://scs.ryerson.ca/~aharley/vis/conv/</a></p>

<p>2D可视化：
<a href="http://scs.ryerson.ca/~aharley/vis/conv/flat.html">http://scs.ryerson.ca/~aharley/vis/conv/flat.html</a></p>

<p>相关论文：
<a href="http://scs.ryerson.ca/~aharley/vis/harley_vis_isvc15.pdf">http://scs.ryerson.ca/~aharley/vis/harley_vis_isvc15.pdf</a></p>

<p><a id="markdown-神经网络中的神经元和权重在哪里" name="神经网络中的神经元和权重在哪里"></a></p>

<h2>神经网络中的“神经元”和“权重”在哪里？</h2>

<p><img src="/images/201805convolution_weights.jpg" alt="convolution and weights" /></p>

<p>各个卷机滤波器的里面的每个位置的值，即是我们需要训练的权重（卷积滤波器的尺寸是需要我们提前指定好的），每个像素对应于一个神经元。</p>

<p>其中神经网络的基本概念可以参考<a href="http://playground.tensorflow.org/">TensorFlow Playground</a>。</p>
</div>

</article>

	<div class="share">
	<div class="addthis_toolbox addthis_default_style ">
	
	
	
	<a class="addthis_counter addthis_pill_style"></a>
	</div>
  <script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#pubid="></script>
</div>


</div>
			</div>
			<footer id="footer" class="inner">Copyright &copy; 2021

    Zhang Hongchao


<!--Design credit: <a href="http://shashankmehta.in/archive/2012/greyshade.html">Shashank Mehta</a>--></footer>
		</div>
	</div>
	










</body>
</html>
