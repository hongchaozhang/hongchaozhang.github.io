<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Reading Space]]></title>
  <link href="http://hongchaozhang.github.io/atom.xml" rel="self"/>
  <link href="http://hongchaozhang.github.io/"/>
  <updated>2023-05-24T02:12:59+08:00</updated>
  <id>http://hongchaozhang.github.io/</id>
  <author>
    <name><![CDATA[Zhang Hongchao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[migrate Octopress to M1 MacBook]]></title>
    <link href="http://hongchaozhang.github.io/blog/2023/05/24/migrate-octopress-to-m1-macbook/"/>
    <updated>2023-05-24T01:49:19+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2023/05/24/migrate-octopress-to-m1-macbook</id>
    <content type="html"><![CDATA[<!-- more -->


<p>pygments.rb is not compatible with M1, so I have to migrate to Rouge.
- detail info in Notes</p>

<p>understand: ruby gem bundle rails require load
- link</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[精英日课-排序不等式]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/12/08/jingyingrike-paixubudengshi/"/>
    <updated>2022-12-08T21:27:01+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/12/08/jingyingrike-paixubudengshi</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>什么是排序不等式</h2>

<p>排序不等式：大数乘大数加上小数乘小数，大于大数乘小数加小数乘大数。</p>

<p>假设:</p>

<ul>
<li>x1>x2>x3>0</li>
<li>y1>y2>y3>0</li>
</ul>


<p>那么：</p>

<ul>
<li>x1*y1 + x2*y2 + x3*y3 > [其它排序乘积相加] > x1*y3 + x2*y2 + x3*y1</li>
</ul>


<p>它能告诉你<strong>效率</strong>和<strong>公平</strong>的本质关系，也正是因为这个不等式，效率和公平是矛盾的。</p>

<p>更关键的是，我们熟悉的那些不等式，比如什么“算数平均值大于几何平均值”、什么“柯西不等式”、什么“车比雪夫不等式”，都可以从排序不等式推导出来。</p>

<h2>排序不等式的应用</h2>

<p>世界上的很多配合不是加法、而是乘法关系。资源和人才往往不是一个加数，而是一个因子：把这个因子扩大一点点，整个这一块都能放大这么高的比例。所以：</p>

<ol>
<li>最好的资源应该用在最赚钱的地方，</li>
<li>最厉害的人员应该放在最关键的岗位，</li>
<li>最好的电影应该乘以最好的导演再乘以最好的演员、然后给最多的院线排期。</li>
</ol>


<p>这就是为什么好东西总爱扎堆，有志向的年轻人非得去大城市。这也是为什么会有马太效应，为什么人人都想跟最好的合作。这也是为什么市场总是让财富分布不平等。</p>

<h3>销售额</h3>

<p>比如你是某个决策者，你现在手里有个大项目，放在哪个地区都能提升当地的经济发展。那请问，你是把它放在经济发达地区呢，还是边远落后地区呢？</p>

<p>只要你关心的是全国经济总量的提升，你想通过这个项目创造更多的税收，你就应该坚决投发达地区。同样是提升1%，发达地区的乘数要大得多。谁都喜欢大数，但是大数最能让大数发挥作用。</p>

<h3>商店促销</h3>

<p>促销要放在周末人多的时候，而不是平时人少的时候。（前提是没有达到销量瓶颈，比如门店承受能力。）</p>

<h3>车间系统</h3>

<p>我们假设你们车间有两条生产线，每条生产线需要两个人先后动作，共同完成一件产品。现在你有四个工人，老张和老李的良品率都是95%，小张和小李的良品率都是75%。那请问，你应该把这四个人怎么分组呢？</p>

<p>直觉的分法，是让老张和小张一组，老李和小李一组，这样两个组的良品率是一样的，都是0.95×0.75=71%。你可能觉得这样分组还能让高手带一带低手，能起到骨干作用。我不知道那个高手“带动”低手的效应能有多大，但是我知道，排序不等式要求你让老张和老李一组，小张和小李一组。你的高手组良品率将是0.95×0.95=90%，低手良品率将是0.75×0.75=56%，而你的总良品率是两组的平均值，也就是73%——高于高低搭配分组的71%。</p>

<h2>排序不等式，是资源配置的“零阶道理”。</h2>

<p>排序不等式，是资源配置的“零阶道理”。</p>

<p>当然，世界是复杂的，事物的发展常常是非线性的，什么东西太多了都会发生边际效应递减。也许这个项目在发达地区的发展空间已经饱和了，也许那个地区暂时落后，以后的发展潜力大，也许大城市生活成本太高了，也许最优秀的导演不会重视你这个剧本，应该找最合适的。</p>

<p>但是，那些都是对零阶道理的一阶、或者高阶修正：零阶道理仍然是零阶道理。我们做决策必须首先考虑零阶道理，只有在证实了零阶道理在这里不行的情况下，我们才应该考虑那些修正。</p>

<h2>不适用排序不等式的场景</h2>

<h3>教育系统</h3>

<p>教育系统有重点大学、重点中学，同一个学校里还会有重点班，重点班的老师是全校最好的。这完全符合排序不等式，教育系统希望培养高水平人才。但是你注意到没有，在任何一个班级里，老师重点关注的，往往不是最好的学生。这是为啥呢？因为<strong>学习成绩有上限</strong>。</p>

<h3>福利系统</h3>

<p>还有一种系统，比如福利系统，则要求各个相加项的大小有一个下限。是，在贫困山区建设通讯基站效率不高，但是贫困山区需要通讯基站。福利系统解决的是<strong>公平问题</strong>。这种系统有时候会把最好的官员排到最贫困的地区去，并不指望他们创造什么效益，只是希望提高那些地区的下限。而既然是为了公平，那就必然牺牲了效率。</p>

<h3>安全系统</h3>

<p>安全系统也强调下限。只要是防守，我们最关心的一定是最薄弱的地方，要把最好的资源和人手放在那个地方。</p>

<h2>如何利用排序不等式</h2>

<p>个人只能做一个乘法因子，管理者要的却是相乘再相加。如果你是一个系统的运行者，你必须清楚判断这是一个不设限系统，还是一个有上限或者下限的系统。</p>

<p>公司在乎的是总收入，本质上是个不设限的系统。排序不等式告诉我们这样的系统应该狠抓“长板”，因为长板最能提高总量。有下限的系统最关心的是短板，而有上限的系统最希望每块板都差不多。</p>

<p>作为个体，如果你认为自己是个大数因子，那你最好不要呆在有上限的系统中。</p>

<p>教育系统搞搞数学竞赛什么的，也算是给好学生一个出路。</p>

<p><strong>搞平均符合直觉，但是违反数学。</strong></p>

<p>我们个人的生活和学习不也是这样的吗？直觉上你可能认为应该把每一件事都做好，每个学科都学好，其实不是。数学要求这是一个长板的世界：你应该把最好的精力、最多的时间用在最能体现你价值的项目上。</p>

<p>设重点、偏科、不均匀、走极端，这才是自然之道。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[精英日课-思维是平的]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/12/08/jingyingrike-siweishipingde/"/>
    <updated>2022-12-08T21:25:01+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/12/08/jingyingrike-siweishipingde</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>思维是平的</h2>

<h3>脑补</h3>

<p>不仅仅是策略、性格和意义，还有动机、信念、价值、情绪、立场、偏见等等，所有这些代表人的“深层内心世界”的东西，都是我们想象出来的，而且是要用的时候临时编造的。</p>

<p>人只能看到细节局部，你的整体感，根本就是个错觉。哲学家和心理学把这个叫做“全局错觉”。</p>

<p>明明每次看到的都是局部，为什么会有一个整体感呢？因为大脑在不停地做解读。请注意这个解读可不是提炼精髓、只做减法，而是要补充细节，要做加法，要脑补。</p>

<p>读小说的时候，主人翁的形象会在你的大脑中被制造出来。</p>

<p>让有过一段共同经历的两个人同时回忆当时的情况，细节必定对不上。不可能记住所有的细节，但是你<em>以为</em>你记住了那些细节——其实所有的叙述、所有的意义，都是大脑的即兴创作。
人是随时都在发现意义和编造理由，特别善于即兴表演、特别善于创造故事而不自知的戏剧天才。</p>

<p>你的大脑以为你知道老虎是什么样子，其实让你画一下你就露馅啦。当你想到老虎的时候，你的大脑现编的老虎形象让你以为你知道老虎的样子。就像你读小说的时候，主人公形象就是你想象出来的。</p>

<p>人脑一直都在做自动的、默默的、让你意识不到的创作。有些创作素材来自真实记忆和当前现场观察，有些素材是根据逻辑脑补的，有些素材纯粹是胡乱添加的，有些素材则是为了某个主题的需要。</p>

<h3>选择失明</h3>

<p>别人问你为什么做出一个选择的时候，你在现编理由。你不知道，你的选择已经被做实验的人改了。</p>

<p>现在我们想一想这个现象。本来你只是很随意地选择了一张女性照片、一个果酱口味、一只股票基金和一个政治观点。你选的时候没想太多，因为你并不在意这个。但是选了之后——事实上是别人调换了你的选项，是你<em>以为</em>你选了之后——你却变成了这个选择的坚定支持者。</p>

<p>你看这像不像量子力学里的“波函数坍缩”？电子的自旋本来是个叠加态，是向上也行、向下也行——因为实验观测，电子被逼表态之后，它就有了一个坚定的自旋。类似的还有政治立场，对女生是否有好感等。</p>

<p>有一首李健创作、王菲演唱的歌叫《传奇》，说——</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>只因为在人群中多看了你一眼
</span><span class='line'>再也没能忘掉你的容颜
</span><span class='line'>梦想着偶然能有一天再相见
</span><span class='line'>从此我开始孤单地思念
</span><span class='line'>……
</span><span class='line'>宁愿相信我们前世有约
</span><span class='line'>今生的爱情故事不会再改变
</span><span class='line'>……</span></code></pre></td></tr></table></div></figure>


<p>你看这整个不就是一个爱情波函数坍缩事件吗？</p>

<p><strong>了解了大脑的这个性质，我们必须对能引起波函数坍缩的东西多加小心。</strong></p>

<h3>承诺和一致</h3>

<p>罗伯特·西奥迪尼（RobertB.Cialdini）的名著《影响力》这本书里有个专门的说法，叫“承诺和一致（CommitmentandConsistency）”，人在心理上有一种「要与过去的所作所为保持一致的愿望」。</p>

<p>因为这个机制，你要想让人帮你一个大忙，一个好办法是先让他帮你一个小忙。最愿意帮助你的是已经帮助过你的人。</p>

<p>咱们中国人管这个叫“得寸进尺”，心理学家把它总结成了一个影响力技术，叫“一只脚已经在门里（Foot-in-the-doortechnique）”——如果你已经让人的一只脚进门了，你好意思不让他整个人进来吗？</p>

<p>有些流氓调戏女孩也是这个套路。一开始只是请吃顿饭，然后是我一直都梦想有个女生能陪我去网吧打游戏，你能满足我这个梦想吗？……流氓一步步升级，女孩一步步沦陷。</p>

<p>我们平时说的什么“来都来了”、“沉没成本”，其实也都是这个机制。西奥迪尼后来搞的什么“先发影响力”、心理学和行为经济学上的prime效应，用环境和细节默默影响一个人的心态，其实也是这个机制。</p>

<p>一切的一切，都是因为我们想要完成自己想象中的、那个甚至都不知道因何而起的故事。</p>

<h3>如何应用大脑坍缩</h3>

<p>大脑坍缩并不见得不好，可能大多数情况下这都是一件好事。正是因为我们有这个想象，我们才能一心一意地完成那些需要长期努力的项目，哪怕遭遇困难也能挺过去。正是因为各种想象的共同体，一群人才能好好合作。但是正如你前面所见，大脑坍缩有可能会给我们带来麻烦。</p>

<p>那么理解了这个大脑坍缩的机制，我们应该如何对待小事呢？我认为这个原则应该是“<strong>谨慎地开始，正面地影响，果断地结束</strong>”。</p>

<p><strong>如果你对一件事物本来没有强硬立场，那就不要轻易表态。</strong></p>

<p>请问你对全球变暖有什么看法？你没看法。你根本就没研究过，你表什么态站什么队？站队是可能要站到底的。领导都是最后一个表态的，而且最好在事情尘埃落定之前都不表态。</p>

<p><strong>别轻易让你的波函数坍缩</strong>。在事情比较微妙的时刻，可能每个人有不一样的解读。你要说这是冲突吧，也对；你要说不是吧，也真不算——这时候应该怎么办呢？你应该抢先给这件事定性，<strong>让波函数往对你有利的那个方向坍缩。</strong></p>

<p>好在这里面没有量子随机性。女朋友昨天好像有点不高兴，你也说不清到底是不是，这时候你要设法帮助她往高兴的剧情上解读。但是如果你的波函数已经坍缩了，别忘了这一切仅仅是你的想象！你完全可以退出这个故事，换一个新故事。</p>

<p>理解了思维是平的，我们要做的不是放弃想象，而是去寻找更好的想象。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[精英日课-伯克森悖论]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/12/08/jingyingrike-bokesenbeilun/"/>
    <updated>2022-12-08T21:20:29+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/12/08/jingyingrike-bokesenbeilun</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>什么是伯克森悖论</h2>

<p>先看几个常见的论点：</p>

<ol>
<li>长得帅的男人性格都很差</li>
<li>不善言辞恰恰是智商高的特征</li>
<li>流行的都没啥深度</li>
<li>漂亮的女生都不聪明</li>
<li>颜值高的演员都没演技</li>
<li>有特长的人必定有明显短板</li>
<li>家里条件好的大学生必定不用功</li>
</ol>


<p>伯克森悖论是说，哪怕上面这些人的经验都是真的，他们从经验中总结出来的结论，也很可能是错的。</p>

<p>伯克森悖论的常见形式，就是如果你对两个特性有一个总体的阈值要求——这两个特性哪怕没关系，甚至哪怕原本可能还是正相关——在你考察的那个范围内，也能让你感觉它们有负的相关性。</p>

<h2>伯克森悖论与幸存者偏差</h2>

<p>伯克森悖论和人们熟悉的“幸存者偏差”都属于“选择偏差”，出错的根本原因都是你统计的数据不够全面。在统计研究中，你稍不小心，就会犯伯克森悖论的错误。</p>

<p>有一个真实的例子是这样的。有人统计了因为出车祸而被送进医院急诊室的摩托车手，发现戴头盔的人所受的伤，反而比不戴头盔的人更重。</p>

<p>难道说因为戴头盔的人开车更大胆，所以更容易受重伤吗？不一定。事实是很多戴头盔的人因为头盔的保护，而只受了轻伤，根本就无需进急诊室。</p>

<p>你考察的其实是“身体受到的保护”和“身体受到的伤害”这两个因素——保护必须足够小，伤害必须足够大，才能让这个人进急诊室——这跟“长相+性格”是一个道理，所以你看到了不戴头盔和受重伤的假的负相关。</p>

<p>还有个二战飞机中弹位置统计的例子。</p>

<h2>伯克森悖论的应用</h2>

<p>了解了伯克森悖论，下一次再听说涉及到能力、人品、长相、运气的各种“负相关”论断，你都应该保持戒心。</p>

<p>生活中有很多这样的民间智慧，比如什么“寒门出贵子”，什么“为富不仁”，什么“仗义每从屠狗辈，负心多是读书人”，什么“杀人放火金腰带，修桥铺路无尸骸”，都十分可疑。</p>

<p>平庸的寒门子弟、遵纪守法的富人、没有英雄壮举的屠狗辈、忠诚的读书人和安享晚年的好心人，他们的新闻阈值太低，他们的事迹没有四海传扬。你必须把这些人都统计上，才能得出正确的结论。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[重学前端-通过window属性了解协议API]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/10/08/chongxueqianduan-tongguo-window-liaojie-protocol-api/"/>
    <updated>2022-10-08T17:18:04+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/10/08/chongxueqianduan-tongguo-window-liaojie-protocol-api</id>
    <content type="html"><![CDATA[<!-- more -->


<p>浏览器的API数目繁多，这一节课，我设计了一个实验，我们一起来给API分分类。</p>

<p>我们按照每个API所在的标准来分类。所以，我们用代码来反射浏览器环境中全局对象的属性，然后我们用JavaScript的filter方法来逐步过滤掉已知的属性。</p>

<p>接下来，我们整理API的方法如下：</p>

<ol>
<li>从Window的属性中，找到API名称；</li>
<li>查阅MDN或者Google，找到API所在的标准；</li>
<li>阅读标准，手工或者用代码整理出标准中包含的API；</li>
<li>用代码在Window的属性中过滤掉标准中涉及的API。</li>
<li>重复这个过程，我们可以找到所有的API对应的标准。</li>
</ol>


<p>原文点击<a href="http://hongchaozhang.github.io/assets/resources/37%E4%B8%A8%E6%B5%8F%E8%A7%88%E5%99%A8API%EF%BC%88%E5%B0%8F%E5%AE%9E%E9%AA%8C%EF%BC%89%EF%BC%9A%E5%8A%A8%E6%89%8B%E6%95%B4%E7%90%86%E5%85%A8%E9%83%A8API.html">这里</a>获取。</p>

<p>从原文整理出来的html文件点击<a href="http://hongchaozhang.github.io/assets/resources/traverseWindows.html">这里</a>获取。</p>

<p>关键js代码如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>function filterOut(names, props) {
</span><span class='line'>    let set = new Set();
</span><span class='line'>    props.forEach(o =&gt; set.add(o));
</span><span class='line'>    return names.filter(e =&gt; !set.has(e));
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>let names = Object.getOwnPropertyNames(window)
</span><span class='line'>console.log(names)
</span><span class='line'>
</span><span class='line'>// 过滤JavaScript 标准规定的属性
</span><span class='line'>let js = new Set();
</span><span class='line'>let objects = ["BigInt", "BigInt64Array", "BigUint64Array", "Infinity", "NaN", "undefined", "eval", "isFinite", "isNaN", "parseFloat", "parseInt", "decodeURI", "decodeURIComponent", "encodeURI", "encodeURIComponent", "Array", "Date", "RegExp", "Promise", "Proxy", "Map", "WeakMap", "Set", "WeakSet", "Function", "Boolean", "String", "Number", "Symbol", "Object", "Error", "EvalError", "RangeError", "ReferenceError", "SyntaxError", "TypeError", "URIError", "ArrayBuffer", "SharedArrayBuffer", "DataView", "Float32Array", "Float64Array", "Int8Array", "Int16Array", "Int32Array", "Uint8Array", "Uint16Array", "Uint32Array", "Uint8ClampedArray", "Atomics", "JSON", "Math", "Reflect", "escape", "unescape"];
</span><span class='line'>objects.forEach(o =&gt; js.add(o));
</span><span class='line'>names = names.filter(e =&gt; !js.has(e));
</span><span class='line'>console.log('\nnames after filtering JS Standard:')
</span><span class='line'>console.log(names)
</span><span class='line'>
</span><span class='line'>// 接下来我们看看已经讲过的 DOM 部分，DOM 部分包含了 document 属性和一系列的构造器，我们可以用 JavaScript 的 prototype 来过滤构造器。
</span><span class='line'>names = names.filter( e =&gt; {
</span><span class='line'>    try { 
</span><span class='line'>        return !(window[e].prototype instanceof Node)
</span><span class='line'>    } catch(err) {
</span><span class='line'>        return true;
</span><span class='line'>    }
</span><span class='line'>}).filter( e =&gt; e != "Node")
</span><span class='line'>console.log('\nnames after filtering DOM:')
</span><span class='line'>console.log(names)
</span><span class='line'>
</span><span class='line'>// 接下来我们要找到 Window 对象的定义，我们在下面链接中可以找到。https://html.spec.whatwg.org/#window 这里有一个 Window 接口，是使用 WebIDL 定义的，我们手工把其中的函数和属性整理出来
</span><span class='line'>let windowprops = new Set();
</span><span class='line'>objects = ["window", "self", "document", "name", "location", "history", "customElements", "locationbar", "menubar", " personalbar", "scrollbars", "statusbar", "toolbar", "status", "close", "closed", "stop", "focus", " blur", "frames", "length", "top", "opener", "parent", "frameElement", "open", "navigator", "applicationCache", "alert", "confirm", "prompt", "print", "postMessage", "console"];
</span><span class='line'>objects.forEach(o =&gt; windowprops.add(o));
</span><span class='line'>names = names.filter(e =&gt; !windowprops.has(e));
</span><span class='line'>console.log('\nnames after filtering WebIDL:')
</span><span class='line'>console.log(names)
</span><span class='line'>
</span><span class='line'>// 我们还要过滤掉所有的事件，也就是 on 开头的属性。
</span><span class='line'>names = names.filter( e =&gt; !e.match(/^on/))
</span><span class='line'>// webkit 前缀的私有属性我们也过滤掉：
</span><span class='line'>names = names.filter( e =&gt; !e.match(/^webkit/))
</span><span class='line'>// 除此之外，我们在 HTML 标准中还能找到所有的接口，这些我们也过滤掉：
</span><span class='line'>let interfaces = new Set();
</span><span class='line'>objects = ["ApplicationCache", "AudioTrack", "AudioTrackList", "BarProp", "BeforeUnloadEvent", "BroadcastChannel", "CanvasGradient", "CanvasPattern", "CanvasRenderingContext2D", "CloseEvent", "CustomElementRegistry", "DOMStringList", "DOMStringMap", "DataTransfer", "DataTransferItem", "DataTransferItemList", "DedicatedWorkerGlobalScope", "Document", "DragEvent", "ErrorEvent", "EventSource", "External", "FormDataEvent", "HTMLAllCollection", "HashChangeEvent", "History", "ImageBitmap", "ImageBitmapRenderingContext", "ImageData", "Location", "MediaError", "MessageChannel", "MessageEvent", "MessagePort", "MimeType", "MimeTypeArray", "Navigator", "OffscreenCanvas", "OffscreenCanvasRenderingContext2D", "PageTransitionEvent", "Path2D", "Plugin", "PluginArray", "PopStateEvent", "PromiseRejectionEvent", "RadioNodeList", "SharedWorker", "SharedWorkerGlobalScope", "Storage", "StorageEvent", "TextMetrics", "TextTrack", "TextTrackCue", "TextTrackCueList", "TextTrackList", "TimeRanges", "TrackEvent", "ValidityState", "VideoTrack", "VideoTrackList", "WebSocket", "Window", "Worker", "WorkerGlobalScope", "WorkerLocation", "WorkerNavigator"];
</span><span class='line'>objects.forEach(o =&gt; interfaces.add(o));
</span><span class='line'>names = names.filter(e =&gt; !interfaces.has(e));
</span><span class='line'>console.log('\nnames after filtering HTML:')
</span><span class='line'>console.log(names)
</span><span class='line'>
</span><span class='line'>// 过滤i18n api
</span><span class='line'>names = names.filter(e =&gt; e != "Intl")
</span><span class='line'>console.log(names)
</span><span class='line'>
</span><span class='line'>/* Streams 标准
</span><span class='line'>    接下来我看到的属性是： ByteLengthQueuingStrategy。
</span><span class='line'>    同样经过查阅，它来自 WHATWG 的 Streams 标准：
</span><span class='line'>    https://streams.spec.whatwg.org/#blqs-class
</span><span class='line'>*/
</span><span class='line'>names = filterOut(names, ["ReadableStream", "ReadableStreamDefaultReader", "ReadableStreamBYOBReader", "ReadableStreamDefaultController", "ReadableByteStreamController", "ReadableStreamBYOBRequest", "WritableStream", "WritableStreamDefaultWriter", "WritableStreamDefaultController", "TransformStream", "TransformStreamDefaultController", "ByteLengthQueuingStrategy", "CountQueuingStrategy"]);
</span><span class='line'>console.log(names)
</span><span class='line'>
</span><span class='line'>/*
</span><span class='line'>    接下来我看到的属性是：WebGLContext​Event。
</span><span class='line'>    显然，这个属性来自 WebGL 标准：
</span><span class='line'>    https://www.khronos.org/registry/webgl/specs/latest/1.0/#5.15
</span><span class='line'>*/
</span><span class='line'>names = filterOut(names, ["WebGLContextEvent","WebGLObject", "WebGLBuffer", "WebGLFramebuffer", "WebGLProgram", "WebGLRenderbuffer", "WebGLShader", "WebGLTexture", "WebGLUniformLocation", "WebGLActiveInfo", "WebGLShaderPrecisionFormat", "WebGLRenderingContext"]);
</span><span class='line'>console.log(names)
</span><span class='line'>
</span><span class='line'>/*
</span><span class='line'>    Web Audio API
</span><span class='line'>    下一个属性是 WaveShaperNode。这个属性名听起来就跟声音有关，这个属性来自 W3C 的 Web Audio API 标准。
</span><span class='line'>    我们来看一下标准：
</span><span class='line'>    https://www.w3.org/TR/webaudio/
</span><span class='line'>*/
</span><span class='line'>names = filterOut(names, ["AudioContext", "AudioNode", "AnalyserNode", "AudioBuffer", "AudioBufferSourceNode", "AudioDestinationNode", "AudioParam", "AudioListener", "AudioWorklet", "AudioWorkletGlobalScope", "AudioWorkletNode", "AudioWorkletProcessor", "BiquadFilterNode", "ChannelMergerNode", "ChannelSplitterNode", "ConstantSourceNode", "ConvolverNode", "DelayNode", "DynamicsCompressorNode", "GainNode", "IIRFilterNode", "MediaElementAudioSourceNode", "MediaStreamAudioSourceNode", "MediaStreamTrackAudioSourceNode", "MediaStreamAudioDestinationNode", "PannerNode", "PeriodicWave", "OscillatorNode", "StereoPannerNode", "WaveShaperNode", "ScriptProcessorNode", "AudioProcessingEvent"]);
</span><span class='line'>console.log(names)
</span><span class='line'>
</span><span class='line'>/*
</span><span class='line'>    Encoding 标准
</span><span class='line'>    在我的环境中，下一个属性是 TextDecoder，经过查阅得知，这个属性也来自一份 WHATWG 的标准，Encoding：
</span><span class='line'>    https://encoding.spec.whatwg.org/#dom-textencoder
</span><span class='line'>*/
</span><span class='line'>names = filterOut(names, ["TextDecoder", "TextEncoder", "TextDecoderStream", "TextEncoderStream"]);
</span><span class='line'>console.log(names)
</span><span class='line'>
</span><span class='line'>/*
</span><span class='line'>    Web Cryptography API
</span><span class='line'>    我们继续看下去，下一个属性是 SubtleCrypto，这个属性来自 Web Cryptography API，也是 W3C 的标准。
</span><span class='line'>    https://www.w3.org/TR/WebCryptoAPI/
</span><span class='line'>    这份标准中规定了三个 Class 和一个 Window 对象的扩展，给 Window 对象添加了一个属性 crypto。
</span><span class='line'>*/
</span><span class='line'>names = filterOut(names, ["CryptoKey", "SubtleCrypto", "Crypto", "crypto"]);
</span><span class='line'>console.log(names)
</span><span class='line'>
</span><span class='line'>/*
</span><span class='line'>    Media Source Extensions
</span><span class='line'>    下一个属性是 SourceBufferList，它来自于：
</span><span class='line'>    https://www.w3.org/TR/media-source/
</span><span class='line'>    这份标准中包含了三个接口，这份标准还扩展了一些接口，但是没有扩展 window。
</span><span class='line'>*/
</span><span class='line'>names = filterOut(names, ["MediaSource", "SourceBuffer", "SourceBufferList"]);
</span><span class='line'>console.log(names)</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[精英日课-期权思维]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/10/08/jingyingrike-qiquan/"/>
    <updated>2022-10-08T11:40:36+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/10/08/jingyingrike-qiquan</id>
    <content type="html"><![CDATA[<!-- more -->


<p>期货，英文option，你可以选，也可以不选，它是你的权利，不是义务。</p>

<p>可选项的重要性：安眠药放那心里就踏实，已经有一个大学录取你了再去参加高考就不会发挥失常。</p>

<p>期权是没有义务，但是它需要你花钱买：</p>

<ol>
<li>看涨期权call：未来某个时间点，你有权利以某一个价格买入。</li>
<li>看跌期权put：未来某个时间点，你有权利以某一个价格卖出。</li>
</ol>


<p>期权可以用来：</p>

<ol>
<li>投机，当杠杆用。做空</li>
<li>保险：对投资者，而不是投机者，期权其实是一个保险，是一个对冲风险的手段。

<ul>
<li>你可以一边持有一个股票，一边卖call</li>
</ul>
</li>
</ol>


<p>期权定价：</p>

<ol>
<li>股票当前价格</li>
<li>期权的到期时间</li>
<li>期权规定的股票的履约价格</li>
<li>固定的银行利率</li>
<li>股票的波动性：波动性越大，期权价格越高。因为你有权利挑好的，而没有义务负责坏的。

<ul>
<li>如果你有特权，你应该喜欢波动性，喜欢极端，喜欢两极分化。</li>
</ul>
</li>
</ol>


<p>其它：</p>

<ol>
<li>股票思维必须关注下限，考虑止损，而期权思维只关心上限。</li>
<li>自己开公司是股票思维，风险投资是期权思维。</li>
<li>奋斗是股票思维，演化（自然选择）是期权行为</li>
<li>结婚是股票思维，暧昧是期权思维</li>
<li>供给侧是股票思维，需求侧是期权思维</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[精英日课-问题分类]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/10/08/jingyingrike-kunnandewenti/"/>
    <updated>2022-10-08T11:38:23+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/10/08/jingyingrike-kunnandewenti</id>
    <content type="html"><![CDATA[<!-- more -->


<p>问题可以分三类：</p>

<ul>
<li>单纯问题</li>
<li>两难问题</li>
<li>棘手问题</li>
</ul>


<h3>单纯问题</h3>

<p>高考，有明确的答案，明确的方向和明确的敌人。这个世界最危险的事情，就是某些人认为一切问题都是单纯问题。</p>

<h3>两难问题</h3>

<p>必须在两个选择中做出取舍。</p>

<h3>棘手问题</h3>

<ol>
<li>没有明确定义</li>
<li>没有终极答案</li>
<li>没有对错</li>
<li>采取措施之后不会（立马）得到反馈</li>
<li>没有试错练习的地方</li>
<li>有什么选项都不知道</li>
<li>没有先例</li>
<li>这个问题可能只是表象，背后可能还有更多的问题</li>
<li>多个利益相关方</li>
<li>如果你上手，那么不论什么结果，你都要负责</li>
</ol>


<p>比如贫富差距、全球变暖等问题
当瑞典女中学生指责各国政府对全球变暖应对不力等时候，当围观群众笑话特朗普对时候，其实都有点站着说话不腰疼。
不是我们不够努力，也不是敌人太坏，而是这个问题太棘手。</p>

<p>怎么处理棘手问题？不能解决，只能应对，应该追求管理这个问题。就像我们应对癌细胞一样。</p>

<ol>
<li>利益相关方充分沟通，不求达成共识，但求互相理解，消除一些偏见。</li>
<li>公司决策相关的棘手问题，不妨想想公司的认同感和意义。</li>
<li>行动。摸着石头过河。每次一小步，边做边调整。就这么应对着，跟着问题一起演化。也许一段时间之后，它就被别的问题取代了。</li>
</ol>


<p>单纯的人总希望一劳永逸地解决一个问题。这种理想主义者一旦受挫，又会心灰意冷，成为一个愤世嫉俗的人。他以为别人都自私就他自己真想解决问题，可是他又解决不了问题。</p>

<p>殊不知，那些顶着骂名，从来没有做过一件快意事，小心翼翼不敢用力过猛，明知没有胜利的彼岸还在吭哧吭哧地维持着局面的人，才是真正值得尊敬的。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[精英日课-计算机不能做所有的事情]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/10/08/jingyingrike-jisuanjibunengzuodeshiqing/"/>
    <updated>2022-10-08T11:35:59+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/10/08/jingyingrike-jisuanjibunengzuodeshiqing</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>计算机不能做所有的事情</h2>

<ul>
<li>停机问题： 不存在这样一个程序（算法），它能够计算任何程序（算法）在给定输入上是否会结束（停机）。

<ul>
<li>理发师悖论</li>
<li>全能悖论</li>
<li>说谎者悖论</li>
</ul>
</li>
<li>Y conbinator</li>
<li>哥德尔不完备性定理，击碎了希尔伯特的美好愿景

<ul>
<li>这理论用在人工智能上，则指出有些道理可能是人类能够判别，但机器单纯用一阶公理化系统却无法得知的道理。不过机器可以用非一阶公理化系统，例如实验、经验。</li>
</ul>
</li>
<li>康托尔对角线定理</li>
</ul>


<p>哥德尔的不完备性定理震撼了20世纪数学界的天空，其数学意义颠覆了希尔伯特的形式化数学的宏伟计划，其哲学意义直到21世纪的今天仍然不断被延伸到各个自然学科，深刻影响着人们的思维。图灵为了解决希尔伯特著名的第十问题而提出有效计算模型，进而作出了可计算理论和现代计算机的奠基性工作，著名的停机问题给出了机械计算模型的能力极限，其深刻的意义和漂亮的证明使它成为可计算理论中的标志性定理之一。丘齐，跟图灵同时代的天才，则从另一个抽象角度提出了lambda算子的思想，与图灵机抽象的倾向于硬件性不同，丘齐的lambda算子理论是从数学的角度进行抽象，不关心运算的机械过程而只关心运算的抽象性质，只用最简洁的几条公理便建立起了与图灵机完全等价的计算模型，其体现出来的数学抽象美开出了函数式编程语言这朵奇葩，Lisp、Scheme、Haskell… 这些以抽象性和简洁美为特点的语言至今仍然活跃在计算机科学界，虽然由于其本质上源于lambda算子理论的抽象方式不符合人的思维习惯从而注定无法成为主流的编程语言[2]，然而这仍然无法妨碍它们成为编程理论乃至计算机学科的最佳教本。而诞生于函数式编程语言的神奇的Y combinator至今仍然让人们陷入深沉的震撼和反思当中…</p>

<p>参考：</p>

<ul>
<li><a href="https://www.infzm.com/contents/76948">【专栏】康托尔、哥德尔、图灵——永恒的金色对角线（1）</a></li>
<li>&hellip;</li>
<li><a href="https://www.infzm.com/contents/77590">【专栏】康托尔、哥德尔、图灵——永恒的金色对角线（13）</a></li>
</ul>


<p>用计算模拟真实世界，解释不了很多根本原因，但是不用解释。比如足球比赛，打仗胜败分析。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[精英日课-杂想]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/10/07/jingyingrike-zaxiang/"/>
    <updated>2022-10-07T23:38:46+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/10/07/jingyingrike-zaxiang</id>
    <content type="html"><![CDATA[<!-- more -->


<h3>基因与开关</h3>

<ol>
<li>基因决定生成什么蛋白，开关决定要不要生成这种蛋白。</li>
<li>基因先天决定，开关环境决定。</li>
<li>基因，基因表达，基因开关，环境影响基因表达，饥饿环境，穷人富人行为</li>
<li>蝌蚪出生时环境决定自己的行为</li>
<li>鸟宝宝</li>
</ol>


<h3>父母类型</h3>

<ul>
<li>权威型父母：高响应，严要求</li>
<li>专制型父母：低响应，严要求</li>
</ul>


<h3>搜索的喜悦</h3>

<ol>
<li>《搜索的喜悦》</li>
<li>google earth</li>
<li>谷歌搜索技巧1008</li>
<li>搜索引擎和淘宝，淘宝不暴露给搜索引擎。一些公司在特定领域瓜分搜索引擎的份额。</li>
</ol>


<h3>路径反噬与路径依赖</h3>

<ul>
<li>路径反噬0830</li>
<li>路径依赖，键盘布局，正反馈，蜜蜂</li>
</ul>


<h3>《模型思考者》</h3>

<ol>
<li>数据->信息->知识->智慧（主观会选模型，敢选模型）</li>
<li>内隐学习，外显学习</li>
<li>股票有效市场，人们的充分分析导致市场趋向于有效，有效市场中分析的作用降低，导致很少人分析，很少人分析导致市场趋向于无效，会有更多的人进行市场分析。</li>
</ol>


<h3>概率分布</h3>

<ol>
<li>什么条件满足正态分布？

<ul>
<li>多个独立随机变量相加</li>
</ul>
</li>
<li>对数正态分布

<ul>
<li>多个独立随机变量相乘</li>
</ul>
</li>
<li>幂律分布

<ul>
<li>更容易出现极端情况</li>
</ul>
</li>
</ol>


<h3>稳态</h3>

<ul>
<li>碗底的小球</li>
<li>急诊拥挤改善没用，因为拥挤是稳态：当改善场地不拥挤的时候，很多不着急的病人也会来看急诊，直到急诊拥挤。当急诊过于拥挤的时候，一些不那么着急的病人就不会来看急诊。</li>
<li>早晚高峰拥挤是稳态，道理和急诊一样。</li>
</ul>


<p>稳态和非稳态
* 稳态（负反馈）
  * 鸽派和鹰派的人口比例
  * 左右手人口比例
  * 重感情和重物质的人口比例
* 非稳态（正反馈）</p>

<h3>极简生活</h3>

<ul>
<li>极简生活，日本，有川真由美</li>
<li>极简生活是奢侈生活，选择多</li>
<li>你敢极简生活，是因为你随时可以不极简生活，有备选方案</li>
<li>有些人不敢极简生活，是因为万一出问题，自己没有其他选择</li>
<li>一个用钱规避风险，一个用物质的备份规避风险</li>
</ul>


<h3>女权主义过头啦</h3>

<p>0702</p>

<h3>5G+VR/AR/MR</h3>

<p>0628</p>

<ul>
<li><p>足球直播
以前的足球直播是摄像机视角，现在可以：</p>

<ol>
<li>360度视角</li>
<li>足球视角：跟着足球走</li>
<li>明星视角：跟着某个明星走</li>
<li>裁判视角：跟着裁判走</li>
</ol>
</li>
<li><p>元宇宙</p>

<ul>
<li>远程控制延伸想象</li>
</ul>
</li>
</ul>


<h3>科学和宗教信仰的区别</h3>

<p>宗教信仰重结论，科学重过程方法，</p>

<h3>厚黑学0625</h3>

<h3>西方文明的道统</h3>

<p>圣经提供意义，古希腊哲学家提供理性</p>

<h3>专才和通才</h3>

<ul>
<li>通才：

<ul>
<li>费德勒：选择网球之前接触过多种运动，11岁才选择网球，16岁开始接受专业训练。纳达尔也是从足球和网球中选择的网球。</li>
</ul>
</li>
<li>专才：

<ul>
<li>老虎伍兹：神童</li>
</ul>
</li>
</ul>


<p>通才的两个有点：</p>

<ol>
<li>容易有内驱力：从小被父母安排的生活总感觉不是自己选择的。</li>
<li>广度能让你更深入</li>
</ol>


<p>专业确定太早，初期成功，后劲不足。基础很重要，大三选专业</p>

<p>功夫在诗外，说的是在牢固基础之上创新所需要的思维和积淀</p>

<p>体育和音乐是童子功，需要年轻的时候出成果。数学也是</p>

<h3>思考问题的两个思路：</h3>

<ol>
<li>完美主义：先考虑做100分（终结问题），不行再考虑90分</li>
<li>实用主义：直接考虑做60分，做到就停</li>
</ol>


<h3>知之者不如好之者，好之者不如乐之者</h3>

<p>乐之者，做前特别期待，做的时候能快速进入心流状态，做成之后有成就感。刻意练习会让人不舒服，只有乐之者才能坚持下去，从而达到优异。</p>

<p>努力做个乐之者。保证工作中百分之二十的事情是乐之的事情，就会开心的工作。</p>

<h3>如何当领导？</h3>

<ul>
<li>定目标的缺点，达标后就放慢，不达标容易违法</li>
<li>目标只是让高层更舒服而已吧</li>
<li>高层提供信息和使命的意义</li>
<li>不给目标给意义，讲哲学</li>
<li>不给计划给信息</li>
<li>夸长处，没有专业技能就说个人感受，比如，我喜欢。夸和指责之间的比例三比一到五比一。夸和指责都应该对事不对人。</li>
</ul>


<h3>马斯洛金字塔</h3>

<ul>
<li>人总是高估自己在金字塔上的层次，低估别人在金字塔上的层次</li>
<li>认为别人物质，自己理想主义，认为别人都是坏人，自己做坏事的时候却总是迫不得已</li>
</ul>


<h3>逻辑与直觉</h3>

<ul>
<li>哥德尔逻辑不完备性</li>
<li>人工智能，纯逻辑？能认知世界吗？</li>
</ul>


<h3>灰度认知</h3>

<ul>
<li>思圆行方，邓小平</li>
<li>灰度认知，黑白决策</li>
<li>灰度认知，灰度决策，黑白执行（模糊数学）</li>
</ul>


<h3>先发优势与后发优势</h3>

<ul>
<li>先发优势：定义产品和服务，占据消费者喜好，申请专利</li>
<li>后发优势：借鉴前人的经验教训</li>
</ul>


<h3>个性化推荐</h3>

<p>个性化推荐，共性推荐
根本就不存在什么个性化推荐。</p>

<h3>怎样提高欢迎度？</h3>

<p>当周围人都对你友好的时候，你也会变得友好。这就是为什么你带着两岁的娃在外的时候，更容易和其他人通过娃拉近距离。</p>

<h3>怎样跟人快速建立亲密关系？</h3>

<ul>
<li>肢体触碰</li>
<li>自爆弱点缺点</li>
</ul>


<h3>怎样对抗进化？</h3>

<p>克制杀戮，阻断害虫抗药性。保证一定数量的没有抗药性的害虫的数量，可以弱化抗药性进化速度。<strong>不灭绝，只控制</strong>，是一种智慧。这不正是中庸之道吗。
禁赌令产生地下赌场，禁酒令产生地下酒交易，禁海令产生海盗和倭寇。试图将事情做绝就会产生副作用。</p>

<h3>对于自己不想回答的问题，怎么不说谎？</h3>

<p>用相关的事实去误导别人。
当别人意识到的时候，同样会生气，会鄙视你的人格，但至少不会鄙视你的智商。</p>

<h3>实在的美国精英</h3>

<p>在一线打拼的人告诉你应该怎么做，而不是结合了儒道佛等玄学之后给你形而上的讲一些大道理，但就是不愿意跟你一起落实到细节上去。</p>

<h3>如何保持快乐</h3>

<p>少见多怪，多见不疑</p>

<p>快乐的两种方式
* 增加时间间隔
* 追求多样性</p>

<p>如何选择这两种方式？
* 浅的东西用间隔，比如好吃的东西不要太频繁吃，也不要吃太多。
* 深的东西自带多样性。</p>

<p>用金钱调节，还是用时间调整。</p>

<h3>解释性框架</h3>

<p>解释性框架，不能通过一两个反例否定，没有固定的实验去验证真伪，比如社会科学，经济学等。</p>

<h3>余闲</h3>

<p>余闲，slack，不是一直处于拼命状态，把时间安排的可丁可卯，那种状态是没时间思考的，是工具人，是奴隶。余闲有选择的余地，有创新的可能，诺贝尔奖的初衷就是给你一笔钱，让你不用为生计发愁，可以自由创新。</p>

<ol>
<li>穷人愈来愈穷，技术差的人愈来愈差</li>
<li>马太效应</li>
<li>正反馈</li>
</ol>


<h3>强人哲学与弱者哲学</h3>

<ul>
<li>阿德勒，强人哲学，所有的性格问题都是自己的选择。</li>
<li>弗洛伊德，弱者哲学，所有的性格问题都是过往经历决定的，决定论。</li>
</ul>


<h3>OpenAI</h3>

<ol>
<li>gpt3: text completion, article generation, conversation</li>
<li>DALL·E: Creating Images from Text</li>
<li>Codex: code completion. (Copilot)</li>
</ol>


<h3>关于量子力学</h3>

<ul>
<li>粒子的波函数能超越时空获得信息，进而影响粒子的行为。</li>
<li>波函数到底是不是客观实在，还是纯数学？</li>
<li>波函数坍缩是瞬时的，退相干是逐渐的。此过程长短取决于粒子数多少。宏观物体有叠加态，只是退相关过程太短，所以察觉不到。这个可以解释薛定谔的猫。

<h3>愿望思维，严重导致确认偏误</h3></li>
<li>吸引力法则： 如果你整天想象自己能得到一个什么东西，那个东西就会自动来找你。这是迷信，是错误的认知。</li>
<li>自证预言：是一个具有普遍意义的现象，是你在明明还有选择的情况下，以为事情是个什么状况，就按照这个状况去做，结果事情就真的被搞成了那个状况。比赛明明还有的打，我以为自己已经输了，结果自暴自弃，最后果然输了。</li>
<li>皮格马利翁效应：是你希望别人是什么样子，你就像他是这个样子一样去对待他，这样他被你影响，慢慢就真的变成了那个样子。</li>
<li>愿望思维：把美好的愿望当作真实。分不清楚“希望”和真实。</li>
<li>确认偏误：（或称确认偏差、证实偏差、肯证偏误、验证偏误、验证性偏见、我方偏见，英语：Confirmation bias）是个人选择性地回忆、搜集有利细节，忽略不利或矛盾的资讯，来支持自己已有的想法或假设的趋势。</li>
</ul>


<p>拿男生追女孩那个例子来说。</p>

<ol>
<li>“自证预言”，是男生稳扎稳打地、但是是符合常规操作地去追求这个女孩。可能先在她面前好好表现，再送花、再请看电影，慢慢再表白……</li>
<li>“皮格马利翁效应”，是男生每天就把这个女孩当做自己的女朋友去相处。不整那些前期的花哨功夫，一上来就天天给送饭，让女孩产生自己早就是她女朋友的错觉。</li>
<li>“吸引力法则”，是男生不敢跟女孩说话，天天躲在宿舍里思念女孩，在脑子里演练跟女孩在一起的点点滴滴，指望通过心灵感应之类的超自然力量得到女孩的爱。</li>
<li>而“愿望思维”，则是男孩说：她肯定喜欢我啊！我那么爱她她怎么可能不喜欢我呢？

<h3>精英日课反对王东岳的递弱代偿理论</h3></li>
</ol>


<p>“递弱代偿”，就是说世间之物，后衍物种的生存强度（生存的顽强程度）总是呈现递减态势，一代比一代弱，于是，要想生存下去，就得不断地寻找更多的支持因素，这个支持因素就是“代偿”。</p>

<p>越原始越低级的物质存在形态存在度反而越高，越高级越进化的物质存在形态或物种存在度越低。</p>

<p>存在度有三项硬指标：
* 其一在宇宙中的空间质量分布越大
* 其二在宇宙中的时间分布越长
* 其三存在状态越稳定。</p>

<h3>第一性原理，改变原来的模式，根本上降低原来的价格</h3>

<h3>辉格史观</h3>

<p>辉格史观是胜利者角度的历史观。与之相对的是：历史现场角度。</p>

<p>辉格史观者相信在历史学中存在演变的逻辑，他们用现在的标准评判过去。用通俗的话语来讲，即辉格史观描述的一切历史都是基于现在为出发点，传达的历史都是为现在做服务。</p>

<h3>0514马歇尔效应罗森效应，高级，势能动能，品牌现金，热寂，逆商</h3>

<h3>汉隆剃刀</h3>

<p>能解释为愚蠢的，就不要解释为恶意。</p>

<h4>恶意循环</h4>

<p>在工作上，同事没有对展示文件的错误进行修改，导致自己做展示的时候被领导发现错误，最后被训话。恶意的循环就是从这里开始的，会不会是同事故意这样做的，想要毁了我的职业生涯。然后两个人就开始互相看不顺眼，互相的使绊子，最后影响到公司的正常运营，两个人都被公司开除了。每一次埋怨都会加深自己的看法，然后导致下一次行动出现问题。不论是怎么样，最后的结果肯定都是以悲剧收场。这就像一个恶意的循环，每循环一次就会加深恶意。</p>

<p>其实第一次可能就是因为同事前一天生病加班给漏掉了。自己也没检查，出现了问题。在聪明的人也会犯错，但区别在于聪明的人会避免重复犯同样的错误。汉隆的剃刀是帮助我们从感性走向理性的绝佳工具，这时候最正确的做法应该是与他人沟通，找到避免下次犯错的方法才是正解。如果陷入了恶意循环，是很难看到问题到底出现在哪里。</p>

<h3>逆火效应</h3>

<p>逆火效应（the backfire effect）是指：当一个错误的信息被更正后，如果更正的信息与人原本的看法相违背，它反而会加深人们对这条（原本）错误的信息的信任。</p>

<h3>其它</h3>

<ul>
<li>世俗的成功驱使着你做事情，世俗的成功也就是别人的认可。别人的认可不应该成为最终目标，而应该只是副产品。</li>
<li>被讨厌的勇气，生活哲学</li>
<li>穷人靠环境，富人靠天赋，因为富人环境优越，天花板取决于天赋，而穷人环境限制了天赋的发挥。轮不到你发挥天* 赋。</li>
<li>0729

<ul>
<li>黑客工具系统</li>
<li>全球目录</li>
</ul>
</li>
<li>高效能人士，本质是把事情交给外部系统或者其他人，付出的可能是金钱</li>
<li>负反馈，囚徒困境，高考刷题，美颜，信用分，搜索引擎排名</li>
<li>kargo网站解决棘手问题，类似于ai领域的？？？</li>
<li>我是谁，我适合做什么？是要在行动中去寻找的。</li>
<li>达芬奇诅咒</li>
<li>思而不学则极端，学而不思则矛盾</li>
<li>蒙台梭利让孩子玩，孩子也可以在家玩，这两种没有区别。只要不学习知识或者技能训练就可以。</li>
<li>学英语，用最重要，突击刻意练习次之，每天二十分钟最差。口音不是问题，比如印度英语。</li>
<li>尽量避免传递坏消息。传递坏消息给国王的信使被射杀，传递坏消息的员工被记恨。</li>
<li>群体选择，好人坏人：群体中的坏人打败好人，好人群体打败坏人群体。</li>
<li>有些特征是物理规律决定的，比如雪花形状，有些特征是演化形成的，比如体型大小，经典的设计产品（手机）等。</li>
<li>正确的人和优异的人</li>
<li>对于别人的诋毁，弱者报复，强者原谅，智者忽略（爱因斯坦）</li>
<li>谈判要逐步深入，逐渐加码，摩尔不破</li>
<li>你的价值取决于你克服了多少不确定性。</li>
<li>远虑包装成近忧，重要包装成紧急，才能获得批准去做。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[精英日课-反脆弱]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/10/07/jingyingrike-fancuiruo/"/>
    <updated>2022-10-07T23:29:22+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/10/07/jingyingrike-fancuiruo</id>
    <content type="html"><![CDATA[<!-- more -->


<p>好运气，你能把它的效果最大化，坏的危险，你能把它限制在可控的范围之内。这简直就是人生的核心算法。</p>

<p>参考知乎文章：<a href="https://www.zhihu.com/question/269850841/answer/2594292784">脆弱的反面是什么？是坚强吗？ 不！脆弱的反面是“反脆弱”！？</a></p>

<p>反脆弱一书主要讲述三方面的内容：</p>

<ol>
<li>什么系统是反脆弱的？</li>
<li>为什么发达的现代社会让我们变得更加脆弱？</li>
<li>如何构建自己的反脆弱性</li>
</ol>


<h2>什么系统是反脆弱的？</h2>

<blockquote><p>所谓的反脆弱系统，其实就是正反馈系统，比如书中说的感情系统和信息传播系统。其实还有沼泽地，越动下沉的越快。</p></blockquote>

<p>熟悉期权交易的童鞋可能会很了解，long Gamma做多波动率的交易策略就是反脆弱，不过这里会用更通俗的方法来解释这个名词。举个简单的例子，少年少女之间的痴情就是真正的反脆弱，，无论被爱慕的那个人做什么。都会增加爱慕者的爱慕，甚至在极端的痴情案例中，即便被爱慕的人虐待，爱慕者也会因为斯德哥尔摩症更爱他。也就是说，无论被爱慕者对爱慕者关怀备至还是拳打脚踢，都会导致更深的爱。</p>

<p>这种无论怎么波动，都会变的更牢固的痴情，自然是反脆弱的。与此类似的是，粉丝对明星的爱也是反脆弱的。无论自己家爱豆是彬彬有礼还是酒驾闯祸，无论演的好不好，这种感情都会随着偶像的好或者坏的言行而逐渐加深。再举一个感情相关的例子，为什么失恋难以走出来？因为失恋也是真正的反脆弱，无论你想采取什么样的方式让自己走出来：否认之前的感情、给自己找理由、反思自己哪里做的不对，都只能让自己变的更加思念对方，陷的越来越深。当然，具有反脆弱特点的事物远远不限于感情，信息就是另外一个反脆弱的例子，你很难控制信息的走向，你越是封杀信息、攻击信息，信息就传播的越快，假设有人散布关于你的谣言，如果你坐卧不安，到处向别人解释，这些事情都是纯属捏造，一派胡言，那这个谣言很快就会满天飞。还有新闻的热点、假如你成为新闻热点、微博热搜，无论怎么解释，否认或者试图封锁消息，都只能是火上浇油，让热点越烧越旺，最终人尽皆知。再比如说很多禁书，其实没有那么出名，但是被禁之后很快流传开来，塔勒布就提到了自己人生读完的第一本书英国作家格雷姆的《权利与荣耀》，这是一本梵蒂冈的禁书，而塔勒布读这本书的唯一目的就是想搞懂为啥这本书会被封禁。</p>

<p>感情、信息本身就是反脆弱的，但也有一些事物，虽然本身是脆弱的，不过由他们组成的系统却是反脆弱的，餐饮行业就是一个典型的反脆弱的案例，虽然顾客的口味一直在变，但是一旦有一家饭馆因为不符合大众主流口味而倒闭啦！其他餐馆都会意识到问题，改进自己的饭菜口味，从而使得整个餐饮行业更加符合顾客的需求，更加欣欣向荣！但是如果在某个时期，顾客并无法选择餐馆，比如说：人民公社时期的饭馆或者大学食堂，餐馆就无法获得顾客的反馈，从而变的非常脆弱，一旦顾客有了更多的选择，原来的餐馆都会面临更大的风险。与餐饮行业类似，航空业也是一个反脆弱的很好的例子，如果有一架飞机不幸失事了，全世界的航空公司和飞机制造商都会总结原因，吸取教训，改进系统，从而让飞机作为一种出行方式，变的越来越安全。而不同于餐饮、航空业的是，在塔勒布眼里，银行系统则是一个脆弱系统的典型，并且在现在的体制下会越来越脆弱：不同的银行之间联系相对紧密，因此整个银行系统都存在系统性风险。如果一家银行倒闭了，因为系统性风险的存在，为了保持金融稳定，政府只能介入救助不让银行破产，但这却让整个银行系统更脆弱了。从而使得银行抗风险的能力远远不如餐饮业和航空业，一旦遇到金融危机这种黑天鹅事件，就会有灾难性的后果出现。为了更直观地说明脆弱和反脆弱的区别，塔勒布还在书中虚构了约翰和乔治一对兄弟，对比了一下兄弟二人的职业。哥哥约翰是一个人力资源专家，有着稳定的收入，完善的福利。他带着金手表，有着25年工作经验的他每年定期休假25天。在每个月月初，约翰的银行账户里都会稳定的多出3082欧收入，他会拿其中的一部分来还房贷，一部分用来吃吃喝喝，剩下一点点存起来。约翰的弟弟乔治则是一名出租车司机，他的收入则十分的不稳定，有些日子乔治能挣几百欧，但是日子差的时候甚至挣不回油钱，平均下来乔治和约翰差不多，但是乔治却常常抱怨自己的收入太不稳定了，工作不想自己的哥哥那样是个铁饭碗。通常人看起来，人力资源专家约翰的工作是稳定的，因此也更好，但是塔勒布则认为乔治的工作是反脆弱的，这种工作状态才是稳定的，塔勒布在书中写到，人们往往认为波动性就是风险本身，致力于消除波动性，但是波动性能带来信息，经常面对波动性的人能从波动性中获取有效的信息，并不断根据信息来改善自己，提高自己的抗风险能力，从而成为反脆弱的人，即使世事动荡，仍然能茁壮成长。而致力于消除自己生活中波动性的人，则可能因为长时间得不到外界的反馈，没有办法调整自己的能力和知识结构，虽然在一段时间内能过上表面上波澜不惊的生活，但是如果黑天鹅事件发生，突如其来的巨大波动性很可能会瞬间毁灭他的生活并再也无法平复。这也是反脆弱理念的核心。总的来说，面对外界环境的波动，反而会成长的事物，就是反脆弱的，反之则是脆弱的。</p>

<p>那么，如何消灭一个反脆弱的事物呢？说简单也简单，反脆弱的事物是依据波动性成长的，消灭波动性就好了。比如走出失恋最好的方式是删掉一切联系方式，去一个新地方生活，停止接受一切信息；消灭微博热点的最好方式不是去否认它，而是发起另外一个热点。说难也真的挺难的，在这个事物普遍联系，时时都在变化的世界，消灭波动性几乎是不可能。以上就是这本书的第一个要点，反脆弱的定义。从不确定性中受益的事物就是反脆弱。</p>

<h2>为什么发达的现代社会让我们变得更加脆弱？</h2>

<p>现代社会使用一切手段让我们的生活变的更轻松，费尽心思消除社会和我们生活中的不确定性，从央行稳定经济体系，到老师手把手地教学生知识，到稍有不适医生就开一大堆药。这种过度干预反而剥夺了我们成长的机会，让我们变的愈加脆弱，讲完了反脆弱的定义，为什么现代社会为什么会让我们变的脆弱，</p>

<h2>如何构建自己的反脆弱性</h2>

<p>首先，要改变自己的三大认知。</p>

<ol>
<li>放弃任何预测未来的想法，世界是不可被预测的。我们的世界纷繁复杂，普遍联系，存在着各种非线性相关性。预测未来根本不可能。</li>
<li>因为世界是不可被预测的，所以风险是不可能被测量的，但我们能测量出自己是不是脆弱的，因此可以有针对性的提高自己的反脆弱能力，简单来讲，做压力测试就可以了，假设极端情况发生，如果我们的收益曲线是凸性的，二阶导大于0，我们就是反脆弱的，我们的收益曲线是凹性的，二阶导小于0，我们就是脆弱的；</li>
<li>要认识到波动和不确定性并不能消除风险，这样只是把风险隐藏起来罢了，适度拥抱不确定性，适度拥抱风险，能让我们更健康的成长，这也是构建反脆弱性的前提。</li>
</ol>


<p>总结一下，就是我们要有一种认知，我们不必认知世界，不必理解世界，只要构建好自己的反脆弱性，也能过的很好，并且很好地抵御风险。</p>

<p>此外，塔勒布还提出了五种具体构建反脆弱的方法</p>

<ol>
<li>留出足够的冗余。脆弱的系统之所以脆弱，根本原因是他们把效率当头等大事，往往孤注一掷，因此抗风险能力极差。而对于反脆弱的系统，活下来才是头等大事，所以优秀的反脆弱系统都会留有充足的冗余，这样才能有应对风险的底气。大自然就给予我们两个肺、两个肾脏，这样虽然效率不高，但是却是必要的冗余。</li>
<li>给自己适度的压力和挑战，促使自己成长。不要贪图表面安逸的生活，意识到波动和不确定性的信息是非常珍贵的，适度的压力反而能促使我们成长，成为反脆弱的事物。</li>
<li>采用杠铃策略。杠铃策略其实也是塔勒布从债券交易中借鉴过来的概念，杠铃策略是指，在债券交易中不买中等期限的债券，只买超短期的债券和超长期的债券，这样无论利率是上升还是下降，都能从中获益。这种两头大，中间空的策略，神似杠铃，所以叫杠铃策略。塔勒布把这种策略扩展到了生活之中，认为应当抛弃中间路线，要努力构建超低风险加超高风险的组合，超低风险用来守底，超高风险用来博取收益。</li>
<li>多做减法，塔勒布在书中提到，虽然我们很难搞清楚怎么才能构建自己的反脆弱性，但是我们却能很容易地发现，是什么让我们变的更加地脆弱，这时候，只要我们多做减法，去掉这些让我们变的脆弱的东西，我们自然就变的反脆弱了，例如：包括债务、损友、垃圾食品等等。</li>
<li>多给自己一些选择权。这一点是显而易见的，当风险来临的时候，肯定是选择权越多的人越反脆弱，例如：作为一个程序员，你完全可以利用每周多出来的时间进行写作，保持自己写作的良好习惯，当一个斜杠青年；</li>
</ol>


<p>总结一下，我们为了构建反脆弱性。可以运用五种方法：留够冗余、给自己适当的压力、采用杠铃策略、多做减法、多给自己选择权。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[精英日课]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/07/27/jingyingrike/"/>
    <updated>2022-07-27T22:29:43+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/07/27/jingyingrike</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>博弈论</h2>

<p><a href="http://hongchaozhang.github.io/blog/2022/07/27/jingyingrike-boyilun/">《精英日课-博弈论》</a></p>

<h2>《反脆弱》（那西姆塔勒布）</h2>

<p><a href="http://hongchaozhang.github.io/blog/2022/10/07/jingyingrike-fancuiruo/">《精英日课-反脆弱》</a></p>

<h2>计算机不能做所有的事情</h2>

<p><a href="http://hongchaozhang.github.io/blog/2022/10/08/jingyingrike-jisuanjibunengzuodeshiqing/">《精英日课-计算机不能做所有的事情</a></p>

<h2>问题的类型</h2>

<p><a href="http://hongchaozhang.github.io/blog/2022/10/08/jingyingrike-kunnandewenti/">《精英日课-问题的类型》</a></p>

<h2>期权思维</h2>

<p><a href="http://hongchaozhang.github.io/blog/2022/10/08/jingyingrike-qiquan/">《精英日课-期权思维》</a></p>

<h2>杂想</h2>

<p><a href="http://hongchaozhang.github.io/blog/2022/10/07/jingyingrike-zaxiang/">《精英日课-杂想》</a></p>

<h2>伯克森悖论</h2>

<p><a href="http://hongchaozhang.github.io/blog/2022/12/08/jingyingrike-bokesenbeilun">《精英日课-博克森悖论》</a></p>

<h2>思维是平的</h2>

<p><a href="http://hongchaozhang.github.io/blog/2022/12/08/jingyingrike-siweishipingde">《精英日课-思维是平的》</a></p>

<h2>排序不等式</h2>

<p><a href="http://hongchaozhang.github.io/blog/2022/12/08/jingyingrike-paixubudengshi">《精英日课-排序不等式》</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[精英日课-博弈论]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/07/27/jingyingrike-boyilun/"/>
    <updated>2022-07-27T22:29:10+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/07/27/jingyingrike-boyilun</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>博弈论11 混合策略</h2>

<p>下面是常见的两个博弈论的问题和一般人的想法：</p>

<ul>
<li>踢点球：左右方向各百分之五十。</li>
<li>德州扑克：牌好就加注，牌不好就弃牌。</li>
</ul>


<p>以上都不是最佳策略，因为：</p>

<ul>
<li>踢点球：如果你往左进门概率是60%，往右进门概率是80%，那么守门员只用防右边就好了。</li>
<li>德州扑克：对手看你加注就弃牌。</li>
</ul>


<p>在这种情况下，应该采取<strong>混合策略</strong>：</p>

<ul>
<li>踢点球：应该结合自己左右方向的进球能力调整左右方向的射门概率，让守门员不管往哪个方向扑，你进球的概率都是相同的。也就是说，你的混合概率选择，应该把对手能得到的最大收益最小化。</li>
</ul>


<h3>真随机才是真正的诡道。</h3>

<ul>
<li>打网球是攻击对方正手还是反手？</li>
<li>足球篮球中，多大概率将球交到球星手里才能最大化进球数？</li>
<li>田忌赛马，齐宣王的最好办法就是采用混合策略：真随机地分配出场顺序。</li>
</ul>


<p>混合策略不是阴谋是阳谋：阴谋被识破就失效了，但是阳谋不怕被识破。归根结底，大家都是纳什均衡的奴隶。</p>

<h2>博弈论12 怎样筛选信号</h2>

<h3>如何解决信息不对称，让信息可信？</h3>

<ol>
<li>产品已经很好了，还要请明星代言，天价广告费，没啥用。</li>
<li>大学学习的是那么艰难又不实用的东西，还要花很多时间</li>
<li>公共场合吹捧领导，那么肉麻，有失体面</li>
</ol>


<h3>要让别人相信你说的话（产品好，有实力），你要主动“发信号”。</h3>

<ol>
<li>为了让别人相信你卖的二手车质量好，你可以提供一个保修合同。</li>
<li>天价广告费，沉没成本，做长期生意的决心。</li>
<li>花时间上大学，是为了证明自己的能力</li>
<li>吹捧领导，损失个人形象，是为了证明忠诚。</li>
</ol>


<h3>如果别人没有主动发信号，如何让他发信号？</h3>

<h4>逆向选择和正向选择</h4>

<p>保险公司有个困境：主动来投保的都是急需要保险的，而最需要保险的人却是保险公司最不想要的人。保险公司因此要提高保费，这样，原来不愿意投保的就更不会来了。这就是逆向选择：你选出来的都是你不想要的。
要解决这个问题，有两个方案：</p>

<ol>
<li>全民强制保险</li>
<li>价格歧视</li>
</ol>


<p>例子：</p>

<ul>
<li>申请美国大学要填写复杂的申请表，这个也不是必须的，但是有作用：筛选出自认为有能力同时又有诚意的学生。</li>
<li>保险公司让用户选择不同的保险方案。</li>
</ul>


<h2>其它问题</h2>

<h3>纳什均衡</h3>

<ol>
<li>纳什均衡，其实就是物理里面的稳态(负反馈)</li>
<li>纳什均衡是博弈的终点</li>
<li>有人的对抗和无人的对抗</li>
<li>理性青年追求纳什均衡，完美青年追求帕累托最优</li>
<li>复习补课是纳什均衡</li>
</ol>


<h3>公地悲剧</h3>

<p>如何打破公地悲剧？</p>

<h3>囚徒困境</h3>

<p>如何打破囚徒困境？</p>

<ul>
<li>谁是胆小鬼，汽车相向而行。首先拔掉方向盘，想对方表达自己的决心。</li>
<li>核威慑</li>
<li>事前最优事后最优，“老师，你要是让我不及格，我会报复你”，事前管用，事后不一定管用。</li>
<li>断自己的后路，给对方增加后路，比如孙子兵法要求围师必阙，在包围敌人的时候最好留一个缺口，防止困兽犹斗。</li>
<li>声望好，可以代价很小而取信于人。</li>
<li>价格匹配，保证是全网最低价</li>
</ul>


<h3>其它</h3>

<ul>
<li>博弈，新博弈，更新的博弈，螺旋上升</li>
<li>博弈次数的多少，决定了我用正义策略还是邪恶策略。熟人社会，古代中国，正义策略</li>
<li>文明世界，正确对待博弈的对手和博弈的失败</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[程序员的数学基础课（黄申）]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/05/31/chengxuyuan-shuxue-jichuke/"/>
    <updated>2022-05-31T15:48:14+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/05/31/chengxuyuan-shuxue-jichuke</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>01-开篇词 (1讲)</h2>

<h3>00丨开篇词丨作为程序员，为什么你应该学好数学？</h3>

<h2>02-导读 (1讲)</h2>

<h3>00丨导读：程序员应该怎么学数学？</h3>

<h2>03-基础思想篇 (18讲)</h2>

<h3>01丨二进制：不了解计算机的源头，你学什么编程</h3>

<h3>02丨余数：原来取余操作本身就是个哈希函数</h3>

<h3>03丨迭代法：不用编程语言的自带函数，你会如何计算平方根？</h3>

<h4>迭代法有什么具体应用？</h4>

<p>迭代法在无论是在数学，还是计算机领域都有很广泛的应用。大体上，迭代法可以运用在以下几个方面：</p>

<ol>
<li>求数值的精确或者近似解。典型的方法包括二分法（Bisection method）和牛顿迭代法（Newton’s method）。</li>
<li>在一定范围内查找目标值。典型的方法包括二分查找。</li>
<li>机器学习算法中的迭代。相关的算法或者模型有很多，比如 K- 均值算法（K-means clustering）、PageRank 的马尔科夫链（Markov chain）、梯度下降法（Gradient descent）等等。迭代法之所以在机器学习中有广泛的应用，是因为很多时候机器学习的过程，就是根据已知的数据和一定的假设，求一个局部最优解。而迭代法可以帮助学习算法逐步搜索，直至发现这种解。</li>
</ol>


<h3>04丨数学归纳法：如何用数学归纳提升代码的运行效率？</h3>

<p>数学归纳法的一般步骤是这样的：</p>

<ol>
<li>证明基本情况（通常是<code>n=1</code>的时候）是否成立；</li>
<li>假设<code>n=k−1</code>成立，再证明<code>n=k</code>也是成立的（<code>k</code>为任意大于1的自然数）。</li>
</ol>


<p>和使用迭代法的计算相比，数学归纳法最大的特点就在于“归纳”二字。它已经总结出了规律。只要我们能够证明这个规律是正确的，就没有必要进行逐步的推算，可以节省很多时间和资源。</p>

<p><strong>递归调用的代码和数学归纳法的逻辑是一致的。</strong></p>

<h4>递归和数学归纳法的核心思想</h4>

<p>复杂的问题，每次都解决一点点，并将剩下的任务转化成为更简单的问题等待下次求解，如此反复，直到最简单的形式。</p>

<h3>05丨递归（上）：泛化数学归纳，如何将复杂问题简单化？</h3>

<h3>06丨递归（下）：分而治之，从归并排序到MapReduce</h3>

<p>对于一些复杂问题，我们可以先分析一下，它们是否可以简化为某些更小的、更简单的子问题来解决，这是一般思路。如果可以，那就意味着我们仍然可以使用递归的核心思想，将复杂的问题逐步简化成最基本的情况来求解。</p>

<p>因此，今天我会从归并排序开始，延伸到多台机器的并行处理，详细讲讲递归思想在“分而治之”这个领域的应用。</p>

<h4>归并排序</h4>

<p><img src="http://hongchaozhang.github.io/images/20220531%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B.jpeg" alt="20220531归并排序模型.jpeg" /></p>

<p>我们可以在归并排序中引入了分而治之（Divide and Conquer）的思想。分而治之，我们通常简称为分治。它的思想就是，将一个复杂的问题，分解成两个甚至多个规模相同或类似的子问题，然后对这些子问题再进一步细分，直到最后的子问题变得很简单，很容易就能被求解出来，这样这个复杂的问题就求解出来了。</p>

<h4>分布式系统中的分治思想</h4>

<p>分而治之更有趣的应用其实是在分布式系统中。</p>

<p>例如，当需要排序的数组很大（比如达到 1024GB 的时候），我们没法把这些数据都塞入一台普通机器的内存里。该怎么办呢？有一个办法，我们可以把这个超级大的数据集，分解为多个更小的数据集（比如 16GB 或者更小），然后分配到多台机器，让它们并行地处理。</p>

<p>等所有机器处理完后，中央服务器再进行结果的合并。由于多个小任务间不会相互干扰，可以同时处理，这样会大大增加处理的速度，减少等待时间。</p>

<p>在单台机器上实现归并排序的时候，我们只需要在递归函数内，实现数据分组以及合并就行了。而在多个机器之间分配数据的时候，递归函数内除了分组及合并，还要负责把数据分发到某台机器上。</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E5%88%86%E8%80%8C%E6%B2%BB%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F.jpeg" alt="20220531分而治之分布式系统.jpeg" /></p>

<h3>07丨排列：如何让计算机学会“田忌赛马”？</h3>

<h3>08丨组合：如何让计算机安排世界杯的赛程？</h3>

<h3>09丨动态规划（上）：如何实现基于编辑距离的查询推荐？</h3>

<p>聊聊查询推荐（Query Suggestion）的实现过程，以及它所使用的数学思想，动态规划（Dynamic Programming）。</p>

<h4>编辑距离</h4>

<p>搜索下拉提示和关键词纠错，这两个功能其实就是查询推荐。查询推荐的核心思想其实就是，对于用户的输入，查找相似的关键词并进行返回。而测量拉丁文的文本相似度，最常用的指标是<strong>编辑距离</strong>（Edit Distance）。</p>

<p>编辑距离是指由一个字符串转成另一个字符串所需的最少编辑操作次数。</p>

<h4>状态转移</h4>

<p>我用mouuse和mouse的例子。我把mouuse的字符数组作为表格的行，每一行表示其中一个字母，而mouse的字符数组作为列，每列表示其中一个字母，这样就得到下面这个表格。</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB%E7%8A%B6%E6%80%81%E8%BD%AC%E7%A7%BB.png" alt="20220531编辑距离状态转移.png" /></p>

<h3>10丨动态规划（下）：如何求得状态转移方程并进行编程实现？</h3>

<h4>状态转移方程</h4>

<p><img src="http://hongchaozhang.github.io/images/20220531%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB%E7%8A%B6%E6%80%81%E8%BD%AC%E7%A7%BB%E6%96%B9%E7%A8%8B.png" alt="20220531编辑距离状态转移方程.png" /></p>

<p>这里面求最小值的<code>min</code>函数里有三个参数，分别对应我们上节讲的三种情况的编辑距离，分别是：替换、插入和删除字符。在表格的右下角我标出了两个字符串的编辑距离1。</p>

<p>我们假设字符数组<code>A[]</code>和<code>B[]</code>分别表示字符串<code>A</code>和<code>B</code>，<code>A[i]</code>表示字符串<code>A</code>中第<code>i</code>个位置的字符，<code>B[i]</code>表示字符串<code>B</code>中第<code>i</code>个位置的字符。二维数组<code>d[,]</code>表示刚刚用于推导的二维表格，而<code>d[i,j]</code>表示这张表格中第<code>i</code>行、第<code>j</code>列求得的最终编辑距离。函数<code>r(i, j)</code>表示替换时产生的编辑距离。如果<code>A[i]</code>和<code>B[j]</code>相同，函数的返回值为0，否则返回值为1。</p>

<p>有了这些定义，下面我们用迭代来表达上述的推导过程。</p>

<ol>
<li>如果<code>i</code>为0，且<code>j</code>也为0，那么<code>d[i, j]</code>为0。</li>
<li>如果<code>i</code>为0，且<code>j</code>大于0，那么<code>d[i, j]</code>为<code>j</code>。</li>
<li>如果<code>i</code>大于0，且<code>j</code>为0，那么<code>d[i, j]</code>为<code>i</code>。</li>
<li>如果<code>i</code>大于0，且<code>j</code>大于0，那么<code>d[i, j]=min(d[i-1, j] + 1, d[i, j-1] + 1, d[i-1, j-1] + r(i, j))</code>。</li>
</ol>


<p>这里面最关键的一步是<code>d[i, j]=min(d[i-1, j] + 1, d[i, j-1] + 1, d[i-1, j-1] + r(i, j))</code>。这个表达式表示的是动态规划中从上一个状态到下一个状态之间可能存在的一些变化，以及基于这些变化的最终决策结果。我们把这样的表达式称为<strong>状态转移方程</strong>。</p>

<h4>总结</h4>

<p>通过这两节的内容，我讲述了动态规划主要的思想和应用。如果仅仅看这两个案例，也许你觉得动态规划不难理解。不过，在实际应用中，你可能会产生这些疑问：什么时候该用动态规划？这个问题可以用动态规划解决啊，为什么我没想到？我这里就讲一些我个人的经验。</p>

<p>首先，如果一个问题有很多种可能，看上去需要使用排列或组合的思想，但是最终求的只是某种最优解（例如最小值、最大值、最短子串、最长子串等等），那么你不妨试试是否可以使用动态规划。</p>

<p>其次，状态转移方程是个关键。你可以用状态转移表来帮助自己理解整个过程。如果能找到准确的转移方程，那么离最终的代码实现就不远了。</p>

<h3>11丨树的深度优先搜索（上）：如何才能高效率地查字典？</h3>

<h3>12丨树的深度优先搜索（下）：如何才能高效率地查字典？</h3>

<h3>13丨树的广度优先搜索（上）：人际关系的六度理论是真的吗？</h3>

<h3>14丨树的广度优先搜索（下）：为什么双向广度优先搜索的效率更高？</h3>

<h4>如何更高效地求两个用户间的最短路径？</h4>

<p>基本的做法是，从其中一个人出发，进行广度优先搜索，看看另一个人是否在其中。如果不幸的话，两个人相距六度，那么即使是广度优先搜索，同样要达到万亿级的数量。</p>

<p>那究竟该如何更高效地求得两个用户的最短路径呢？我们先看看，影响效率的问题在哪里？很显然，随着社会关系的度数增加，好友数量是呈指数级增长的。所以，如果我们可以控制这种指数级的增长，那么就可以控制潜在好友的数量，达到提升效率的目的。</p>

<p>如何控制这种增长呢？我这里介绍一种“<strong>双向广度优先搜索</strong>”。它巧妙地运用了两个方向的广度优先搜索，大幅降低了搜索的度数。</p>

<h3>15丨从树到图：如何让计算机学会看地图？</h3>

<p>使用Dijkstra算法来查找地图中两点之间的最短路径。</p>

<h3>16丨时间和空间复杂度（上）：优化性能是否只是“纸上谈兵”？</h3>

<h3>17丨时间和空间复杂度（下）：如何使用六个法则进行复杂度分析？</h3>

<h3>18丨总结课：数据结构、编程语句和基础算法体现了哪些数学思想？</h3>

<h2>04-概率统计篇 (14讲)</h2>

<h3>19丨概率和统计：编程为什么需要概率和统计？</h3>

<h3>20丨概率基础（上）：一篇文章帮你理解随机变量、概率分布和期望值</h3>

<h4>随机变量</h4>

<h4>概率分布</h4>

<ol>
<li>离散概率分布：伯努利分布、分类分布、二项分布、泊松分布

<ol>
<li>伯努利分布：二分类分布</li>
<li>分类分布：随机变量的取值空间为<code>n</code>个离散的值，<code>n=2</code>时就是伯努利分布。</li>
</ol>
</li>
<li>连续概率分布：正态分布、均匀分布、指数分布、拉普拉斯分布

<ol>
<li>正态分布：也叫高斯分布，有两个关键参数：均值和方差。</li>
</ol>
</li>
</ol>


<h4>期望值</h4>

<p>均值是期望值的特例，即各个取值的概率相同。</p>

<h3>21丨概率基础（下）：联合概率、条件概率和贝叶斯法则，这些概率公式究竟能做什么？</h3>

<h4>联合概率</h4>

<p>由多个随机变量决定的概率我们就叫联合概率，使用<code>P(x, y)</code>表示。</p>

<h4>边缘概率</h4>

<p>联合概率和单个随机变量的概率之间有什么关联呢？对于离散型随机变量，我们可以通过通过联合概率<code>P(x, y)</code>在<code>y</code>上求和，就可以得到<code>P(x)</code>。对于连续型随机变量，我们可以通过联合概率<code>P(x, y)</code>在<code>y</code>上的积分，推导出概率<code>P(x)</code>。这个时候，我们称<code>P(x)</code>为<strong>边缘概率</strong>。</p>

<h4>条件概率</h4>

<p>条件概率也是由多个随机变量决定，但是和联合概率不同的是，它计算了给定某个（或多个）随机变量的情况下，另一个（或多个）随机变量出现的概率，其概率分布叫做条件概率分布。给定随机变量<code>x</code>，随机变量<code>y</code>的条件概率使用<code>P(y|x)</code>表示。</p>

<h4>贝叶斯法则</h4>

<p>条件概率、联合概率之间的关系如下：
<code>P(x,y) = P(x|y) * P(y)</code></p>

<p>根据上面的关系，可以得到贝叶斯定理如下：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86.png" alt="20220531贝叶斯定理.png" /></p>

<ol>
<li>先验概率： 我们把<code>P(x)</code>称为先验概率。之所以称为“先验”，是因为它是从数据资料统计得到的，不需要经过贝叶斯定理的推算。</li>
<li>条件概率（似然函数）：<code>P(y|x)</code>是给定<code>x</code>之后<code>y</code>出现的条件概率。在统计学中，我们也把<code>P(y|x)</code>写作似然函数<code>L(x|y)</code>。在数学里，似然函数和概率是有区别的。概率是指已经知道模型的参数来预测结果，而似然函数是根据观测到的结果数据，来预估模型的参数。不过，当<code>y</code>值给定的时候，两者在数值上是相等的，在应用中我们可以不用细究。</li>
<li>边缘概率：我们没有必要事先知道<code>P(y)</code>。<code>P(y)</code>可以通过联合概率<code>P(x,y)</code>计算边缘概率得来，而联合概率<code>P(x,y)</code>可以由<code>P(y|x)</code>*<code>P(x)</code>推出。</li>
<li>后验概率：<code>P(x|y)</code>是根据贝叶斯定理，通过先验概率<code>P(x)</code>、似然函数<code>P(y|x)</code>和边缘概率<code>P(y)</code>推算而来，因此我们把它称作后验概率。</li>
</ol>


<p>如果有一定数量的标注数据，那么通过统计的方法，我们可以很方便地得到先验概率和似然函数，然后推算出后验概率，最后依据后验概率来做预测。这整个过程符合监督式机器学习的模型训练和新数据预测这两个阶段，因此朴素贝叶斯算法被广泛运用在机器学习的分类问题中。</p>

<h4>随机变量之间的独立性</h4>

<p>如果随机变量<code>x</code>和<code>y</code>之间不相互影响，那么我们就说<code>x</code>和<code>y</code>相互独立。此时，有<code>P(x|y)=P(x)</code>，所以<code>P(x,y)=P(x)*P(y)</code>。</p>

<p>变量之间的独立性，可以帮我们简化计算。</p>

<p>举个例子，假设有6个随机变量，而每个变量有10种可能的取值，那么计算它们的联合概率<code>p(x1,x2,x3,x4,x5,x6)</code>，在实际中是非常困难的一件事情。</p>

<p>根据排列，可能的联合取值，会达到10的6次方，也就是100万这么多。那么使用实际的数据进行统计时，我们也至少需要这个数量级的样本，否则的话很多联合概率分布的值就是0，产生了数据稀疏的问题。但是，如果假设这些随机变量都是相互独立的，那么我们就可以将联合概率<code>p(x1,x2,x3,x4,x5,x6)</code>转换为<code>p(x1)*p(x2)*p(x3)*p(x4)*p(x5)*p(x6)</code>。如此一来，我们只需要计算<code>p(x1)</code>到<code>p(x6)</code>就行了。</p>

<h3>22丨朴素贝叶斯：如何让计算机学会自动分类？</h3>

<h4>训练样本</h4>

<p>贝叶斯分类需要的训练样本如下：
<img src="http://hongchaozhang.github.io/images/20220531%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC.png" alt="20220531训练样本" /></p>

<h4>训练</h4>

<p>贝叶斯定理的核心思想：<strong>用先验概率和条件概率估计后验概率</strong>。</p>

<p>具体到这里的分类问题，贝叶斯公式可以写成这样：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%85%AC%E5%BC%8F.png" alt="20220531贝叶斯分类公式.png" /></p>

<p>其中<code>c</code>表示一个分类（class）, <code>f</code>表示属性对应的数据字段（field）。如此一来，等号左边的<code>P(c|f)</code>就是待分类样本中，出现属性值<code>f</code>时，样本属于类别<code>c</code>的概率。而等号右边的<code>P(f|c)</code>是根据训练数据统计，得到分类<code>c</code>中出现属性<code>f</code>的概率。<code>P(c)</code>是分类<code>c</code>在训练数据中出现的概率，<code>P(f)</code>是属性<code>f</code>在训练样本中出现的概率。</p>

<p>这里的贝叶斯公式只描述了单个属性值属于某个分类的概率，可是我们要分析的水果每个都有很多属性，<strong>朴素贝叶斯</strong>在这里就要发挥作用了。这是基于一个简单假设建立的一种贝叶斯方法，并<strong>假定数据对象的不同属性对其归类影响时是相互独立的</strong>。此时若数据对象<code>o</code>中同时出现属性<code>fi</code>与<code>fj</code>，则对象<code>o</code>属于类别<code>c</code>的概率就是这样：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%85%AC%E5%BC%8F.png" alt="20220531朴素贝叶斯分类公式.png" /></p>

<p>现在，我们应该已经可以用10个水果的数据，来建立朴素贝叶斯模型了。</p>

<p>比如，苹果的分类中共包含3个数据实例，对于形状而言，出现2次不规则圆、1次圆形和0次椭圆形，因此各自的统计概率为0.67、0.33和0.00。我们将这些值称为，给定一个水果分类时，出现某个属性值的<strong>条件概率</strong>。以此类推，所有的统计结果就是下面这个表格中这样：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E8%B4%9D%E5%8F%B6%E6%96%AF%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87.png" alt="20220531贝叶斯训练样本条件概率.png" /></p>

<blockquote><p>对于上表中出现的0.00概率，在做贝叶斯公式中的乘积计算时，会出现结果为0的情况，因此我们通常取一个比这个数据集里最小统计概率还要小的极小值，来代替“零概率”。比如，我们这里取0.01。在填充训练数据中从来没有出现过的属性值的时候，我们就会使用这种技巧，我们给这种技巧起个名字就叫作<strong>平滑</strong>（Smoothing）。</p></blockquote>

<h4>预测</h4>

<p>有了这些条件概率，以及各类水果和各个属性出现的先验概率，我们已经建立起了朴素贝叶斯模型。现在，我们就可以用它进行朴素贝叶斯分类了。</p>

<p>假设我们有一个新的水果，它的形状是圆形，口感是甜的，那么根据朴素贝叶斯，它属于苹果、甜橙和西瓜的概率分别是多少呢？</p>

<p>我们先来计算一下，它属于苹果的概率有多大:</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B%E8%8B%B9%E6%9E%9C%E6%A6%82%E7%8E%87.png" alt="20220531贝叶斯分类预测苹果概率.png" /></p>

<p>其中，<code>apple</code>表示分类为苹果，<code>shape-2</code>表示形状属性的值为<code>2</code>（也就是圆形），<code>taste-2</code>表示口感属性的值为<code>2</code>。以此类推，我们还可计算该水果属于甜橙和西瓜的概率:</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B%E6%A9%99%E5%AD%90%E8%A5%BF%E7%93%9C%E6%A6%82%E7%8E%87.png" alt="20220531贝叶斯分类预测橙子西瓜概率.png" /></p>

<p>比较这三个数值，<code>0.00198&lt;0.00798&lt;0.26934</code>，所以计算机可以得出的结论，该水果属于甜橙的可能性是最大的，或者说，这个水果最有可能是甜橙。</p>

<blockquote><p>这几个公式里的概率乘积通常都非常小，在物品的属性非常多的时候，这个乘积可能就小到计算机无法处理的地步。因此，在实际运用中，我们还会采用一些数学手法进行转换（比如取<code>log</code>将小数转换为绝对值大于<code>1</code>的负数），原理都是一样的。</p></blockquote>

<h4>总结</h4>

<p>总结一次朴素贝叶斯分类的主要步骤：</p>

<ol>
<li>准备数据：针对水果分类这个案例，我们收集了若干水果的实例，并从水果的常见属性入手，将其转化为计算机所能理解的数据。这种数据也被称为<strong>训练样本</strong>。</li>
<li>建立模型：通过手头上水果的实例，我们让计算机统计每种水果、属性出现的先验概率，以及在某个水果分类下某种属性出现的条件概率。这个过程也被称为基于样本的<strong>训练</strong>。</li>
<li>分类新数据：对于一颗新水果的属性数据，计算机根据已经建立的模型进行推导计算，得到该水果属于每个分类的概率，实现了分类的目的。这个过程也被称为<strong>预测</strong>。</li>
</ol>


<h3>23丨文本分类：如何区分特定类型的新闻？</h3>

<p>运用朴素贝叶斯原理，根据词频特征，对文章进行分类。清晰明了，值得一看。</p>

<h3>24丨语言模型：如何使用链式法则和马尔科夫假设简化概率模型？</h3>

<h4>语言模型</h4>

<p>这里说的语言模型指的是基于概率和统计的语言模型。</p>

<h5>链式法则</h5>

<p><img src="http://hongchaozhang.github.io/images/20220531%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99.png" alt="20220531链式法则.png" /></p>

<h5>马尔可夫假设</h5>

<p>理解了链式法则，我们再来看看马尔可夫假设。这个假设的内容是：任何一个词<code>wi</code>出现的概率只和它前面的1个或若干个词有关。基于这个假设，我们可以提出多元文法（Ngram）模型。Ngram中的<code>N</code>很重要，它表示任何一个词出现的概率，只和它前面的<code>N-1</code>个词有关。</p>

<p>以二元文法模型为例，按照刚才的说法，二元文法表示，某个单词出现的概率只和它前面的1个单词有关。也就是说，即使某个单词出现在一个很长的句子中，我们也只需要看前面那1个单词。用公式来表示出来就是这样：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E4%BA%8C%E5%85%83%E6%96%87%E6%B3%95%E6%A8%A1%E5%9E%8B.png" alt="20220531二元文法模型.png" /></p>

<p>假设我们有一个统计样本文本<code>d</code>，<code>s</code>表示某个有意义的句子，由一连串按照特定顺序排列的词<code>w1，w2,…,wn</code>组成，这里<code>n</code>是句子里单词的数量。现在，我们想知道根据文档<code>d</code>的统计数据，<code>s</code>在文本中出现的可能性，即<code>P(s|d)</code>，那么我们可以把它表示为<code>P(s|d)=P(w1,w2,…,wn|d)</code>。假设我们这里考虑的都是在集合<code>d</code>的情况下发生的概率，所以可以忽略<code>d</code>，写为<code>P(s)=P(w1,w2,…,wn)</code>。</p>

<p><code>P(w1,w2,…,wn)</code>可以通过上面说的链式法则计算，通过文档集合<code>C</code>，你可以知道<code>P(w1)</code>，<code>P(w2|w1)</code>这种概率。但是，这会带来两个问题：</p>

<ol>
<li>概率为0的问题
 <code>P(w1)</code>大小还好，<code>P(w2|w1)</code>会小一些，再往后看，<code>P(w3|w1,w2)</code>出现概率更低，<code>P(w4|w1,w2,w3)</code>出现的概率就更低了。一直到<code>P(wn|w1,w2,…,wn−1)</code>，基本上又为0了。我们可以使用上一节提到的平滑技巧，减少0概率的出现。不过，如果太多的概率都是通过平滑的方式而得到的，那么模型和真实的数据分布之间的差距就会加大，最终预测的效果也会很差，所以平滑也不是解决0概率的最终办法。</li>
<li>存储空间的问题
 为了统计现有文档集合中<code>P(w1,w2,…,wn)</code>这类值，我们就需要生成很多的计数器。我们假设文档集合中有<code>m</code>个不同的单词，那么从中挑出<code>n</code>个单词的可重复排列，数量就是<code>m^n</code>。此外，还有<code>m^(n−1)</code>,<code>m^(n−2)</code>等等。这也意味着，如果要统计并存储的所有<code>P(w1,w2,…,wn)</code>或<code>P(wn|w1,w2,…,wn−1)</code>这类概率，就需要大量的内存和磁盘空间。当然，你可以做一些简化，不考虑单词出现的顺序，那么问题就变成了可重复组合，但是数量仍然非常巨大。</li>
</ol>


<p>在这两个问题上，马尔科夫假设和多元文法模型就能帮上大忙了。如果我们使用三元文法模型，上述公式可以改写为：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E4%B8%89%E5%85%83%E6%96%87%E6%B3%95%E6%A8%A1%E5%9E%8B.png" alt="20220531三元文法模型.png" /></p>

<p>这样，系统的复杂度大致在<code>(C(m,1)+C(m,2)+C(m,3))</code>这个数量级，而且<code>P(wn|wn−2,wn−1)</code>为0的概率也会大大低于<code>P(wn|w1,w2,…,wn−1)</code>为0的概率。</p>

<h4>语言模型的应用</h4>

<p>基于概率的语言模型，本身不是新兴的技术。它已经在机器翻译、语音识别和中文分词中得到了成功应用。近几年来，人们也开始在信息检索领域中尝试语言模型。下面我就来讲讲语言模型在信息检索和中文分词这两个方面里是如何发挥作用的。</p>

<h5>信息检索</h5>

<p>信息检索很关心的一个问题就是相关性，也就是说，给定一个查询，哪篇文档是更相关的呢？一种常见的做法是计算<code>P(d|q)</code>，其中<code>q</code>表示一个查询，<code>d</code>表示一篇文档。<code>P(d|q)</code>表示用户输入查询<code>q</code>的情况下，文档<code>d</code>出现的概率是多少？如果这个概率越高，我们就认为<code>q</code>和<code>d</code>之间的相关性越高。</p>

<p>通过我们手头的文档集合，并不能直接获得<code>P(d|q)</code>。好在我们已经学习过了贝叶斯定理，通过这个定理，我们可以将<code>P(d|q)</code>重写如下：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F.png" alt="20220531信息检索贝叶斯公式.png" /></p>

<p>让<code>k1,k2,…,kn</code>表示查询<code>q</code>里包含的<code>n</code>个关键词，就可以根据链式法则求解出<code>P(q|d)</code>，我们也使用马尔科夫假设和多元文法来提高算法效率。</p>

<p>最终，当用户输入一个查询<code>q</code>之后，对于每一篇文档<code>d</code>，我们都能获得<code>P(d|q)</code>的值。根据每篇文档所获得的<code>P(d|q)</code>这个值，由高到低对所有的文档进行排序。这就是语言模型在信息检索中的常见用法。</p>

<h5>中文分词</h5>

<p>和拉丁语系不同，中文存在分词的问题。比如原句是“兵乓球拍卖完了”，分词结果可能是：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>1. 兵乓球|拍卖|完了
</span><span class='line'>2. 兵乓|球拍|卖完|了
</span><span class='line'>3. ...</span></code></pre></td></tr></table></div></figure>


<p>上面分词的例子，从字面来看都是合理的，所以这种歧义无法通过这句话本身来解决。那么这种情况下，语言模型能为我们做什么呢？我们知道，语言模型是基于大量的语料来统计的，所以我们可以使用这个模型来估算，哪种情况更合理。</p>

<p>假设整个文档集合是<code>D</code>，要分词的句子是<code>s</code>，分词结果为<code>w1,…wn</code>，如果使用三元文法模型，</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E4%B8%89%E5%85%83%E6%96%87%E6%B3%95%E6%A8%A1%E5%9E%8B.png" alt="20220531中文分词三元文法模型.png" /></p>

<blockquote><p>请注意，在信息检索中，我们关心的是每篇文章产生一个句子（也就是查询）的概率，而这里可以是整个文档集合<code>D</code>产生一个句子的概率。</p></blockquote>

<p>语言模型可以帮我们估计某种分词结果，在文档集合中出现的概率。由于不同的分词方法，会导致<code>w1</code>到<code>wn</code>的不同，因此就会产生不同的<code>P(s)</code>。接下来，我们只要取最大的<code>P(s)</code>，并假设这种分词方式是最合理的，就可以在一定程度上解决歧义。</p>

<p>回到“兵乓球拍卖完了”这句话，如果文档集合都是讲述的有关体育用品的销售，而不是拍卖行，那么“兵乓|球拍|卖完|了”这种分词的可能性应该更高。</p>

<h3>25丨马尔科夫模型：从PageRank到语音识别，背后是什么模型在支撑？</h3>

<h4>马尔可夫模型</h4>

<p>在介绍语言模型的时候，我们提到了马尔科夫假设，这个假设是说，每个词出现的概率和之前的一个或若干个词有关。我们换个角度思考就是，<strong>每个词按照一定的概率转移到下一个词</strong>。</p>

<p>如果把词抽象为一个状态，那么我们就可以认为，状态到状态之间是有关联的。前一个状态有一定的概率可以转移到到下一个状态。如果多个状态之间的随机转移满足马尔科夫假设，那么这类随机过程就是一个马尔科夫随机过程。而刻画这类随机过程的统计模型，就是<strong>马尔科夫模型</strong>（Markov Model）。</p>

<p>前面讲多元文法的时候，我提到了二元文法、三元文法。对于二元文法来说，某个词出现的概率只和前一个词有关。对应的，在马尔科夫模型中，如果一个状态出现的概率只和前一个状态有关，那么我们称它为<strong>一阶马尔科夫模型</strong>或者<strong>马尔科夫链</strong>。对应于三元、四元甚至更多元的文法，我们也有二阶、三阶等马尔科夫模型。</p>

<h5>PageRank和马尔可夫链</h5>

<p>Google公司最引以为傲的PageRank链接分析算法，它的核心思想就是基于马尔科夫链。这个算法假设了一个“随机冲浪者”模型，冲浪者从某张网页出发，根据Web图中的链接关系随机访问。在每个步骤中，冲浪者都会从当前网页的链出网页中随机选取一张作为下一步访问的目标。在整个Web图中，绝大部分网页节点都会有链入和链出。那么冲浪者就可以永不停歇地冲浪，持续在图中走下去。我们可以假设每张网页就是一个状态，而网页之间的链接表明了状态转移的方向。这样，我们很自然地就可以使用马尔科夫链来刻画“随机冲浪者”。</p>

<blockquote><ol>
<li>PageRank值：在随机访问的过程中，越是被频繁访问的链接，越是重要。可以看出，每个节点的PageRank值取决于Web图的链接结构。<strong>假如一个页面节点有很多的链入链接，或者是链入的网页有较高的被访问率，那么它也将会有更高的被访问概率</strong>。</li>
<li>PageRank在标准的马尔科夫链上，引入了随机的跳转操作，也就是假设冲浪者不按照Web图的拓扑结构走下去，只是随机挑选了一张网页进行跳转。这样的处理是类比人们打开一张新网页的行为，也是符合实际情况的，避免了信息孤岛的形成。

<h4>隐马尔可夫模型</h4>

<p>马尔可夫模型都是假设每个状态对我们都是已知的，比如在概率语言模型中，一个状态对应了单词“上学”，另一个状态对应了单词“书包”。可是，有没有可能某些状态我们是未知的呢？</p></li>
</ol>
</blockquote>

<p>在某些现实的应用场景中，我们是无法确定马尔科夫过程中某个状态的取值的。这种情况下，最经典的案例就是<strong>语音识别</strong>。使用概率对语音进行识别的过程，和语言模型类似，因此我们可以把每个等待识别的词对应为马尔科夫过程中的一个状态。</p>

<p>计算机只知道某个词的发音，而不知道它具体怎么写，对于这种情况，我们就认为计算机只能观测到每个状态的部分信息，而另外一些信息被“隐藏”了起来。这个时候，我们就需要用隐马尔科夫模型来解决这种问题。隐马尔科夫模型有两层，一层是我们可以观测到的数据，称为“输出层”，另一层则是我们无法直接观测到的状态，称为“隐藏状态层”。如下图：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%E5%9B%BE.jpeg" alt="20220531隐马尔可夫模型图.jpeg" /></p>

<p>那么在这个两层模型示例中，“隐藏状态层”(x1，x2，x3)产生“输出层”(y1，y2，y3)的概率是:</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%87%BA%E5%B1%82%E6%A6%82%E7%8E%87.png" alt="20220531隐马尔可夫模型输出层概率.png" /></p>

<p>语音识别要做的，就是遍历所有可能的状态层，找出最可能产生已知“输出层”的状态层，即为语音识别结果。</p>

<h3>26丨信息熵：如何通过几个问题，测出你对应的武侠人物？</h3>

<p>现在有个小游戏，“测测你是哪个武侠人物”：通过连续的几个问题，确定答题者是武侠人物中的哪一位？</p>

<p>那么，问卷设计者应该如何选择合适的题目，才能在读者回答尽量少的问题的同时，相对准确地测出自己对应于武侠中的哪个人物呢？为了实现这一目的，系统背后需要有这样的一张表格：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E4%BF%A1%E6%81%AF%E7%86%B5%E6%B8%B8%E6%88%8F%E8%A1%A8%E6%A0%BC.png" alt="20220531信息熵游戏表格.png" /></p>

<p>在题目的设计上，我们可能要考虑下面两个问题：
1. 每个问题在人物划分上，是否有着不同的区分能力？
2. 题目的先后顺序会不会直接影响要回答问题的数量？</p>

<h4>问题的区分能力</h4>

<p>每一个问题都会将被测试者划分为不同的人物分组。如果某个问题将属于不同人物分组的被测者，尽可能地划分到了相应的分组，那么我们认为这个问题的区分能力较强。相反，如果某个问题无法将属于不同人物分组的被测者划分开来，那么我们认为这个问题的区分能力较弱。</p>

<p>举个例子，我们先来比较一下“性别”和“智商”这两个属性。</p>

<p>首先，性别属性将武侠人物平均地划分为一半一半，也就是说“男”和“女”出现的先验概率是各 50%。如果我们假设被测试的人群，其男女性别的概率分布也是50%和50%，那么关于性别的测试题，就能将被测者的群体大致等分。</p>

<p>我们再来看智商属性。我们也将武侠人物划分为2个小集合，不过“智商高”的先验概率是 80%，而“智商中等”的先验概率只有 20%。同样，我们假设被测试的人群，其智商的概率分布也是类似地，那么经过关于智商的测试题之后，仍然有 80% 左右的不同人物还是属于同一个集合，并没有被区分开来。因此，我们可以认为关于“智商”的测试题，在对人物进行分组这个问题上，其能力要弱于“性别”的测试题。</p>

<p>这只是对区分能力的一个感性认识，如何对其进行量化呢？这就需要引入<strong>信息量，信息熵，信息增益</strong>等概念。</p>

<h4>信息量</h4>

<p>任何能够减少不确定性的消息，都叫做信息。定性地看，事件的概率越小，不确定性越大，一旦发生带来的信息量也就越大。信息量公式如下：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E4%BF%A1%E6%81%AF%E9%87%8F%E5%85%AC%E5%BC%8F.svg" alt="20220531信息量公式.svg" /></p>

<h4>信息熵</h4>

<p>一个系统的信息熵是其各种状态的信息量的期望：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E4%BF%A1%E6%81%AF%E7%86%B5%E5%85%AC%E7%A4%BA.svg" alt="20220531信息熵公示.svg" /></p>

<p>这个公式和热力学的熵的本质一样，故也称为熵。从公式可知，当各个符号出现的几率相等，即“不确定性”最高时，信息熵最大。故信息可以视为“不确定性”、“不纯净度”或“选择的自由度”的度量。</p>

<p>从集合和分组的角度来说，如果一个集合里的元素趋向于落在同一分组里，那么告诉你某个元素属于哪个分组的信息量就越小，整个集合的熵也越小，换句话说，整个集合就越“纯净”。相反，如果一个集合里的元素趋向于分散在不同分组里，那么告诉你某个元素属于哪个分组的信息量就越大，整个集合的熵也越大，换句话说，整个集合就越“混乱”。</p>

<p>已经知道单个集合的熵是如何计算的了。那么，如果将一个集合划分成多个更小的集合之后，又该如何根据这些小集合，来计算整体的熵呢？之前我们提到了信息量和熵具有加和的性质，所以对于包含多个集合的更大集合，它的信息量期望值是可以通过每个小集合的信息量期望值来推算的。具体来说，我们可以使用如下公式：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E9%9B%86%E5%90%88%E5%88%92%E5%88%86%E4%BF%A1%E6%81%AF%E7%86%B5%E5%85%AC%E5%BC%8F.png" alt="20220531集合划分信息熵公式.png" /></p>

<p>其中，<code>T</code>表示一种划分，<code>Pv</code>表示划分后其中某个小集合，<code>Entropy(Pv)</code>表示某个小集合的熵， 而<code>|Pv|/|P|</code>表示某个小集合出现的概率。</p>

<h4>信息增益</h4>

<p>一个系统的信息增益是指，由于信息量大增加带来的其信息熵的减少:</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E5%85%AC%E5%BC%8F.png" alt="20220531信息增益公式.png" /></p>

<p>其中<code>T</code>表示当前选择的特征，<code>Entropy(P)</code>表示选择特征<code>T</code>之前的熵，<code>Entropy(Pv)</code>表示特征<code>T</code>取值为<code>v</code>分组的熵。减号后面的部分表示选择<code>T</code>做决策之后，各种取值子集合的熵的加权平均（期望）后整体的熵。</p>

<h4>再次回到“武侠人物分类”的小游戏</h4>

<p>我们把这个信息增益的概念放到咱们的小游戏里就是，如果一个测试问题能够将来自不同分组的人物尽量的分开，也就是该划分对应的信息增益越高，那么我们就认为其区分能力越高，提供的信息含量也越多。</p>

<p>我们还是以“性别”和“智商”的两个测试题为例。</p>

<p>在提出任何问题之前，我们无法知道被测者属于哪位武侠人物，因此所有被测者属于同一个集合。假设被测者的概率分布和这10位武侠人物的先验概率分布相同，那么被测者集合的熵为3.32(<code>10*(-1 * 0.1 * log(0.1, 2))</code>)。</p>

<p>通过性别的测试问题对人物进行划分后，我们得到了两个更小的集合，每个小集合都包含5种不同的人物分组，因此每个小集合的熵是2.32(<code>(-1 * 5 * 0.2 * log(0.2, 2))</code>)，两个小集合的整体熵是2.32(<code>0.5 * 2.32 + 0.5 * 2.32</code>)。因此使用性格的测试题后，信息增益是1(<code>3.32 - 2.32</code>)。</p>

<p>而通过智商的测试问题对人物分组后，我们也得到了两个小集合，一个包含了8种人物，另一个包含了2种人物。包含8种人物的小集合其熵是3(<code>(-1* 8 * 0.125 * log(0.125, 2))</code>)，包含<code>2</code>种人物的小集合其熵是1(<code>(-1* 2 * 0.5 * log(0.5, 2))</code>)。两个小集合的整体熵是2.6(<code>0.8 * 3 + 0.2 * 1</code>)。因此使用智商的测试题后，信息增益是0.72(<code>3.32 - 2.6</code>)，低于基于性别的测试。所以，我们可以得出结论，有关性别的测试题比有关智商的测试题更具有区分能力。</p>

<h3>27丨决策树：信息增益、增益比率和基尼指数的运用</h3>

<h4>继续“武侠人物分类”游戏</h4>

<p>还说上面的“武侠人物分类”游戏，被测者们每次回答一道问题，就会被细分到不同的集合，每个细分的集合纯净度就会提高，而熵就会下降。在测试结束的时候，如果所有被测者都被分配到了相应的武侠人物名下，那么每个人物分组都是最纯净的，熵值都为0。于是，测试问卷的过程就转化为“如何将熵从3.32下降到0”的过程。</p>

<p>首先计算各个特征的信息增益：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E6%AD%A6%E4%BE%A0%E4%BA%BA%E7%89%A9%E6%B8%B8%E6%88%8F%E5%90%84%E4%B8%AA%E7%89%B9%E5%BE%81%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A.png" alt="20220531武侠人物游戏各个特征信息增益.png" /></p>

<p>按照信息增益从高到低的顺序选择特征问题：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E6%AD%A6%E4%BE%A0%E4%BA%BA%E7%89%A9%E5%88%86%E7%B1%BB%E5%9B%BE.png" alt="20220531武侠人物分类图.png" /></p>

<p>从这个图可以看出来，对于每种人物的判断，我们至多需要问3个问题，没有必要问全5个问题。比如，对于人物J和C，我们只需要问2个问题。假设读者属于10种武侠人物的概率是均等的，那么我们就可以利用之前介绍的知识，来计算读者需要回答的问题数量之期望值。每种人物出现的概率是0.1，8种人物需要问3个问题，2种人物需要问2个问题，那么回答问题数的期望值是2.8(<code>0.8 * 3 + 0.2 * 2</code>)。</p>

<p>如果我们每次不选熵值最高的问题，而选择熵值最低的问题，那么需要回答的问题的数量期望值为4到5之间。</p>

<h4>决策树</h4>

<p>上述这个过程就体现了训练决策树（Decision Tree）的基本思想。决策树学习属于归纳推理算法之一，适用于分类问题。决定问卷题出现顺序的这个过程，其实就是建立决策树模型的过程，即<strong>训练</strong>过程。</p>

<p>整个构建出来的图就是一个树状结构，这也是“决策树”这个名字的由来。而根据用户对每个问题的答案，从决策树的根节点走到叶子节点，最后来判断其属于何种人物类型，这个过程就是分类新数据的过程，即<strong>预测</strong>过程。</p>

<blockquote><p>有点需要注意的是，问卷案例中的每类武侠人物。都只有一个样本，而在泛化的机器学习问题中，每个类型对应了多个样本。也就是说，我们可以有很多个郭靖，而且每个人的属性并不完全一致，但是它们的分类都是“郭靖”。正是因为这个原因，决策树通常都只能把整体的熵降低到一个比较低的值，而无法完全降到0。这也意味着，训练得到的决策树模型，常常无法完全准确地划分训练样本，只能求到一个近似的解。</p></blockquote>

<h4>几种常见的决策树算法</h4>

<p>采用信息增益来构建决策树的算法被称为<a href="https://zh.wikipedia.org/wiki/ID3%E7%AE%97%E6%B3%95">ID3</a>（Iterative Dichotomiser 3，迭代二叉树3代）。但是这个算法有一个缺点，它一般会优先考虑具有较多取值的特征，因为取值多的特征会有相对较大的信息增益。这是为什么呢？</p>

<p>仔细观察一下信息熵的定义，就能发现背后的原因。更多的取值会把数据样本划分为更多更小的分组，这样熵就会大幅降低，信息增益就会大幅上升。但是这样构建出来的树，很容易导致机器学习中的过拟合现象，不利于决策树对新数据的预测。为了克服这个问题，人们又提出了一个改进版，<a href="https://zh.wikipedia.org/wiki/C4.5%E7%AE%97%E6%B3%95">C4.5算法</a>。</p>

<p>决策树也有不足。这类算法受训练样本的影响很大，比较容易过拟合。在预测阶段，如果新的数据和原来的训练样本差异较大，那么分类效果就会比较差。为此人们也提出了一些优化方案，比如剪枝和随机森林。</p>

<h3>28丨熵、信息增益和卡方：如何寻找关键特征？</h3>

<h4>通过信息增益进行特征选择</h4>

<p>类似于决策树算法。</p>

<h4>通过卡方检验进行特征选择</h4>

<p>在统计学中，我们使用卡方检验来检验两个变量是否相互独立。把它运用到特征选择，我们就可以检验特征与分类这两个变量是否独立。如果两者独立，证明特征和分类没有明显的相关性，特征对于分类来说没有提供足够的信息量。反之，如果两者有较强的相关性，那么特征对于分类来说就是有信息量的，是个好的特征。</p>

<p>为了检验独立性，卡方检验考虑了四种情况的概率：P(fi,cj)、P(fi¯,cj¯)、P(fi,cj¯)和P(fi¯,cj)。</p>

<p>在这四种概率中，P(fi,cj)和P(fi¯,cj¯)表示特征fi和分类cj是正相关的。如果P(fi,cj)很高，表示特征fi的出现意味着属于分类cj的概率更高；如果P(fi¯,cj¯)很高，表示特征fi不出现意味着不属于分类cj的概率更高。</p>

<p>类似地，P(fi,cj¯)和P(fi¯,cj)表示特征fi和分类cj是负相关的。如果P(fi,cj¯)很高，表示特征fi的出现意味着不属于分类cj的概率更高；如果P(fi¯,cj)很高，表示特征fi不出现意味着属于分类cj的概率更高。</p>

<p>如果特征和分类的相关性很高，要么是正向相关值远远大于负向相关值，要么是负向相关值远远大于正向相关值。如果特征和分类相关性很低，那么正向相关值和负向相关的值就会很接近。卡方检验就是利用了正向相关和负向相关的特性。</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9.png" alt="20220531卡方检验进行特征选择.png" /></p>

<p>其中，N表示数据的总个数。通过这个公式，你可以看到，如果一个特征和分类的相关性很高，无论是正向相关还是负向相关，那么正向相关和负向相关的差值就很大，最终计算的值就很高。最后，我们就可以按照卡方检验的值由高到低对特征进行排序，挑选出排列靠前的特征。</p>

<h3>29丨归一化和标准化：各种特征如何综合才是最合理的？</h3>

<p>第一点，为什么有时候需要转换特征值？因为不同类型的特征取值范围不同，分布也不同，相互之间没有可比性。因此在线性回归中，通过这些原始值分析得到的权重，并不能代表每个特征实际的重要性。</p>

<p>我们用Boston Housing 数据集对房价数据进行回归分析，这个数据来自 70 年代美国波斯顿周边地区的房价，是用于机器学习的经典数据集，你可以在<a href="https://www.kaggle.com/c/boston-housing#description">Kaggle的网站</a>下载到它，并查看表格中各列的含义：</p>

<ol>
<li>CRIM：per capita crime rate by town.</li>
<li>ZN：proportion of residential land zoned for lots over 25,000 sq.ft.</li>
<li>INDUS：proportion of non-retail business acres per town.</li>
<li>CHAS：Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).</li>
<li>NOX：nitrogen oxides concentration (parts per 10 million).</li>
<li>RM：average number of rooms per dwelling.</li>
<li>AGE：proportion of owner-occupied units built prior to 1940.</li>
<li>DIS：weighted mean of distances to five Boston employment centres.</li>
<li>RAD：index of accessibility to radial highways.</li>
<li>TAX：full-value property-tax rate per \$10,000.</li>
<li>PTRATIO：pupil-teacher ratio by town.</li>
<li>B：1000(Bk - 0.63)<sup>2</sup> where Bk is the proportion of blacks by town.</li>
<li>LSTAT：lower status of the population (percent).</li>
<li>MEDV：median value of owner-occupied homes in \$1000s.</li>
</ol>


<blockquote><p>Kaggle上面好像不能直接下载啦，可以点击<a href="http://hongchaozhang.github.io/assets/resources/boston_house_price.csv">这里</a>下载。</p></blockquote>

<p>使用下面的python代码实现线性回归分析：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import pandas as pd
</span><span class='line'>from sklearn.linear_model import LinearRegression
</span><span class='line'>
</span><span class='line'>df = pd.read_csv("demo/datasets/boston_house_price.csv")  # 读取 Boston Housing 中的 csv数据
</span><span class='line'>df_features = df.drop(['MEDV'], axis=1)  # Dataframe 中除了最后一列，其余列都是特征，或者说自变量
</span><span class='line'>df_targets = df['MEDV']  # Dataframe 最后一列是目标变量，或者说因变量
</span><span class='line'>#
</span><span class='line'>regression = LinearRegression().fit(df_features, df_targets)  # 使用特征和目标数据，拟合线性回归模型
</span><span class='line'>print(regression.score(df_features, df_targets))  # 拟合程度的好坏
</span><span class='line'>print(regression.coef_)  # 各个特征所对应的系</span></code></pre></td></tr></table></div></figure>


<p>输出结果：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>0.7406426641094095
</span><span class='line'>[-1.08011358e-01  4.64204584e-02  2.05586264e-02  2.68673382e+00
</span><span class='line'> -1.77666112e+01  3.80986521e+00  6.92224640e-04 -1.47556685e+00
</span><span class='line'>  3.06049479e-01 -1.23345939e-02 -9.52747232e-01  9.31168327e-03
</span><span class='line'> -5.24758378e-01]</span></code></pre></td></tr></table></div></figure>


<p>因为不是所有的数据都是可以使用线性回归模型来表示，所以我们需要使用 regression.score 函数，来看拟合的程度。如果完美拟合，这个函数就会输出 1；如果拟合效果很差，这个函数的输出可能就是一个负数。</p>

<p>这里 regression.score 函数的输出大约为 0.74，接近于 1.0。它表示这个数据集使用线性模型拟合的效果还是不错的。</p>

<blockquote><p>注意：下面是原文章中的解释，但是和我下载到的数据跑出的结果匹配不上，但是有关归一化和标准化的作用还是能够看出来的。
原文章中的输出：</p></blockquote>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>0.735578647853312
</span><span class='line'>[-4.54789253e-03 -5.17062363e-02  4.93344687e-02  5.34084254e-02
</span><span class='line'>  3.78011391e+00 -1.54106687e+01  3.87910457e+00 -9.51042267e-03
</span><span class='line'> -1.60411361e+00  3.61780090e-01 -1.14966409e-02 -8.48538613e-01
</span><span class='line'>  1.18853164e-02 -6.01842329e-01]</span></code></pre></td></tr></table></div></figure>


<p>权重可以帮助我们解释哪个特征对最终房价的中位值有更大的影响。参看 csv 中的数据，你会发现最主要的两个正相关特征是 nox（系数为 3.78011391e+00）和 age（系数为 3.87910457e+00）。其中 nox 表示空气污染浓度，age 表示老房子占比，也就是说空气污染越多、房龄越高，房价中位数越高，这好像不太合乎常理。我们再来看看最主要的负相关特征 rm（系数为 -1.54106687e+01），也就是房间数量。房间数量越多，房价中位数越低，也不合理。</p>

<p>造成这些现象最重要的原因是，不同类型的特征值没有转换到同一个可比较的范围内，所以线性回归后所得到的系数不具有可比性，因此我们无法直接对这些权重加以解释。</p>

<h4>归一化（Normalization）</h4>

<p>简单起见，这里的归一化是指使用特征取值范围中的最大值和最小值，把原始值转换为0到1之间的值。这样处理的好处在于简单易行，便于理解。不过，它的缺点也很明显，由于只考虑了最大最小值，因此很容易受到异常数据点的干扰。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>from sklearn.preprocessing import StandardScaler
</span><span class='line'>from sklearn.preprocessing import MinMaxScaler
</span><span class='line'>
</span><span class='line'>minMaxScaler = MinMaxScaler()  # 基于 min 和 max 值的归一化
</span><span class='line'>
</span><span class='line'>df = pd.read_csv("demo/datasets/boston_house_price.csv")  # 读取 Boston Housing 中的 csv的数据
</span><span class='line'>df_normalized = minMaxScaler.fit_transform(df)  # 对原始数据进行归一化，包括特征值和目标变量
</span><span class='line'>df_features_normalized = df_normalized[:, 0:-1]  # 获取归一化之后的特征值
</span><span class='line'>df_targets_normalized = df_normalized[:, -1]  # 获取归一化之后的目标值
</span><span class='line'>
</span><span class='line'># 再次进行线性回归
</span><span class='line'>regression_normalized = LinearRegression().fit(df_features_normalized, df_targets_normalized)
</span><span class='line'>print(regression_normalized.score(df_features_normalized, df_targets_normalized))
</span><span class='line'>print(regression_normalized.coef_)</span></code></pre></td></tr></table></div></figure>


<p>输出：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>0.7406426641094094
</span><span class='line'>[-0.21355017  0.10315657  0.0124631   0.0597052  -0.1918794   0.4418597
</span><span class='line'>  0.00149367 -0.36059247  0.15642529 -0.14362949 -0.19901831  0.08206283
</span><span class='line'> -0.42260541]</span></code></pre></td></tr></table></div></figure>


<blockquote><p>注意：下面是原文章中的解释，但是和我下载到的数据跑出的结果匹配不上，但是有关归一化和标准化的作用还是能够看出来的。
原文章中的输出：</p></blockquote>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>0.7355786478533118
</span><span class='line'>[-0.05103746 -0.08448544  0.10963215  0.03204506  0.08400253 -0.16643522
</span><span class='line'>  0.4451488  -0.01986622 -0.34152292  0.18490982 -0.13361651 -0.16216516
</span><span class='line'>  0.10390408 -0.48468369]</span></code></pre></td></tr></table></div></figure>


<p>你可以看到，表示拟合程度的分数没有变，但是每个特征对应的系数或者说权重，发生了比较大的变化。仔细观察一下，你会发现，这次最主要的正相关特征是 age（0.4451488）和 tax（0.18490982），也就是老房子占比和房产税的税率，其中至少房产税的税率是比较合理的，因为高房价的地区普遍税率也比较高。而最主要的负相关特征是 rad（-0.34152292）和 lstat（-0.48468369），rad 表示高速交通的便利程度，它的值越大表示离高速越远，房价中位数越低。而 lstat 表示低收入人群的占比，这个值越大房价中位数越低，这两点都是合理的。</p>

<h4>标准化（Standardizaiton）</h4>

<p>另一种常见的方法是基于正态分布的 z 分数（z-score）标准化（Standardization）。该方法假设数据呈现标准正态分布。</p>

<p>经过标准化处理之后，每种特征的取值都会变成一个标准正态分布，以0为均值，1为标准差。和归一化相比，标准化使用了数据是正态分布的假设，不容易受到过大或过小值的干扰。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>standardScaler = StandardScaler()  # 基于 Z 分数的标准化
</span><span class='line'>
</span><span class='line'>df = pd.read_csv("demo/datasets/boston_house_price.csv")  # 读取 Boston Housing 中的 csv的数据
</span><span class='line'>print(df)
</span><span class='line'>standardScaler.fit(df)
</span><span class='line'>df_standardized = standardScaler.transform(df)  # 对原始数据进行标准化，包括特征值和目标变量
</span><span class='line'>print(df_standardized)
</span><span class='line'>
</span><span class='line'>df_features_standardized = df_standardized[:, 0:-1]  # 获取标准化之后的特征值
</span><span class='line'>df_targets_standardized = df_standardized[:, -1]  # 获取标准化之后的特征值
</span><span class='line'>
</span><span class='line'># 再次进行线性回归
</span><span class='line'>regression_standardized = LinearRegression().fit(df_features_standardized, df_targets_standardized)
</span><span class='line'>print(regression_standardized.score(df_features_standardized, df_targets_standardized))
</span><span class='line'>print(regression_standardized.coef_)</span></code></pre></td></tr></table></div></figure>


<p>输出：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>0.7406426641094093
</span><span class='line'>[-0.10101708  0.1177152   0.0153352   0.07419883 -0.22384803  0.29105647
</span><span class='line'>  0.00211864 -0.33783635  0.28974905 -0.22603168 -0.22427123  0.09243223
</span><span class='line'> -0.40744693]</span></code></pre></td></tr></table></div></figure>


<blockquote><p>注意：下面是原文章中的解释，但是和我下载到的数据跑出的结果匹配不上，但是有关归一化和标准化的作用还是能够看出来的。
原文章中的输出：</p></blockquote>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>0.7355786478533118
</span><span class='line'>[-0.07330367 -0.04144107  0.12194378  0.04074345  0.09805446 -0.19311408
</span><span class='line'>  0.29767387 -0.02916672 -0.34642803  0.34477088 -0.21410757 -0.19904179
</span><span class='line'>  0.11218058 -0.46369483]</span></code></pre></td></tr></table></div></figure>


<p>表示拟合程度的分数任然没有变。再次对比不同特征所对应的系数，你会发现这次最主要的正相关特征还是 age（0.29767387）和 tax（0.34477088），但是相比之前，明显房产税的税率占了更高的权重，更加合理。而最主要的负相关特征还是 rad（-0.34152292）和 lstat（-0.48468369），这两点都是合理的。</p>

<h3>30丨统计意义（上）：如何通过显著性检验，判断你的A-B测试结果是不是巧合？</h3>

<ol>
<li>显著性差异</li>
<li>统计假设检验和显著性检验</li>
<li>P值</li>
</ol>


<h3>31丨统计意义（下）：如何通过显著性检验，判断你的A-B测试结果是不是巧合？</h3>

<p>对于正态分布的数据，可以采用方差分析（Analysis of Variance, ANOVA），也叫F检验。有了F值，我们需要根据F检验值的临界表来查找对应的P值。</p>

<p>对于非正态分布的数据，我们也可以使用非参数的分析。常见的非参数检验包括二项分布检验、K-S 检验、卡方检验等等。</p>

<h3>32丨概率统计篇答疑和总结为什么会有欠拟合和过拟合？</h3>

<h4>什么是欠拟合/过拟合</h4>

<p>在监督式学习过程中，适度拟合、欠拟合和过拟合，这三种状态是逐步演变的。</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E6%AC%A0%E6%8B%9F%E5%90%88%E8%BF%87%E6%8B%9F%E5%90%88.png" alt="20220531欠拟合过拟合.png" /></p>

<h4>如何处理欠拟合和过拟合？</h4>

<h5>欠拟合</h5>

<p>欠拟合问题，产生的主要原因是特征维度过少，拟合的模型不够复杂，无法满足训练样本，最终导致误差较大。因此，我们就可以增加特征维度，让输入的训练样本具有更强的表达能力。</p>

<p>之前讲解朴素贝叶斯的时候，我提到“任何两个变量是相互独立的假设”，这种假设和马尔科夫假设中的一元文法的作用一致，是为了降低数据稀疏程度、节省计算资源所采取的措施。可是，这种假设在现实中往往不成立，所以朴素贝叶斯模型的表达能力是非常有限的。当我们拥有足够的计算资源，而且希望建模效果更好的时候，我们就需要更加精细、更加复杂的模型，我们完全可以放弃朴素贝叶斯中关于变量独立性的假设，而使用二元、三元甚至更大的 N 元文法来处理这些数据。这就是典型的通过增加更多的特征，来提升模型的复杂度，让它从欠拟合阶段往适度拟合阶段靠拢。</p>

<h5>过拟合</h5>

<p>过拟合问题产生的主要原因则是特征维度过多，导致拟合的模型过于完美地符合训练样本，但是无法适应测试样本或者说新的数据。所以我们可以减少特征的维度。</p>

<p>之前在介绍决策树的时候，我提到了这类算法比较容易过拟合，可以使用剪枝和随机森林来缓解这个问题。</p>

<p>剪枝，顾名思义，就是删掉决策树中一些不是很重要的结点及对应的边，这其实就是在减少特征对模型的影响。虽然去掉一些结点和边之后，决策树对训练样本的区分能力变弱，但是可以更好地应对新数据的变化，具有更好的泛化能力。至于去掉哪些结点和边，我们可以使用前面介绍的特征选择方法来进行。</p>

<p>随机森林的构建过程更为复杂一些。“森林”表示有很多决策树，可是训练样本就一套，那这些树都是怎么来的呢？随机森林算法采用了统计里常用的可重复采样法，每次从全部 n 个样本中取出 m 个，然后构建一个决策树。重复这种采样并构建决策树的过程若干次，我们就能获得多个决策树。对于新的数据，每个决策树都会有自己的判断结果，我们取大多数决策树的意见作为最终结果。由于每次采样都是不完整的训练集合，而且有一定的随机性，所以每个决策树的过拟合程度都会降低。</p>

<p>从另一个角度来看，过拟合表示模型太复杂，而相对的训练数据量太少。因此我们也可以增加训练样本的数据量，并尽量保持训练数据和测试数据分布的一致性。如果我们手头上有大量的训练数据，则可以使用交叉验证（Cross Validation）的划分方式来保持训练数据和测试数据的一致性。其核心思想是在每一轮中，拿出大部分数据实例进行建模，然后用建立的模型对留下的小部分实例进行预测，最终对本次预测结果进行评估。这个过程反复进行若干轮，直到所有的标注样本都被预测了一次而且仅一次。如果模型所接受的数据总是在变化，那么我们就需要定期更新训练样本，重新拟合模型。</p>

<h2>05-线性代数篇 (13讲)</h2>

<h3>33丨线性代数：线性代数到底都讲了些什么？</h3>

<h4>标量，向量，向量空间</h4>

<h4>向量运算</h4>

<p>向量运算的几何意义</p>

<h4>矩阵运算</h4>

<p>乘法，转置，单位矩阵，逆矩阵</p>

<h3>34丨向量空间模型：如何让计算机理解现实事物之间的关系？</h3>

<h4>向量空间模型</h4>

<ol>
<li>向量之间的距离</li>
<li>向量的长度</li>
<li>向量之间的夹角，夹角余弦</li>
</ol>


<h4>向量空间模型与机器学习</h4>

<p>由于夹角余弦的取值范围已经在-1到1之间，而且越大表示越相似，所以可以直接作为相似度的取值。相对于夹角余弦，欧氏距离<code>ED</code>的取值范围可能很大，而且和相似度呈现反比关系，所以通常要进行<code>1/(1-ED)</code>这种归一化。</p>

<p>当ED为0的时候，变化后的值就是1，表示相似度为1，完全相同。当ED趋向于无穷大的时候，变化后的值就是0，表示相似度为0，完全不同。所以，这个变化后的值，取值范围是0到1之间，而且和相似度呈现正比关系。</p>

<p>早在上世纪的70年代，人们把向量空间模型运用于信息检索领域。由于向量空间可以很形象地表示数据点之间的相似程度，因此现在我们也常常把这个模型运用在基于相似度的一些机器学习算法中，例如K近邻（KNN）分类、K均值（K-Means)聚类等等。</p>

<h3>35丨文本检索：如何让计算机处理自然语言？</h3>

<h3>36丨文本聚类：如何过滤冗余的新闻？</h3>

<h3>37丨矩阵（上）：如何使用矩阵操作进行PageRank计算？</h3>

<p>我们可以把向量看作一维数组，把矩阵看作二维数组。矩阵的点乘，是由若干个向量的点乘组成的，所以我们可以通过矩阵的点乘操作，挖掘多组向量两两之间的关系。</p>

<p>我们讲了矩阵的点乘操作在PageRank算法中的应用。通过表示网页的邻接二元关系，我们可以使用矩阵来计算PageRank的得分。在这个应用场景下，矩阵点乘体现了多个马尔科夫过程中的状态转移。</p>

<p>矩阵点乘和其他运算操作，还可以运用在很多其他的领域。例如，我在上一节介绍K均值聚类算法时，就提到了需要计算某个数据点向量、其他数据点向量之间的距离或者相似度，以及使用多个数据点向量的平均值来获得质心点的向量，这些都可以通过矩阵操作来完成。</p>

<p>另外，在协同过滤的推荐中，我们可以使用矩阵点乘，来实现多个用户或者物品之间的相似程度，以及聚集后的相似程度所导致的最终推荐结果。下一节，我会使用矩阵来表示用户和物品的二元关系，并通过矩阵来计算协同过滤的结果。</p>

<h3>38丨矩阵（下）：如何使用矩阵操作进行协同过滤推荐？</h3>

<p>矩阵中的二维关系，除了可以表达图的邻接关系，还可以表达推荐系统中用户和物品的关系。这个关系是推荐系统的核心。</p>

<p>我们用矩阵 X 来表示用户对物品喜好程度：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.png" alt="20220531协同过滤推荐系统.png" /></p>

<p>其中第<code>i</code>行是第<code>i</code>个用户的数据，而第<code>j</code>列是用户对第<code>j</code>格物品的喜好程度。我们用<code>xij</code>表示这个数值。这里的喜好程度可以是用户购买商品的次数、对书籍的评分等等。</p>

<p>假设我们用一个0到1之间的小数表示。有了这种矩阵，我们就可以通过矩阵的操作，充分挖掘用户和物品之间的关系。下面，我会使用经典的协同过滤算法，来讲解矩阵在其中的运用。</p>

<h4>基于用户的协同过滤</h4>

<p><img src="http://hongchaozhang.github.io/images/20220531%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7.png" alt="20220531协同过滤基于用户.png" /></p>

<p>根据这张图的访问关系来看，用户A访问了物品A和C，用户B访问了物品B，用户C访问了物品A，C和D。我们计算出来，用户C是A的近邻，而B不是。因此系统会更多地向用户A推荐用户C访问的物品D。</p>

<p>基于用户的协同过滤的核心公式如下：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E5%85%AC%E5%BC%8F1.png" alt="20220531基于用户协同过滤公式1.png" /></p>

<ol>
<li>第一个公式是计算用户和用户之间的相似度。完成了这一步我们就能找到给定用户的“近邻”。</li>
<li>第二个公式利用第一个公式所计算的用户间相似度，以及用户对物品的喜好度，预测任一个用户对任一个物品的喜好度。其中<code>pij</code>表示第<code>i</code>用户对第<code>j</code>个物品的喜好度。</li>
</ol>


<h4>基于物品的过滤</h4>

<p>基于物品的协同过滤是指利用物品相似度，而不是用户间的相似度来计算预测值。</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E5%9B%BE.png" alt="20220531基于物品的协同过滤图.png" /></p>

<p>在这张图中，物品A和C因为都被用户A和B同时访问，因此它们被认为相似度更高。当用户C访问过物品A后，系统会更多地向用户推荐物品C，而不是其他物品。</p>

<p>基于用户的协同过滤同样有两个公式:</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E5%85%AC%E5%BC%8F.png" alt="20220531基于物品的协同过滤公式.png" /></p>

<ol>
<li>第一个公式的核心思想是计算物品和物品之间的相似度。</li>
<li>第二个公式利用第一个公式所计算的物品间相似度，和用户对物品的喜好度，预测任一个用户对任一个物品的喜好度。</li>
</ol>


<p>协同过滤的公式（基于用户/物品）都可以用矩阵操作表达。</p>

<h4>总结</h4>

<p>今天我首先简要地介绍了推荐系统的概念和主要思想。为了给用户提供可靠的结果，推荐系统需要充分挖掘历史数据中，用户和物品之间的关系。协同过滤的推荐算法就很好地体现了这一点。</p>

<p>一旦涉及用户和物品的这种二元关系，矩阵就有用武之地了。我通过矩阵来表示用户和物品的关系，并通过矩阵计算来获得协同过滤的结果。协同过滤分为基于用户的过滤和基于物品的过滤两种，它们的核心思想都是相同的，因此矩阵操作也是类似的。在这两个应用场景下，矩阵点乘体现了多个用户或者物品之间的相似程度，以及聚集后的相似程度所导致的最终推荐结果。</p>

<p>当然，基于用户和物品间关系的推荐算法有很多，对矩阵的操作也远远不止点乘、按行求和、元素对应乘除法。我后面会介绍如何使用矩阵的主成分分析或奇异值分解，来进行物品的推荐。</p>

<h3>39丨线性回归（上）：如何使用高斯消元求解线性方程组？</h3>

<h4>高斯消元</h4>

<p>矩阵操作实现高斯消元求解线性方程组。</p>

<p>高斯消元法主要包含了消元和回代两个步骤。这些步骤都可以使用矩阵的操作来进行。从矩阵的角度来说，消元就是把系数矩阵变为上三角矩阵，而回代是把这个上三角矩阵变为单位矩阵。我们可以直接把用于消元和回代的矩阵，用于由系数和因变量值组成的增广矩阵，并获得最终的方程解。</p>

<h4>线性方程组与线性回归分析</h4>

<p>线性方程组的概念，也是线性回归分析的基础。它们有两个最主要的区别。</p>

<ol>
<li>第一个区别是，在线性回归分析中，样本数据会告诉我们自变量和因变量的值，要求的是系数。而在线性方程组中，我们已知系数和因变量的值，要求的是自变量的值。</li>
<li>第二个区别是，在线性回归分析中，方程的数量要远远大于自变量的数量，而且我们不要求每个方程式都是完全成立。这里，不要求完全成立的意思是，拟合出来的因变量值可以和样本数据给定的因变量值存在差异，也就允许模型拟合存在误差。模型拟合的概念我在上一模块的总结篇中重点讲解了，所以你应该能理解，模型的拟合不可能 100% 完美，这和我们求解线性方程组精确解的概念是不同的。</li>
</ol>


<p>正是因为这两点差异，我们无法直接使用消元法来求解线性回归，而是使用最小二乘法来解决线性回归的问题。</p>

<h3>40丨线性回归（中）：如何使用最小二乘法进行直线拟合？</h3>

<h3>41丨线性回归（下）：如何使用最小二乘法进行效果验证？</h3>

<p>从广义上来说，最小二乘法不仅可以用于线性回归，还可以用于非线性的回归。其主要思想还是要确保误差ε最小，但是由于现在的函数是非线性的，所以不能使用求多元方程求解的办法来得到参数估计值，而需要采用迭代的优化算法来求解，比如梯度下降法、随机梯度下降法和牛顿法。</p>

<h3>42丨PCA主成分分析（上）：如何利用协方差矩阵来降维？</h3>

<p>在概率统计模块，我详细讲解了如何使用各种统计指标来进行特征的选择，降低用于监督式学习的特征之维度。接下来的几节，我会阐述两种针对数值型特征，更为通用的降维方法，它们是主成分分析 PCA（Principal Component Analysis）和奇异值分解 SVD（Singular Value Decomposition）。这两种方法是从矩阵分析的角度出发，找出数据分布之间的关系，从而达到降低维度的目的。</p>

<h4>PCA 分析法的主要步骤</h4>

<p>对于m×n维的样本矩阵，其中每一行表示一个样本，而每一列表示一维特征。现在，我们的问题是，能不能通过某种方法，找到一种变换，可以降低这个矩阵的列数，也就是特征的维数，并且尽可能的保留原始数据中有用的信息？</p>

<p>针对这个问题，PCA 分析法提出了一种可行的解决方案。它包括了下面这样几个主要的步骤：</p>

<ol>
<li>标准化样本矩阵中的原始数据；</li>
<li>获取标准化数据的协方差矩阵；</li>
<li>计算协方差矩阵的特征值和特征向量；</li>
<li>依照特征值的大小，挑选主要的特征向量；</li>
<li>生成新的特征。</li>
</ol>


<h4>标准化原始数据</h4>

<p>之前我们已经介绍过特征标准化，这里我们需要进行同样的处理，才能让每维特征的重要性具有可比性。需要注意的是，这里标准化的数据是针对同一种特征，也是在同一个特征维度之内。不同维度的特征不能放在一起进行标准化。</p>

<h4>获取协方差矩阵</h4>

<p>首先，来看一下什么是<a href="https://zh.m.wikipedia.org/zh-sg/%E5%8D%8F%E6%96%B9%E5%B7%AE">协方差</a>（Covariance），以及<a href="https://zh.m.wikipedia.org/zh-sg/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5">协方差矩阵</a>。</p>

<p><strong>协方差</strong>是用于衡量两个变量的总体误差。假设两个变量分别是 x 和 y，而它们的采样数量都是 m，那么协方差的计算公式就是如下这种形式：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E5%8D%8F%E6%96%B9%E5%B7%AE%E5%85%AC%E5%BC%8F.png" alt="20220531协方差公式.png" /></p>

<p>而当两个变量是相同时，协方差就变成了方差。</p>

<p>对于m×n维的样本矩阵，其<strong>协方差矩阵</strong>（i,j)位置处的值表示第i个特征（列向量）和第j个特征（列向量）之间的协方差，公式如下：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5ij%E4%BD%8D%E7%BD%AE%E5%85%83%E7%B4%A0.png" alt="20220531协方差矩阵ij位置元素.png" /></p>

<p>所以，样本矩阵的协方差矩阵就可以表示为：</p>

<p><img src="http://hongchaozhang.github.io/images/20220531%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5%E5%85%AC%E5%BC%8F.png" alt="20220531协方差矩阵公式.png" /></p>

<p>从协方差的定义可以看出，协方差矩阵是个对称矩阵。另外，这个对称矩阵的主对角线上的值就是各维特征的方差。</p>

<h4>计算协方差矩阵的特征值和特征向量</h4>

<p>需要注意的是，这里所说的矩阵的特征向量，和机器学习中的特征向量（Feature Vector）完全是两回事。矩阵的特征值和特征向量是线性代数中两个非常重要的概念。对于一个矩阵X，如果能找到向量v和标量λ，使得下面这个式子成立。</p>

<p><code>Xv=λv</code></p>

<p>那么，我们就说v是矩阵X的特征向量，而λ是矩阵X的特征值。矩阵的特征向量和特征值可能不止一个。说到这里，你可能会好奇，特征向量和特征值表示什么意思呢？我们为什么要关心这两个概念呢？简单的来说，我们可以把向量v左乘一个矩阵X看做对v进行旋转或拉伸，而这种旋转和拉伸都是由于左乘矩阵X后，所产生的“运动”所导致的。特征向量v表示了矩阵X运动的方向，特征值λ表示了运动的幅度，这两者结合就能描述左乘矩阵X所带来的效果，因此被看作矩阵的“特征”。在PCA中的主成分，就是指特征向量，而对应的特征值的大小，就表示这个特征向量或者说主成分的重要程度。特征值越大，重要程度越高，我们要优先现在这个主成分，并利用这个主成分对原始数据进行变换。</p>

<h4>挑选主要的特征向量，转换原始数据</h4>

<p>假设我们获得了k个特征值和对应的特征向量，按照所对应的λ数值的大小，对这k组的特征向量进行排序。排名靠前的特征向量就是最重要的特征向量。</p>

<p>假设我们只取前k1个最重要的特征，那么我们使用这k1个特征向量，组成一个n×k1维的矩阵D。</p>

<p>把包含原始数据的m×n维矩阵X左乘矩阵D，就能重新获得一个m×k1维的矩阵，达到了降维的目的。</p>

<p>有的时候，我们无法确定k1取多少合适。一种常见的做法是，看前k1个特征值的和占所有特征值总和的百分比。假设一共有10个特征值，总和是100，最大的特征值是80，那么第一大特征值占整个特征值之和的80%，我们认为它能表示80%的信息量，还不够多。那我们就继续看第二大的特征值，它是15，前两个特征值之和有95，占比达到了95%，如果我们认为足够了，那么就可以只选前两大特征值，把原始数据的特征维度从10维降到2维。</p>

<h3>43丨PCA主成分分析（下）：为什么要计算协方差矩阵的特征值和特征向量？</h3>

<p>这一部分分析的太到位了，将原文链接放上：<a href="http://hongchaozhang.github.io/assets/resources/43%E4%B8%A8PCA%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%AE%A1%E7%AE%97%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%EF%BC%9F.html">PCA主成分分析（下）：为什么要计算协方差矩阵的特征值和特征向量？</a>。</p>

<h4>基于Python的案例分析</h4>

<p>通过基于Python的案例来一步步计算PCA的各个步骤的中间结果。</p>

<h4>PCA背后的核心思想</h4>

<p><strong>为什么要使用协方差矩阵？</strong></p>

<p>为什么我们要使用样本数据中，各个维度之间的协方差，来构建一个新的协方差矩阵？要弄清楚这一点，首先要回到PCA最终的目标：降维。降维就是要去除那些表达信息量少，或者冗余的维度。</p>

<ol>
<li>我们首先来看如何定义维度的<strong>信息量</strong>大小。这里我们认为样本在某个特征上的差异越大，这个特征包含的信息量就越大，就越重要。很自然，我们就能想到使用某维特征的方差来定义样本在这个特征维度上的差异。</li>
<li>另一方面，我们要看如何发现冗余的信息。如果两种特征是有很高的相关性，那我们可以从一个维度的值推算出另一个维度的值，所表达的信息就是重复的。在实际运用中，我们可以使用皮尔森（Pearson）相关系数，来描述两个变量之间的线性相关程度。这个系数的取值范围是<code>[−1,1]</code>，绝对值越大，说明相关性越高，正数表示正相关，负数表示负相关。在本质上，皮尔森相关系数和数据标准化后的协方差是一致的。</li>
</ol>


<p>考虑到协方差既可以衡量信息量的大小，也可以衡量不同维度之间的相关性，因此我们就使用各个维度之间的协方差所构成的矩阵，作为PCA分析的对象。就如前面说讲述的，这个协方差矩阵主对角线上的元素是各维度上的方差，也就体现了信息量，而其他元素是两两维度间的协方差，也就体现了相关性。</p>

<p>既然协方差矩阵提供了我们所需要的方差和相关性，那么下一步，我们就要考虑对这个矩阵进行怎样的操作了。</p>

<p><strong>为什么要计算协方差矩阵的特征值和特征向量？</strong></p>

<p>关于这点，我们可以从两个角度来理解。</p>

<p>第一个角度是对角矩阵。所谓对角矩阵，就是说只有矩阵主对角线之上的元素有非0值，而其他元素的值都为0。我们刚刚解释了协方差矩阵的主对角线上，都是表示信息量的方差，而其他元素都是表示相关性的协方差。既然我们希望尽可能保留大信息量的维度，而去除相关的维度，那么就意味着我们希望对协方差进行对角化，尽可能地使得矩阵只有主对角线上有非0元素。</p>

<p>假如我们确实可以把矩阵尽可能的对角化，那么对角化之后的矩阵，它的主对角线上元素就是、或者接近矩阵的特征值，而特征值本身又表示了转换后的方差，也就是信息量。而此时，对应的各个特征向量之间是基本正交的，也就是相关性极低甚至没有相关性。</p>

<p>第二个角度是特征值和特征向量的几何意义。在向量空间中，对某个向量左乘一个矩阵，实际上是对这个向量进行了一次变换。在这个变换的过程中，被左乘的向量主要发生旋转和伸缩这两种变化。<strong>如果左乘矩阵对某一个向量或某些向量只发生伸缩变换，不对这些向量产生旋转的效果，那么这些向量就称为这个矩阵的特征向量，而伸缩的比例就是特征值</strong>。换句话来说，某个矩阵的特征向量表示了这个矩阵在空间中的变换方向，这些方向都是趋于正交的，而特征值表示每个方向上伸缩的比例。</p>

<p>如果一个特征值很大，那么说明在对应的特征向量所表示的方向上，伸缩幅度很大。这也是为什么，我们需要使用原始的数据去左乘这个特征向量，来获取降维后的新数据。因为这样做可以帮助我们找到一个方向，让它最大程度地包含原有的信息。需要注意的是，这个新的方向，往往不代表原始的特征，而是多个原始特征的组合和缩放。</p>

<h3>44丨奇异值分解：如何挖掘潜在的语义关系？</h3>

<p>今天，我们来聊另一种降维的方法，SVD奇异值分解（SingularValueDecomposition）。它的核心思路和PCA不同。PCA是通过分析不同纬特征之间的协方差，找到包含最多信息量的特征向量，从而实现降维。而SVD这种方法试图通过样本矩阵本身的分解，找到一些“潜在的因素”，然后通过把原始的特征维度映射到较少的潜在因素之上，达到降维的目的。</p>

<h4>方阵的特征分解</h4>

<ul>
<li>方阵</li>
<li>酉矩阵</li>
<li>方阵的特征分解</li>
</ul>


<p>那么如果X不是方阵，那么应该如何进行矩阵的分解呢？这个时候就需要用到奇异值分解SVD了。</p>

<h4>SVD分解</h4>

<ul>
<li><a href="https://zh.wikipedia.org/wiki/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3">Wiki SVD分解</a></li>
<li>奇异值</li>
<li>右奇异向量</li>
<li>左奇异向量</li>
</ul>


<h4>潜在语义分析和SVD</h4>

<h3>45丨线性代数篇答疑和总结：矩阵乘法的几何意义是什么？</h3>

<h2>06-综合应用篇 (6讲)</h2>

<h3>46丨缓存系统：如何通过哈希表和队列实现高效访问？</h3>

<p>缓存设计的几个主要考量因素:
1. 硬件性能：高性能做低性能的缓存。
2. 命中率。缓存删除策略：
    1. 最少使用 LFU（Least Frequently Used）策略
    2. 最久未用 LRU（Least Recently Used）策略：使用队列（Queue）表示上次使用时间，刚用过的放在队尾，淘汰的时候直接淘汰队头的即可。
3. 更新周期</p>

<p>我们同时使用了哈希函数和队列，实现了一个最简单的缓存系统。哈希函数确保了查找的高效率，而队列则实现了LRU的淘汰策略。通过这两点，你就能理解缓存设计的基本原理和方法。</p>

<h3>47丨搜索引擎（上）：如何通过倒排索引和向量空间模型，打造一个简单的搜索引擎？</h3>

<p>搜索引擎最重要的核心就是及时性和相关性。及时性确保用户可以快速找到信息，而相关性确保所找到的信息是用户真正需要的。
1. 倒排索引是搜索引擎提升及时性中非常关键的一步。倒排索引非常适合使用哈希表，特别是链地址型的哈希表来实现。
2. 向量空间模型可以作为文本搜索的相关性模型。但是，它的计算需要把查询和所有的文档进行比较，时间复杂度太高，影响了及时性。这个时候，我们可以利用倒排索引，过滤掉绝大部分不包含查询关键词的文档。</p>

<h3>48丨搜索引擎（下）：如何通过查询的分类，让电商平台的搜索结果更相关？</h3>

<p>相关性模型是搜索引擎非常核心的模块，它直接影响了搜索结果是不是满足用户的需求。我们之前讲解的向量空间模型、概率语言模型等常见的模型，逐渐成为了主流的相关性模型。不过这些模型通常适用于普通的文本检索，并没有针对每个应用领域进行优化。</p>

<p>在电商平台上，搜索引擎是帮助用户查找商品的好帮手。可是，直接采用向量空间模型进行排序往往效果不好。这主要是因为索引的标题和属性都很短，我们无法充分利用关键词的词频、逆文档频率等信息。考虑到搜索商品的时候，商品的分类对于用户更为重要，所以我们在设计相关性排序的时候需要考虑这个信息。</p>

<p>为了识别用户对哪类商品更感兴趣，我们可以对用户输入的查询进行分类。用于构建分类器的数据，可以是运营人员发布的商品目录信息，也可以是用户使用之后的行为日志。我们可以根据搜索系统运行的情况，赋予它们不同的权重。</p>

<p>如果我们可以对查询做出更为准确的分类，那么就可以使用这个分类的结果，来对原有搜索结果进行重新排序。现在的开源搜索引擎，例如Elasticsearch，都支持动态修改排序结果，为我们结合分类器和搜索引擎提供了很大的便利。</p>

<h3>49丨推荐系统（上）：如何实现基于相似度的协同过滤？</h3>

<p>原文链接：<a href="http://hongchaozhang.github.io/assets/resources/49%E4%B8%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8E%E7%9B%B8%E4%BC%BC%E5%BA%A6%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%EF%BC%9F.html">49丨推荐系统（上）：如何实现基于相似度的协同过滤？.html</a></p>

<p>通过一个常用的实验数据，设计并实现了最简单的基于用户的协同过滤。值得动手练习一下。</p>

<h3>50丨推荐系统（下）：如何通过SVD分析用户和物品的矩阵？</h3>

<p>原文链接：<a href="http://hongchaozhang.github.io/assets/resources/50%E4%B8%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87SVD%E5%88%86%E6%9E%90%E7%94%A8%E6%88%B7%E5%92%8C%E7%89%A9%E5%93%81%E7%9A%84%E7%9F%A9%E9%98%B5%EF%BC%9F.html">50丨推荐系统（下）：如何通过SVD分析用户和物品的矩阵？.html</a></p>

<p>通过Python示例，解释了SVD分解过程中的数学量的物理意义，值得上手一试。</p>

<blockquote><p>在用户对电影评分的应用场景下，SVD分解后的U矩阵、V矩阵和Σ矩阵各自代表的意义，其中Σ矩阵中的奇异值表示了SVD挖掘出来的电影主题，U矩阵中的奇异向量表示用户对这些电影主题的评分，而V矩阵中的奇异向量表示了电影和这些主题的相关程度。</p>

<p>分解之后所得到的奇异值σ对应了一个“主题”，σ值的大小表示这个主题在整个电影集合中的重要程度，而V中的右奇异向量表示每部电影和这些“主题”的关系强弱。</p></blockquote>

<h3>51丨综合应用篇答疑和总结：如何进行个性化用户画像的设计？</h3>

<h2>07-加餐 (3讲)</h2>

<h3>数学专栏课外加餐（一）丨我们为什么需要反码和补码？</h3>

<h3>数学专栏课外加餐（三）：程序员需要读哪些数学书？</h3>

<h3>数学专栏课外加餐（二）丨位操作的三个应用实例</h3>

<h2>08-结束语 (1讲)</h2>

<h3>结束语丨从数学到编程，本身就是一个很长的链条</h3>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[web性能优化]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/03/21/web-xingneng-youhua/"/>
    <updated>2022-03-21T23:30:53+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/03/21/web-xingneng-youhua</id>
    <content type="html"><![CDATA[<!-- more -->


<p>从web渲染全过程分析，从下面几个方面进行性能优化考虑：</p>

<ol>
<li>HTTP请求性能优化</li>
<li>浏览器内渲染性能优化</li>
</ol>


<h2>HTTP(s)请求性能优化</h2>

<ul>
<li>参考极客时间课程《透视HTTP协议》的39和40两节课。</li>
<li>另外，<a href="http://hongchaozhang.github.io/blog/2021/05/26/toushi-http-xieyi/">极客时间-罗剑锋-《透视HTTP协议》总结</a>中的章节<a href="http://hongchaozhang.github.io/blog/2021/05/26/toushi-http-xieyi/#http%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96">http性能优化</a>，有一个概括性的描述。</li>
<li>相关内容个人总结参考<a href="http://hongchaozhang.github.io/blog/2022/03/08/http-xingneng-youhua/">HTTP(s)请求性能优化</a>。</li>
</ul>


<h2>浏览器内渲染性能优化</h2>

<ul>
<li>参考极客时间课程《让你页面速度飞起来 Web前端性能优化》</li>
<li>相关内容个人总结参考<a href="http://hongchaozhang.github.io/blog/2022/01/04/web-qianduan-xingneng-youhua/">极客时间-Web前端性能优化</a>。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[从Terminal切换到iTerm2，从Bash切换到Zsh]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/03/08/change-from-bash-to-zsh/"/>
    <updated>2022-03-08T16:45:12+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/03/08/change-from-bash-to-zsh</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>安装iTerm2 + Oh My Zsh</h2>

<p><a href="https://segmentfault.com/a/1190000014992947">iTerm2 + Oh My Zsh 打造舒适终端体验</a></p>

<h4>我的主题和插件</h4>

<p>OhMyZsh的主题：ZSH_THEME=&ldquo;af-magic&rdquo;</p>

<p>OhMyZsh的插件：plugins=(git zsh-syntax-highlighting zsh-autosuggestions)</p>

<h2>Zsh配置文件加载顺序</h2>

<p>最重要的是下面两个文件：</p>

<ul>
<li>.zshenv：.zshenv总是被读取,所以通常把$PATH, $EDITOR等变量写在这里,这样无论是在shell交互,或者运行程序都会读取此文件</li>
<li>.zshrc：.zshrc主要用在交互shell,所以主要是为shell服务的,比如对shell做的一些个性化设置都可以在这里写入</li>
</ul>


<p>更多配置文件，参考<a href="https://unix.stackexchange.com/questions/71253/what-should-shouldnt-go-in-zshenv-zshrc-zlogin-zprofile-zlogout">What should/shouldn&rsquo;t go in .zshenv, .zshrc, .zlogin, .zprofile, .zlogout?</a>，或者这一篇中文<a href="http://blog.xsudo.com/2019/04/12/1445/">zsh的环境变量的加载.zprofile .zlogin .zshrc .zshenv</a></p>

<h2>Zsh问题</h2>

<h3>Octopress在zsh下无法新建博客的问题</h3>

<p>执行：</p>

<pre><code>$ rake new_post["new post name"]
</code></pre>

<p>报错：</p>

<pre><code>zsh: no matches found: new_post[new post name]
</code></pre>

<p>原因：
zsh中若出现‘*’, ‘(’, ‘|’, ‘&lt;’, ‘[’, 或者 ‘?’符号，则将其识别为查找文件名的通配符。</p>

<p>解决方法一：</p>

<p>遇到上面的特殊字符，使用转义字符代替。比如：</p>

<pre><code>$ rake new_post\["new post name"\]
</code></pre>

<p>解决方法二：</p>

<p>取消zsh的通配(GLOB), 在.zshrc中加入</p>

<pre><code>alias rake="noglob rake"
</code></pre>

<p>并且执行：</p>

<pre><code>source ./zshrc
</code></pre>

<p>PS: git操作也有类似的问题。</p>

<p>在 git 回滚操作</p>

<pre><code>git reset --soft HEAD^
</code></pre>

<p>出现报错：</p>

<pre><code>zsh: no matches found HEAD^
</code></pre>

<p>也为同样原因，因为^也为正则中的符号， 需要转义为</p>

<pre><code>git reset --soft HEAD\^
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP(s)请求性能优化]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/03/08/http-xingneng-youhua/"/>
    <updated>2022-03-08T16:44:40+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/03/08/http-xingneng-youhua</id>
    <content type="html"><![CDATA[<!-- more -->




<!-- TOC -->


<ul>
<li><a href="#%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7">性能测试工具</a></li>
<li><a href="#http%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96">HTTP性能优化</a>

<ul>
<li><a href="#%E5%BC%80%E6%BA%90">开源</a></li>
<li><a href="#%E8%8A%82%E6%B5%81">节流</a></li>
<li><a href="#%E7%BC%93%E5%AD%98">缓存</a></li>
<li><a href="#%E5%8D%87%E7%BA%A7%E5%88%B0http2">升级到HTTP/2</a></li>
<li><a href="#%E5%85%B3%E4%BA%8E%E8%B5%84%E6%BA%90%E5%90%88%E5%B9%B6">关于资源合并</a></li>
</ul>
</li>
<li><a href="#https%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96">HTTPs性能优化</a>

<ul>
<li><a href="#1-%E7%A1%AC%E4%BB%B6%E4%BC%98%E5%8C%96cpussl%E5%8A%A0%E9%80%9F%E5%8D%A1ssl%E5%8A%A0%E9%80%9F%E6%9C%8D%E5%8A%A1%E5%99%A8">1. 硬件优化：CPU，SSL加速卡，SSL加速服务器</a></li>
<li><a href="#2-%E8%BD%AF%E4%BB%B6%E4%BC%98%E5%8C%96">2. 软件优化：</a></li>
</ul>
</li>
</ul>


<!-- /TOC -->


<p><a id="markdown-性能测试工具" name="性能测试工具"></a></p>

<h2>性能测试工具</h2>

<ol>
<li><p>在 Linux 上，最常用的性能测试工具可能就是 ab（Apache Bench）了，比如，下面的命令指定了并发数 100，总共发送 10000 个请求：</p>

<pre><code class="`"> ab -c 100 -n 10000 'http://www.xxx.com'
</code></pre></li>
<li><p>系统资源监控方面，Linux 自带的工具也非常多，常用的有 uptime、top、vmstat、netstat、sar 等等，可能你比我还要熟悉，我就列几个简单的例子吧：</p>

<pre><code class="`"> top             # 查看 CPU 和内存占用情况
 vmstat  2       # 每 2 秒检查一次系统状态
 sar -n DEV 2    # 看所有网卡的流量，定时 2 秒检查
</code></pre></li>
<li>之前讲 HTTPS 时介绍过一个专门的网站<a href="https://www.ssllabs.com/">SSLLabs</a>，而对于 HTTP 性能优化，也有一个专门的测试网站<a href="https://www.webpagetest.org/">WebPageTest</a>。它的特点是在世界各地建立了很多的测试点，可以任意选择地理位置、机型、操作系统和浏览器发起测试，非常方便，用法也很简单。网站测试的最终结果是一个直观的“瀑布图”（Waterfall Chart），清晰地列出了页面中所有资源加载的先后顺序和时间消耗。</li>
<li>Chrome 等浏览器自带的开发者工具也可以很好地观察客户端延迟指标，面板左边有每个 URI 具体消耗的时间，面板的右边也有瀑布图。</li>
</ol>


<p><a id="markdown-http性能优化" name="http性能优化"></a></p>

<h2>HTTP性能优化</h2>

<p><a id="markdown-开源" name="开源"></a></p>

<h3>开源</h3>

<ul>
<li>Nginx及相关配置</li>
<li>HTTP启用长连接
<a id="markdown-节流" name="节流"></a></li>
</ul>


<h3>节流</h3>

<ul>
<li>数据压缩：图片，json等</li>
<li>html/css/js的minify</li>
<li>去除不必要的Header属性</li>
<li>减少域名数量和重定向次数
<a id="markdown-缓存" name="缓存"></a></li>
</ul>


<h3>缓存</h3>

<ul>
<li>服务器缓存：Redis</li>
<li>CDN缓存
<a id="markdown-升级到http2" name="升级到http2"></a></li>
</ul>


<h3>升级到HTTP/2</h3>

<ul>
<li>消除了应用层的队头阻塞，拥有头部压缩、二进制帧、多路复用、流量控制、服务器推送等许多新特性，大幅度提升了 HTTP 的传输效率。
<a id="markdown-关于资源合并" name="关于资源合并"></a></li>
</ul>


<h3>关于资源合并</h3>

<ul>
<li>“资源合并”在 HTTP/1 里减少了多次请求的成本，但在 HTTP/2 里因为有头部压缩和多路复用，传输小文件的成本很低，所以合并就失去了意义。而且“资源合并”还有一个缺点，就是降低了缓存的可用性，只要一个小文件更新，整个缓存就完全失效，必须重新下载。</li>
<li>所以在现在的大带宽和 CDN 应用场景下，应当尽量少用资源合并（JS、CSS 图片合并，数据内嵌），让资源的粒度尽可能地小，才能更好地发挥缓存的作用。</li>
</ul>


<p><a id="markdown-https性能优化" name="https性能优化"></a></p>

<h2>HTTPs性能优化</h2>

<p><a id="markdown-1-硬件优化cpussl加速卡ssl加速服务器" name="1-硬件优化cpussl加速卡ssl加速服务器"></a></p>

<h3>1. 硬件优化：CPU，SSL加速卡，SSL加速服务器</h3>

<p><a id="markdown-2-软件优化" name="2-软件优化"></a></p>

<h3>2. 软件优化：</h3>

<ol>
<li>软件升级：Linux内核，Nginx，OpenSSL</li>
<li>协议优化：

<ul>
<li>TLS1.3</li>
<li>密钥交换协议尽量选用椭圆曲线ECDHE算法，能够把握手的消息往返由 2-RTT 减少到 1-RTT，达到与 TLS1.3 类似的效果。</li>
<li>Nginx配置密码套件和椭圆曲线，将优先使用的放在前面。</li>
</ul>
</li>
<li>证书优化：

<ul>
<li>CRL（Certificate revocation list，证书吊销列表）由 CA 定期发布，里面是所有被撤销信任的证书序号，查询这个列表就可以知道证书是否有效。</li>
<li>现在 CRL 基本上不用了，取而代之的是 OCSP（在线证书状态协议，Online Certificate Status Protocol），向 CA 发送查询请求，让 CA 返回证书的有效状态。</li>
<li>“OCSP Stapling”（OCSP 装订），它可以让服务器预先访问 CA 获取 OCSP 响应，然后在握手时随着证书一起发给客户端，免去了客户端连接 CA 服务器查询的时间。</li>
</ul>
</li>
<li>会话复用：

<ul>
<li>我们再回想一下 HTTPS 建立连接的过程：先是 TCP 三次握手，然后是 TLS 一次握手。这后一次握手的重点是算出主密钥“Master Secret”，而主密钥每次连接都要重新计算，未免有点太浪费了，如果能够把“辛辛苦苦”算出来的主密钥缓存一下“重用”，不就可以免去了握手和计算的成本了吗？</li>
<li>这种做法就叫“会话复用”（TLS session resumption），和 HTTP Cache 一样，也是提高 HTTPS 性能的“大杀器”，被浏览器和服务器广泛应用。</li>
<li>会话复用分两种

<ul>
<li>第一种叫“Session ID”：“Session ID”是最早出现的会话复用技术，也是应用最广的，但它也有缺点，服务器必须保存每一个客户端的会话数据，对于拥有百万、千万级别用户的网站来说存储量就成了大问题，加重了服务器的负担。</li>
<li>第二种叫“Session Ticket”：它有点类似 HTTP 的 Cookie，存储的责任由服务器转移到了客户端</li>
</ul>
</li>
<li>预共享密钥：

<ul>
<li>在发送 Ticket 的同时会带上应用数据（Early Data），免去了 1.2 里的服务器确认步骤，这种方式叫“Pre-shared Key”，简称为“PSK”。</li>
</ul>
</li>
</ul>
</li>
</ol>


<p>上面的内容来自极客时间的《透视HTTP协议》课程的39和40两节课。
另外，<a href="http://hongchaozhang.github.io/blog/2021/05/26/toushi-http-xieyi/">极客时间-罗剑锋-《透视HTTP协议》总结</a>中的章节<a href="http://hongchaozhang.github.io/blog/2021/05/26/toushi-http-xieyi/#http%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96">http性能优化</a>，有一个概括性的描述。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何调试NodeJs源码]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/01/12/how-to-debug-nodejs/"/>
    <updated>2022-01-12T15:57:01+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/01/12/how-to-debug-nodejs</id>
    <content type="html"><![CDATA[<!-- more -->


<h2>调试javascript代码</h2>

<p>通过添加<code>--inspect</code>参数启动nodejs服务，看到下面的消息，表明成功启动调试模式：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>HANM10610:nodePlayground hozhang$ node --inspect sightReading.js
</span><span class='line'>Debugger listening on ws://127.0.0.1:9229/c8620553-2cf2-4fac-bab8-d18e98c3d777
</span><span class='line'>For help, see: https://nodejs.org/en/docs/inspector</span></code></pre></td></tr></table></div></figure>


<p>可以通过很多种方式连接到调试环境，比如Chrome Developer Tools, VS Code等，详细信息参考官方文档<a href="https://nodejs.org/en/docs/guides/debugging-getting-started/">Debugging Guide</a>。下面以Chrome Developer Tools说明。</p>

<p>在chrome://inspect/#devices找到启动的target，打开，搜索打开你的文件或者相关的库文件，就可以打断点开始调试了。</p>

<p><img src="http://hongchaozhang.github.io/images/debug%E6%9F%A5%E7%9C%8B%E5%8F%82%E6%95%B0%E7%B1%BB%E5%9E%8B.jpg" alt="debug查看参数类型.jpg" /></p>

<p><img src="http://hongchaozhang.github.io/images/%E8%B0%83%E8%AF%95readFileSync.jpg" alt="调试readFileSync.jpg" /></p>

<h2>调试C/C++代码</h2>

<p>参考<a href="https://www.tripfe.cn/node-js-four-postures-of-source-code-debugging/">Node.js源代码调试的4种姿势</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[极客时间-Web前端性能优化]]></title>
    <link href="http://hongchaozhang.github.io/blog/2022/01/04/web-qianduan-xingneng-youhua/"/>
    <updated>2022-01-04T18:06:29+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2022/01/04/web-qianduan-xingneng-youhua</id>
    <content type="html"><![CDATA[<!-- more -->




<!-- TOC -->


<ul>
<li><a href="#%E8%B5%84%E6%BA%90%E5%8E%8B%E7%BC%A9%E4%B8%8E%E5%90%88%E5%B9%B6">资源压缩与合并</a>

<ul>
<li><a href="#%E5%9B%BE%E7%89%87%E4%BC%98%E5%8C%96">图片优化</a></li>
</ul>
</li>
<li><a href="#%E5%9B%BE%E7%89%87%E7%9A%84%E6%87%92%E5%8A%A0%E8%BD%BD%E9%A2%84%E5%8A%A0%E8%BD%BD">图片的懒加载预加载</a>

<ul>
<li><a href="#%E6%87%92%E5%8A%A0%E8%BD%BD">懒加载：</a></li>
<li><a href="#%E9%A2%84%E5%8A%A0%E8%BD%BD">预加载：</a></li>
</ul>
</li>
<li><a href="#html%E6%B8%B2%E6%9F%93%E8%BF%87%E7%A8%8B">HTML渲染过程</a></li>
<li><a href="#%E9%87%8D%E7%BB%98%E5%A4%96%E8%A7%82%E4%B8%8E%E5%9B%9E%E6%B5%81%E5%B8%83%E5%B1%80redrawreflow">重绘（外观）与回流（布局）redraw/reflow</a>

<ul>
<li><a href="#top-and-translate">top and translate</a></li>
<li><a href="#opacity%E6%9B%BF%E6%8D%A2visibility"><code>opacity</code>替换<code>visibility</code></a></li>
<li><a href="#css%E7%9A%84class%E6%9B%BF%E4%BB%A3style">css的class替代style</a></li>
<li><a href="#displaynone"><code>display:none</code></a></li>
<li><a href="#%E6%85%8E%E7%94%A8clientwidth">慎用<code>clientWidth</code></a></li>
<li><a href="#%E5%B0%91%E7%94%A8table%E5%B8%83%E5%B1%80">少用table布局。</a></li>
<li><a href="#%E5%8A%A8%E7%94%BB%E7%9A%84%E5%88%B7%E6%96%B0%E7%8E%87%E5%92%8C%E9%A1%B5%E9%9D%A2%E6%80%A7%E8%83%BD%E5%B9%B3%E8%A1%A1">动画的刷新率和页面性能平衡</a></li>
<li><a href="#%E5%B0%86gif%E5%9B%BE%E5%8D%95%E7%8B%AC%E6%88%90%E4%B8%80%E4%B8%AA%E5%9B%BE%E5%B1%82">将gif图单独成一个图层</a></li>
<li><a href="#%E5%90%AF%E7%94%A8gpu%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F">启用GPU硬件加速</a></li>
</ul>
</li>
<li><a href="#%E6%B5%8F%E8%A7%88%E5%99%A8%E5%AD%98%E5%82%A8">浏览器存储</a></li>
<li><a href="#%E7%BC%93%E5%AD%98">缓存</a></li>
<li><a href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E6%B8%B2%E6%9F%93">服务器端渲染</a></li>
</ul>


<!-- /TOC -->


<p>总结极客时间课程《让你页面速度飞起来 Web前端性能优化》</p>

<p><a id="markdown-资源压缩与合并" name="资源压缩与合并"></a></p>

<h2>资源压缩与合并</h2>

<p>资源合并会减少请求次数，总体上降低请求时间。但是，也不能不加考虑地都合并到一起，这样会影响首页渲染速度。</p>

<p><a id="markdown-图片优化" name="图片优化"></a></p>

<h3>图片优化</h3>

<ol>
<li>图片<strong>雪碧图</strong>，不能太大，太大影响首屏渲染性能。一个页面的小图放在一起，生成一张雪碧图即可。</li>
<li><strong>inline image</strong>，inline image内嵌在html里面，作为html的一部分和html一起加载。当图片大小小于8KB时，考虑使用inline image。</li>
<li><strong>使用webp格式图片</strong>，webp格式图片由google推出，android平台支持好，apple safari浏览器有兼容性问题（2020年Mac OS Big Sur中的Safari 14已经支持WebP格式。）</li>
<li><strong>jpg</strong>、<strong>png</strong>、<strong>svg</strong>等图片格式各有其特点和应用场合。</li>
</ol>


<p>另附上两个工具软件：</p>

<ol>
<li><a href="https://tinypng.com">图片压缩网站</a></li>
<li><a href="www.spritecow.com">雪碧图生成网站</a></li>
</ol>


<p><a id="markdown-图片的懒加载预加载" name="图片的懒加载预加载"></a></p>

<h2>图片的懒加载预加载</h2>

<p><a id="markdown-懒加载" name="懒加载"></a></p>

<h3>懒加载：</h3>

<p>通过图片进入可视区域的时候再设置img的src属性，进行请求。或者通过库实现。</p>

<p><a id="markdown-预加载" name="预加载"></a></p>

<h3>预加载：</h3>

<ol>
<li>使用<code>image</code>标签引入，先设置<code>display:none</code>。需要显示的时候再通过设置<code>display</code>属性将其显示出来。</li>
<li>在js中<code>new image</code>，并且设置<code>image</code>的<code>src</code>，进行图片下载，保存在js的变量中，但是不显示，需要的时候直接拿过来显示即可。</li>
<li>使用<code>XMLHttpRequest</code>，可以清楚知道请求的过程，但是存在跨域的问题。</li>
<li>或者通过库实现：preloader.js</li>
</ol>


<p><a id="markdown-html渲染过程" name="html渲染过程"></a></p>

<h2>HTML渲染过程</h2>

<ol>
<li>顺序执行，并发加载：为了让资源并发加载，可以部署多个CDN，以突破浏览器对单个域名并发加载数量的限制（4-6个）。

<ol>
<li><a href="https://juejin.cn/post/6844904035628089357">突破浏览器域名并发限制的解决方案</a></li>
<li>浏览器为什么要有这个限制，针对这个限制我们在开发的时候怎么优化？参考<a href="https://segmentfault.com/a/1190000039157302">前端性能优化篇——浏览器同域名并发请求对限制</a></li>
</ol>
</li>
<li>css加载延迟，页面先显示出没有样式的内容，原因是：css没有在header中引入，而是通过其他方式加载，比如在js中加载css。但是在header中通过link加载css也有缺点：阻塞页面渲染和js执行，但是不阻塞外部脚本的加载（得益于webkit的预扫描功能），但是阻塞执行。</li>
<li><code>script</code>和<code>import</code>引入方式：<code>script</code>引入js是同步的，阻塞页面渲染。结合<code>differ</code>和<code>sync</code>标签影响js引入过程。不阻塞资源的加载（得益于webkit的预扫描功能）。</li>
<li>SPA：单页应用，动态加载，路由到相关页面再加载相关的资源。</li>
</ol>


<p><a id="markdown-重绘外观与回流布局redrawreflow" name="重绘外观与回流布局redrawreflow"></a></p>

<h2>重绘（外观）与回流（布局）redraw/reflow</h2>

<p>css性能让js变慢：css影响layout，进而产生重绘与回流。多次的重绘与回流使得UI线程多次工作，而UI线程的启动会阻塞js线程的执行。</p>

<p>下面是一些有关<strong>回流与重绘</strong>实战演练。通过观察Chrome的Performance调试工具分析渲染过程和性能瓶颈。截图如下：</p>

<p><img src="http://hongchaozhang.github.io/images/chrome_performance_demo.jpg" alt="chrome_performance_demo.jpg" /></p>

<p><a id="markdown-top-and-translate" name="top-and-translate"></a></p>

<h3>top and translate</h3>

<p>相比于<code>top</code>，<code>translate</code>没有回流的过程，对于dom结构复杂的页面，性能提升比较明显。</p>

<p><details>
  <summary>Code using <code>top</code></summary></p>

<pre><code>&lt;html&gt;
&lt;head&gt;
    &lt;style&gt;
        #rect {
            position: relative;
            top: 0;
            width: 100px;
            height: 100px;
            background: blue;
        }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div id="rect"&gt;&lt;/div&gt;
    &lt;script&gt;
        setTimeout(() =&gt; {
            document.getElementById("rect").style.top = "100px";
        }, 2000);
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p></details></p>

<p><details>
  <summary>Code using <code>transform</code></summary></p>

<pre><code>&lt;html&gt;
&lt;head&gt;
    &lt;style&gt;
        #rect {
            position: relative;
            transform: translateY(0);
            width: 100px;
            height: 100px;

            background: blue;
        }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div id="rect"&gt;&lt;/div&gt;
    &lt;script&gt;
        setTimeout(() =&gt; {
            document.getElementById("rect").style.transform = "translateY(100px)";
        }, 2000);
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p></details></p>

<p><a id="markdown-opacity替换visibility" name="opacity替换visibility"></a></p>

<h3><code>opacity</code>替换<code>visibility</code></h3>

<p><code>opaciy</code>：如果被修改的dom元素自己是一个图层，不触发回流和重绘（试验结果：没有回流，但是有重绘）；否则，触发回流和重绘。
<code>visibility</code>：不触发回流，只触发重绘。</p>

<p><a id="markdown-css的class替代style" name="css的class替代style"></a></p>

<h3>css的class替代style</h3>

<p>多个dom样式通过class一次改动多条style属性，减少回流和重绘的次数</p>

<p><a id="markdown-displaynone" name="displaynone"></a></p>

<h3><code>display:none</code></h3>

<p>先设置<code>display</code>为<code>none</code>，再修改各种属性，再将<code>display</code>设回来。</p>

<p><a id="markdown-慎用clientwidth" name="慎用clientwidth"></a></p>

<h3>慎用<code>clientWidth</code></h3>

<p>不要在循环中获取dom的<code>clientWidth</code>，否则会flash掉浏览器的缓冲区，使浏览器性能下降。</p>

<p>缓冲区是浏览器的优化机制，将多个改动合并成一次改动，以便提高效率。</p>

<p><a id="markdown-少用table布局" name="少用table布局"></a></p>

<h3>少用table布局。</h3>

<p>修改某一<code>td</code>的宽度，会使得所有<code>td</code>进行回流。</p>

<p><a id="markdown-动画的刷新率和页面性能平衡" name="动画的刷新率和页面性能平衡"></a></p>

<h3>动画的刷新率和页面性能平衡</h3>

<p><a id="markdown-将gif图单独成一个图层" name="将gif图单独成一个图层"></a></p>

<h3>将gif图单独成一个图层</h3>

<p>通过设置某些css属性，将某个dom做成一个图层：</p>

<ol>
<li><code>will-change</code></li>
<li><code>transform: translateZ(0)</code></li>
<li><code>translate3d(0,0,0)</code></li>
</ol>


<p><a id="markdown-启用gpu硬件加速" name="启用gpu硬件加速"></a></p>

<h3>启用GPU硬件加速</h3>

<p>启用GPU加速，会减少重绘的时间，但是图层增多，图层合并的时间会增加，这里也有个平衡需要把握。</p>

<p>细节参考<a href="https://lz5z.com/Web%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-CSS3%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F/">Web 性能优化-CSS3 硬件加速(GPU 加速)</a></p>

<p><a id="markdown-浏览器存储" name="浏览器存储"></a></p>

<h2>浏览器存储</h2>

<ol>
<li>cdn域名和主站域名区分开，防止获取静态资源携带cookie，浪费带宽。</li>
<li>通过service worker开启另一个线程，和主页通过<code>postMessage</code>互相通信。</li>
<li>通过浏览器performance profile查看性能瓶颈和改进效果。</li>
<li>增加图层是减少的重绘与回流的时间与增加的图层合并时间的增加之间的平衡。比如通过设置translate3d开启GPU加速。</li>
<li>获取offsetHeight为什么会降低效率？使缓冲区域失效，因为要得到一个真实的尺寸。缓冲区域是浏览器的一个优化机制，通过将多次更改dom综合起来一次更新，提高效率。</li>
</ol>


<p><a id="markdown-缓存" name="缓存"></a></p>

<h2>缓存</h2>

<p><strong>强缓存</strong>
如果命中，不需要发请求到服务器。</p>

<ol>
<li>cache-control: max-age, s-max-age</li>
<li>expires:</li>
</ol>


<p><strong>协商缓存（弱缓存）</strong>
需要发请求到服务器询问本地缓存是否可用。如果可用，服务器返回304，不携带具体内容，具体内容从本地缓存中读取。如果不可用，服务器直接返回内容。</p>

<ol>
<li>last-modified:</li>
<li>if-modified-since: 304</li>
<li>e-tag:</li>
<li>if-none-match:</li>
</ol>


<p>浏览器缓存流程如下：</p>

<p><img src="http://hongchaozhang.github.io/images/%E6%B5%8F%E8%A7%88%E5%99%A8%E7%BC%93%E5%AD%98%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="浏览器缓存流程图.png" /></p>

<p>关于缓存，下面两篇文章介绍的很清楚：</p>

<ol>
<li><a href="https://www.jiqizhixin.com/articles/2020-07-24-12">Web 缓存介绍</a></li>
<li><a href="https://segmentfault.com/a/1190000010787023">HTTP 缓存之浏览器刷新行为</a>: disable cache setting in the developper tool</li>
</ol>


<p><a id="markdown-服务器端渲染" name="服务器端渲染"></a></p>

<h2>服务器端渲染</h2>

<ol>
<li>vue-ssr (server-side-rendering)</li>
<li>react-ssr</li>
<li>代价：需要一个universal的code base，保证其在服务器端和浏览器端都能运行。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[极客时间-深入浅出云计算]]></title>
    <link href="http://hongchaozhang.github.io/blog/2021/12/06/shenru-qianchu-yunjisuan/"/>
    <updated>2021-12-06T10:21:06+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2021/12/06/shenru-qianchu-yunjisuan</id>
    <content type="html"><![CDATA[<!-- more -->




<!-- TOC -->


<ul>
<li><a href="#01--%E5%8C%BA%E5%9F%9F%E5%92%8C%E5%8F%AF%E7%94%A8%E5%8C%BA%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%88%B0%E4%BA%91%E7%AB%AF%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83">01 | 区域和可用区：欢迎来到云端数据中心</a></li>
<li><a href="#02--%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%80%E4%BA%91%E7%AB%AF%E6%94%92%E6%9C%BA%E6%9C%89%E5%93%AA%E4%BA%9B%E5%AE%B9%E6%98%93%E5%BF%BD%E8%A7%86%E7%9A%84%E8%A6%81%E7%82%B9">02 | 云虚拟机（一）：云端“攒机”，有哪些容易忽视的要点?</a></li>
<li><a href="#03-%E4%B8%A8%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%BA%8C%E7%9C%BC%E8%8A%B1%E7%BC%AD%E4%B9%B1%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9E%8B%E5%8F%B7%E6%88%91%E8%AF%A5%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9">03 丨云虚拟机（二）：眼花缭乱的虚拟机型号，我该如何选择？</a></li>
<li><a href="#04-%E4%B8%A8%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%89%E8%80%81%E6%9D%BF%E8%A6%81%E6%B1%82%E7%9C%81%E7%9C%81%E7%9C%81%E6%9C%89%E5%93%AA%E4%BA%9B%E5%A6%99%E6%8B%9B">04 丨云虚拟机（三）：老板要求省省省，有哪些妙招？</a></li>
<li><a href="#05--%E4%BA%91%E7%A1%AC%E7%9B%98%E4%BA%91%E4%B8%8Aio%E5%88%B0%E5%BA%95%E7%BB%99%E4%B8%8D%E7%BB%99%E5%8A%9B">05 | 云硬盘：云上IO到底给不给力？</a></li>
<li><a href="#06--%E4%BA%91%E4%B8%8A%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E5%BC%80%E5%90%88%E6%9C%89%E5%BA%A6%E7%BC%96%E7%BB%87%E6%97%A0%E5%BD%A2%E4%B9%8B%E7%BD%91">06 | 云上虚拟网络：开合有度，编织无形之网</a>

<ul>
<li><a href="#%E5%BC%B9%E6%80%A7%E7%BD%91%E5%8D%A1">弹性网卡</a></li>
<li><a href="#%E5%85%AC%E7%BD%91ip%E5%92%8C%E5%BC%B9%E6%80%A7ip">公网IP和弹性IP</a></li>
</ul>
</li>
<li><a href="#07--%E4%BA%91%E7%AB%AF%E6%9E%B6%E6%9E%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%E4%B8%8E%E6%95%85%E9%9A%9C%E5%90%8C%E8%88%9E%E4%B8%8E%E4%BC%B8%E7%BC%A9%E5%85%B1%E7%94%9F">07 | 云端架构最佳实践：与故障同舞，与伸缩共生</a></li>
<li><a href="#08-%E4%B8%A8%E4%BA%91%E4%B8%8A%E8%BF%90%E7%BB%B4%E4%BA%91%E7%AB%AF%E7%A9%B6%E7%AB%9F%E9%9C%80%E4%B8%8D%E9%9C%80%E8%A6%81%E8%BF%90%E7%BB%B4%E9%9C%80%E8%A6%81%E6%80%8E%E6%A0%B7%E7%9A%84%E8%BF%90%E7%BB%B4">08 丨云上运维：云端究竟需不需要运维？需要怎样的运维？</a></li>
<li><a href="#09--%E4%BB%80%E4%B9%88%E6%98%AFpaas%E6%80%8E%E6%A0%B7%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%92%8C%E8%AF%84%E4%BC%B0paas">09 | 什么是PaaS？怎样深入理解和评估PaaS？</a></li>
<li><a href="#10--%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9C%8B%E4%BC%BC%E7%AE%80%E5%8D%95%E7%9A%84%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E7%8E%84%E6%9C%BA">10 | 对象存储：看似简单的存储服务都有哪些玄机？</a>

<ul>
<li><a href="#%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E7%9A%84%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7">对象存储的高级特性</a></li>
</ul>
</li>
<li><a href="#11--%E5%BA%94%E7%94%A8%E6%89%98%E7%AE%A1%E6%9C%8D%E5%8A%A1web%E5%BA%94%E7%94%A8%E6%80%8E%E6%A0%B7%E5%9C%A8%E4%BA%91%E4%B8%8A%E5%AE%89%E5%AE%B6">11 | 应用托管服务：Web应用怎样在云上安家？</a></li>
<li><a href="#12--%E4%BA%91%E6%95%B0%E6%8D%AE%E5%BA%93%E9%AB%98%E6%AD%8C%E7%8C%9B%E8%BF%9B%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%B0%E8%B4%B5">12 | 云数据库：高歌猛进的数据库“新贵”</a>

<ul>
<li><a href="#%E4%BA%91%E5%8E%9F%E7%94%9F%E6%95%B0%E6%8D%AE%E5%BA%93">云原生数据库</a></li>
</ul>
</li>
<li><a href="#13--%E4%BA%91%E4%B8%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BA%91%E8%AE%A1%E7%AE%97%E9%81%87%E4%B8%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A0%AA%E7%A7%B0%E5%A4%A9%E4%BD%9C%E4%B9%8B%E5%90%88">13 | 云上大数据：云计算遇上大数据，为什么堪称天作之合？</a></li>
<li><a href="#14--%E4%BA%91%E4%B8%8A%E5%AE%B9%E5%99%A8%E6%9C%8D%E5%8A%A1%E4%BB%8Edocker%E5%88%B0kubernetes%E8%BF%8E%E6%8E%A5%E4%BA%91%E5%8E%9F%E7%94%9F%E6%B5%AA%E6%BD%AE">14 | 云上容器服务：从Docker到Kubernetes，迎接云原生浪潮</a></li>
<li><a href="#15--%E6%97%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%A1%E7%AE%97%E8%BF%BD%E6%B1%82%E6%9E%81%E8%87%B4%E6%95%88%E7%8E%87%E7%9A%84%E5%A4%9A%E9%9D%A2%E6%89%8B">15 | 无服务器计算：追求极致效率的多面手</a></li>
<li><a href="#16--%E4%BA%91%E4%B8%8Aai%E6%9C%8D%E5%8A%A1%E4%BA%91ai%E8%83%BD%E4%BB%8E%E5%93%AA%E4%BA%9B%E6%96%B9%E9%9D%A2%E5%B8%AE%E5%8A%A9%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8">16 | 云上AI服务：云AI能从哪些方面帮助构建智能应用？</a></li>
</ul>


<!-- /TOC -->


<p><a id="markdown-01--区域和可用区欢迎来到云端数据中心" name="01--区域和可用区欢迎来到云端数据中心"></a></p>

<h2>01 | 区域和可用区：欢迎来到云端数据中心</h2>

<p><a id="markdown-02--云虚拟机一云端攒机有哪些容易忽视的要点" name="02--云虚拟机一云端攒机有哪些容易忽视的要点"></a></p>

<h2>02 | 云虚拟机（一）：云端“攒机”，有哪些容易忽视的要点?</h2>

<p>传统的虚拟化（虚拟机），往往是对单一物理机器资源的纵向切割，计算、存储、网络等各方面的能力都是一台物理机的子集。因此，从可伸缩性的角度来说，传统虚拟机存在较大的局限，当物理机的局部出现故障时，也很容易影响到里面的虚拟机。</p>

<p>得益于云端大规模的专属硬件以及高速的内部网络，云虚拟机的组成则有所不同。除了核心的 CPU 与内存部分仍属于一台宿主机外，它的网络、硬盘等其他部分，则可以超脱于宿主机之外，享受云端其他基础设施的能力。大致架构如下图所示：</p>

<p><img src="http://hongchaozhang.github.io/images/%E4%BA%91%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%B5%84%E6%BA%90%E6%9E%84%E6%88%90.jpeg" alt="云虚拟机资源构成" /></p>

<p>所以，云虚拟机，与其说是由一台宿主机虚拟而成的，不如说是云数据中心中的不同部分一起协作，“拼凑”而成的一台机器。这样虚拟出来的机器，我们在使用感受上其实与传统服务器并无不同，但在可扩展性和故障隔离方面，它就具有很大的优势了。</p>

<p><a id="markdown-03-丨云虚拟机二眼花缭乱的虚拟机型号我该如何选择" name="03-丨云虚拟机二眼花缭乱的虚拟机型号我该如何选择"></a></p>

<h2>03丨云虚拟机（二）：眼花缭乱的虚拟机型号，我该如何选择？</h2>

<p><a id="markdown-04-丨云虚拟机三老板要求省省省有哪些妙招" name="04-丨云虚拟机三老板要求省省省有哪些妙招"></a></p>

<h2>04丨云虚拟机（三）：老板要求省省省，有哪些妙招？</h2>

<p><a id="markdown-05--云硬盘云上io到底给不给力" name="05--云硬盘云上io到底给不给力"></a></p>

<h2>05 | 云硬盘：云上IO到底给不给力？</h2>

<p>云厂商对于云盘，一般会帮你在存储端同步和保留至少三份副本的数据。所以说，云硬盘的冗余度和可用性是非常之高的，一般极少发生云硬盘数据丢失的情况，你大可放心地使用。</p>

<p>云盘性能指标：</p>

<ul>
<li>IOPS</li>
<li>吞吐量</li>
<li>访问延时</li>
</ul>


<p>云硬盘与传统磁盘的真正差异在于，绝大多数的云硬盘都是<strong>远程</strong>的。</p>

<p>我们都知道，在经典计算机的体系结构中，硬盘是通过本地机器内部主板的高速总线，与 CPU、内存等部件相连接；而在云端，你的硬盘则很可能并不在宿主机上，而是在专用的磁盘服务器阵列中，两者是通过数据中心内部的特有IO线路进行连接的。</p>

<p>理解了这样的一个结构，你就能明白，有些云上的“IO优化实例”（AWS 上称为 EBS-Optimized）是指什么了。它就是指云虚拟机与云硬盘之间的网络传输，进行了软硬件层面的优化，这样可以充分地发挥所挂载磁盘的性能。现在较新型号、较强性能的云虚拟机，一般都自动启用了这个优化。</p>

<p>云存储的性能级别：</p>

<p><img src="http://hongchaozhang.github.io/images/%E4%BA%91%E5%AD%98%E5%82%A8%E7%9A%84%E7%BA%A7%E5%88%AB.jpeg" alt="云存储的级别" /></p>

<p>除了云盘性能等级，还有一个指标也是影响云盘性能的重要指标：云盘容量。不论是哪种磁盘类型，它的容量大小几乎都与性能正向相关。同等的性能等级下，云硬盘的容量越大，一般来说它的性能就越高，直到达到这个等级的上限。这是由云上磁盘能力共享的底层设计所决定的。</p>

<p>所以在某些时候，你可能需要刻意地增大所申请的云硬盘的容量，以获取更高的性能，即便这些额外的空间不一定能被用上。</p>

<p><a id="markdown-06--云上虚拟网络开合有度编织无形之网" name="06--云上虚拟网络开合有度编织无形之网"></a></p>

<h2>06 | 云上虚拟网络：开合有度，编织无形之网</h2>

<p>虚拟私有网络（Virtual Private Cloud，简称 VPC），是云计算网络端最重要的概念之一，它是指构建在云上的、相互隔离的、用户可以自主控制的私有网络环境。虚拟私有网络有时也称为专有网络（阿里云）或虚拟网络（Virtual Network 或 VNet，Azure 的叫法）。</p>

<p>上面的概念解释也许不太好理解，其实用通俗的话来讲，私有网络就是一张属于你自己的内网。内网之内的服务器和设备，可以比较自由地互相通信，与外界默认是隔离的。如果外部互联网，或者其他虚拟网络需要连接，则需要额外的配置。</p>

<p>所以说，虚拟私有网络，就是你在云上的保护网，能够有效地保护网内的各种设施。有的时候，你可能还要同时创建多个虚拟网络，让它们各司其职，实现更精细的隔离。</p>

<p><a id="markdown-弹性网卡" name="弹性网卡"></a></p>

<h3>弹性网卡</h3>

<p>云上的网卡，之所以被称为“弹性”网卡，是因为它具备以下特征：</p>

<ol>
<li>一个虚拟机可以绑定多块网卡，有主网卡和辅助网卡之分；</li>
<li>一块网卡隶属于一个子网，可以配置同一子网内的多个私有 IP；</li>
<li>辅助网卡可以动态解绑，还能够绑定到另一台虚拟机上。</li>
</ol>


<p><a id="markdown-公网ip和弹性ip" name="公网ip和弹性ip"></a></p>

<h3>公网IP和弹性IP</h3>

<p>在绝大多数的云上，创建虚拟机时都会有一个选项，问你“是否同时为虚拟机分配一个公网 IP 地址”。如果你选择“是”，这样机器启动后，就会拥有一个自动分配的公网地址，便于你从自己的电脑连接到这个实例。这在很多时候都是最方便的选择。</p>

<p>但对于生产环境，我的推荐是，尽量不要使用和依赖这个自动生成的公有 IP。因为它本质上是一个从公有云的 IP 池中临时租用给你的 IP。如果你的机器关闭或重启，下次获得的 IP 可能就完全不同了。</p>

<p>这时，我们真正应该用到的是弹性 IP（Elastic IP），有些云称为 eIP。弹性 IP 一旦生成，它所对应的 IP 是固定、不会变化的，而且完全属于你所有。这非常适合需要稳定 IP 的生产环境。</p>

<p>请不要被它的名字迷惑，它所谓的弹性，其实是指可以非常自由地解绑和再次绑定到任意目标。你本质上是买下了这个 IP 的所有权，将这个 IP 赋予谁，是你的权利，而且你还可以动态按需切换。</p>

<p><a id="markdown-07--云端架构最佳实践与故障同舞与伸缩共生" name="07--云端架构最佳实践与故障同舞与伸缩共生"></a></p>

<h2>07 | 云端架构最佳实践：与故障同舞，与伸缩共生</h2>

<p>云上架构最需要注意什么呢？就像我在标题所描述的那样，云端架构一方面需要处理和应对可能出现的<strong>故障</strong>，保证架构和服务的可用性；另一方面则是需要充分利用好云端的<strong>弹性</strong>，要能够根据负载进行灵活的伸缩。</p>

<p>那么，云上可能出现哪些不同层面的故障？相应的故障范围和应对措施又会是怎样的呢？</p>

<p><strong>第一种故障是在宿主机的级别，这也是从概率上来说最常见的一种故障。</strong>当宿主机出现硬件故障等问题后，毫无疑问将影响位于同一宿主机上的多个虚拟机。为了避免产生这样的影响，当我们承载重要业务时，就需要创建多台虚拟机组成的集群，共同来进行支撑。这样，当一台虚拟机出现故障时，还有其他几台机器能够保证在线。</p>

<p>这里需要注意的是，<strong>我们需要保证多个虚拟机不在同一台宿主机上，甚至不处于同一个机架上，以免这些虚拟机一起受到局部事故的影响。</strong></p>

<p><strong>第二种规模更大的故障，是在数据中心，也就是可用区的层面。</strong>要应对这类故障，我们就需要<strong>多可用区的实例部署</strong>。</p>

<p><strong>第三种更严重的故障，就是整个区域级别的事故了。</strong>当然这种一般非常少见，只有地震等不可抗力因素，或者人为过失引发出的一系列连锁反应，才有可能造成这么大的影响。区域级别的事故一般都难免会对业务造成影响了。这时能够进行补救的，主要看<strong>多区域架构层面是否有相关的预案</strong>。</p>

<p>再更进一步的万全之策，就需要考虑<strong>多云</strong>了。也就是同时选用多家云厂商的公有云，一起来服务业务。虽然集成多个异构的云会带来额外的成本，但这能够最大限度地降低服务风险，因为两家云厂商同时出问题的概率实在是太低了。更何况，多云还能带来避免厂商锁定的好处，现在其实也越来越多见了。</p>

<p>当然，盲目地追求可用性也不可取。<strong>根据业务需求，在成本投入与可用性之间获得一个最佳的平衡，才是你应该追求的目标。</strong></p>

<p><a id="markdown-08-丨云上运维云端究竟需不需要运维需要怎样的运维" name="08-丨云上运维云端究竟需不需要运维需要怎样的运维"></a></p>

<h2>08丨云上运维：云端究竟需不需要运维？需要怎样的运维？</h2>

<p><a id="markdown-09--什么是paas怎样深入理解和评估paas" name="09--什么是paas怎样深入理解和评估paas"></a></p>

<h2>09 | 什么是PaaS？怎样深入理解和评估PaaS？</h2>

<p>PaaS 是在 IaaS 的基础上又做了许多工作，构建了很多关键抽象和可复用的单元，让我们用户能够在更上层进行应用的构建，把更多精力放在业务逻辑上。</p>

<p>所以 PaaS 服务的优势，就在于生产力，在于效率，尤其是在搭建和运维层面。</p>

<p><a id="markdown-10--对象存储看似简单的存储服务都有哪些玄机" name="10--对象存储看似简单的存储服务都有哪些玄机"></a></p>

<h2>10 | 对象存储：看似简单的存储服务都有哪些玄机？</h2>

<p>同样是存储服务，对象存储和前面我们 IaaS 部分讲过的云硬盘存储有什么区别呢？</p>

<p>第一个主要区别，在于<strong>访问的接口与形式</strong>。</p>

<p>云硬盘其实是挂载到虚拟机的虚拟硬盘，它是通过实现操作系统级别的底层接口，作为虚拟机的块存储设备而存在。我们也必须连接到相关的虚拟机，才能访问它里面的数据。</p>

<p>而对象存储，本质是一个网络化的服务，调用方主要通过高层的 API 和 SDK 来和它进行交互。不管是面向外部公开互联网服务，还是和内部应用程序对接，对象存储都是通过提供像 HTTP 这样的网络接口来实现的。所以它的独立性很强，不需要依赖其他组件就可以运作。</p>

<p>第二个主要区别，也是对象存储的一大特征，就是对象存储内本身不存在一个真正的文件系统，而是更接近一个<strong>键值</strong>（Key-Value）形式的存储服务。</p>

<p>键值系统和云硬盘上经典文件系统的<strong>核心差异</strong>，就在于文件系统保存了更多的元数据，尤其是实现了目录结构和目录操作。而键值系统中，所谓的目录其实是多个对象共享的路径前缀，可以说是用前缀模拟出了目录。</p>

<p>第三个主要区别，在于对象存储的<strong>据大容量</strong>。</p>

<p><a id="markdown-对象存储的高级特性" name="对象存储的高级特性"></a></p>

<h3>对象存储的高级特性</h3>

<p>第一个重要特性，是<strong>存储分层</strong>。</p>

<p><img src="http://hongchaozhang.github.io/images/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E5%88%86%E5%B1%82.jpeg" alt="对象存储分层" /></p>

<p>存储分层的存在，让原本价格低廉的云上存储更加具有成本竞争力。给你举个例子，现在归档层的存储费用，在典型情况下大约是每 GB 每月 1 分钱左右，是不是低得惊人？所以，很多用户上云的一个应用场景就是，把原本占用大量传统磁盘的备份文件，利用对象存储的归档能力长期保存。</p>

<p>第二个值得称道的特性，是<strong>生命周期管理</strong>。可以对存储对象设置过期规则。</p>

<p>第三个特性，则是对象的<strong>版本管理</strong>。</p>

<p><a id="markdown-11--应用托管服务web应用怎样在云上安家" name="11--应用托管服务web应用怎样在云上安家"></a></p>

<h2>11 | 应用托管服务：Web应用怎样在云上安家？</h2>

<p>你可以使用虚拟机和其他 IaaS 组件来搭建你的网站。但用 IaaS，你需要操心的事情比较多，包括虚拟机的创建、运行环境的搭建和依赖安装、高可用性和水平扩展的架构等等。而且一旦应用的规模大了，每次应用的更新升级也会是件麻烦事，另外你还要操心 Web 漏洞的弥补修复。</p>

<p>那么，能不能有一个平台服务，来帮助我们解决所有这些基础架构问题，让我们只需要专注于应用构建本身就好了呢？当然是有的，这就是云上应用托管 PaaS 服务的由来。</p>

<p><a id="markdown-12--云数据库高歌猛进的数据库新贵" name="12--云数据库高歌猛进的数据库新贵"></a></p>

<h2>12 | 云数据库：高歌猛进的数据库“新贵”</h2>

<p>而近年来随着云计算的兴起，云数据库作为一支新生力量，一路高歌猛进，打破了数据库市场的原有格局，也进入了越来越多开发者的视野当中。这类 PaaS 服务的朴素思想就是，将数据库服务搬到云上，让用户更方便轻松地使用、管理和维护数据库。</p>

<p><a id="markdown-云原生数据库" name="云原生数据库"></a></p>

<h3>云原生数据库</h3>

<p>云原生数据库：完全为云设计、能够充分发挥云的特点和优势的数据库。</p>

<p>出于生态发展和降低学习难度的需要，绝大多数的云原生数据库仍然保留了 SQL 等常见接口（有的还支持不同 SQL 方言的选择），但除此以外，云原生数据库大都进行了全面革新和重新设计，有的云会大刀阔斧地改造开源代码，有的甚至脱离了现有包袱，完全重新构建。</p>

<p>这样的尝试取得了巨大的成功，业界也逐渐形成了一系列不同领域的云原生数据库矩阵，大大拓展了云上数据库的范畴和影响力。</p>

<p>我这里也为你整理了一张表格，按照厂商和云数据库的类型进行了梳理和比较。其中，标红的部分是相当值得你关注的自研云原生数据库。</p>

<p><img src="http://hongchaozhang.github.io/images/%E4%BA%91%E5%8E%9F%E7%94%9F%E6%95%B0%E6%8D%AE%E5%BA%93.jpeg" alt="云原生数据库" /></p>

<p><a id="markdown-13--云上大数据云计算遇上大数据为什么堪称天作之合" name="13--云上大数据云计算遇上大数据为什么堪称天作之合"></a></p>

<h2>13 | 云上大数据：云计算遇上大数据，为什么堪称天作之合？</h2>

<p><a id="markdown-14--云上容器服务从docker到kubernetes迎接云原生浪潮" name="14--云上容器服务从docker到kubernetes迎接云原生浪潮"></a></p>

<h2>14 | 云上容器服务：从Docker到Kubernetes，迎接云原生浪潮</h2>

<p><a id="markdown-15--无服务器计算追求极致效率的多面手" name="15--无服务器计算追求极致效率的多面手"></a></p>

<h2>15 | 无服务器计算：追求极致效率的多面手</h2>

<p>无服务器（Serverless）完全屏蔽了计算资源，它是在真正地引导你不再去关心底层环境，你只要遵循标准方式来直接编写业务代码就可以了。其中一个具体应用就是函数即服务（FaaS，Function as a service)。</p>

<p>各大云厂商现在都已经推出了各自的无服务器计算服务，比如 AWS 的 <strong>Lambda</strong>，阿里云的<strong>函数计算</strong>，微软Azure的<strong>Azure Function</strong>，微信的<strong>云函数</strong>。</p>

<p>为了让这个云函数能够对外服务，我们接下来就需要为它添加一个 <strong>API网关触发器</strong>，这样当 API 被外界访问时，这个云函数就会被触发执行并返回结果给网关。</p>

<p>API 网关是一个独立的 PaaS 服务，它可以和云函数联动使用。它的作用是为外界访问提供一个端点，并引流到我们的后台计算服务。</p>

<p>无服务器计算灵活轻量，便于迭代。但是，我们还是要记得恪守冷静客观的原则。一定不要忽略了 Serverless 服务的限制，毕竟它的本质是受限的环境。<strong>冷启动的延时、内存的限制、云函数的运行时长、并发数上限</strong>等等，这些都是你大规模深入应用之前需要评估考虑的问题。虽然云厂商一直在改进，这些客观限制在当下对于你的场景是否造成了实质性障碍，也是你目前是否选择 Serverless 计算的一个重要依据。</p>

<p><a id="markdown-16--云上ai服务云ai能从哪些方面帮助构建智能应用" name="16--云上ai服务云ai能从哪些方面帮助构建智能应用"></a></p>

<h2>16 | 云上AI服务：云AI能从哪些方面帮助构建智能应用？</h2>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[极客时间-徐文浩-《深入浅出计算机组成原理》]]></title>
    <link href="http://hongchaozhang.github.io/blog/2021/11/11/jisuanji-zucheng-yuanli/"/>
    <updated>2021-11-11T12:43:31+08:00</updated>
    <id>http://hongchaozhang.github.io/blog/2021/11/11/jisuanji-zucheng-yuanli</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://time.geekbang.org/column/intro/100026001">深入浅出计算机组成原理》</a></p>

<p>零散笔记，不成体系。</p>

<h2>浮点数和定点数</h2>

<h2>GPU/TPU/FPGA</h2>

<h2>CPU</h2>

<p>CPU、缓存和内存的关系：
<img src="http://hongchaozhang.github.io/images/cpu%E5%92%8C%E5%86%85%E5%AD%98%E7%9A%84%E5%85%B3%E7%B3%BB%E7%B1%BB%E6%AF%94.png" alt="cpu和内存的关系类比.png" /></p>

<ul>
<li>cache line （64KB）</li>
<li>cache和内存地址映射</li>
<li>缓存读取</li>
<li>缓存写入</li>
<li>缓存一致性：比分布式系统的数据一致性简单，因为不用考虑网络传输延迟和异常。

<ul>
<li>写传播</li>
<li>事务串行化

<ul>
<li>总线嗅探</li>
<li>MESI协议</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>参考
* <a href="https://coolshell.cn/articles/20793.html">与程序员相关的CPU缓存知识</a>。
* Github上的一个代码库 <a href="https://github.com/Kobzol/hardware-effects">hardware-effects</a> 里面有受CPU影响的程序的演示。
    > This repository demonstrates various hardware effects that can degrade application performance in surprising ways and that may be very hard to explain without knowledge of the low-level CPU and OS architecture.</p>

<h2>内存</h2>

<ul>
<li>虚拟内存地址</li>
<li>物理内存地址</li>
<li>页表

<ul>
<li>简单页表</li>
<li>多级页表：时间换空间，树形结构</li>
</ul>
</li>
<li>加速地址转换（TLB）：通过在CPU中放置cache可以快速进行虚拟内存地址到物理内存地址的转换。</li>
<li>内存保护

<ul>
<li>可执行空间保护</li>
<li>地址空间布局随机化

<h2>CPU架构</h2>

<h3>CISC和RISC</h3></li>
</ul>
</li>
<li>复杂指令集（Complex Instruction Set Computing，简称 CISC）</li>
<li>精简指令集（Reduced Instruction Set Computing，简称 RISC）</li>
</ul>


<p>当时，UC Berkeley的大卫·帕特森（David Patterson）教授发现，实际在CPU运行的程序里，80%的时间都是在使用20%的简单指令。于是，他就提出了RISC的理念。自此之后，RISC类型的CPU开始快速蓬勃发展。</p>

<p>在RISC架构里面，CPU选择把指令“精简”到20%的简单指令。而原先的复杂指令，则通过用简单指令组合起来来实现，让软件来实现硬件的功能。这样，CPU的整个硬件设计就会变得更简单了，在硬件层面提升性能也会变得更容易了。</p>

<p>RISC的CPU里完成指令的电路变得简单了，于是也就腾出了更多的空间。这个空间，常常被拿来放通用寄存器。因为RISC完成同样的功能，执行的指令数量要比CISC多，所以，如果需要反复从内存里面读取指令或者数据到寄存器里来，那么很多时间就会花在访问内存上。于是，RISC架构的CPU往往就有更多的通用寄存器。</p>

<h3>ARM和RISC-V：CPU的现在与未来</h3>

<p>2017年，ARM公司的CEO Simon Segards宣布，ARM累积销售的芯片数量超过了1000亿。作为一个从12个人起步，在80年代想要获取Intel的80286架构授权来制造CPU的公司，ARM是如何在移动端把自己的芯片塑造成了最终的霸主呢？</p>

<p>ARM这个名字现在的含义，是“Advanced RISC Machines”。你从名字就能够看出来，ARM的芯片是基于RISC架构的。不过，ARM能够在移动端战胜Intel，并不是因为RISC架构。</p>

<p>到了21世纪的今天，CISC和RISC架构的分界已经没有那么明显了。Intel和AMD的CPU也都是采用译码成RISC风格的微指令来运行。而ARM的芯片，一条指令同样需要多个时钟周期，有乱序执行和多发射。我甚至看到过这样的评价，“ARM和RISC的关系，只有在名字上”。</p>

<p>ARM真正能够战胜Intel，我觉得主要是因为下面这两点原因。</p>

<ul>
<li><p>第一点是功耗优先的设计。一个4核的Intel i7的CPU，设计的时候功率就是130W。而一块ARM A8的单个核心的CPU，设计功率只有2W。两者之间差出了100倍。在移动设备上，功耗是一个远比性能更重要的指标，毕竟我们不能随时在身上带个发电机。ARM的CPU，主频更低，晶体管更少，高速缓存更小，乱序执行的能力更弱。所有这些，都是为了功耗所做的妥协。</p></li>
<li><p>第二点则是低价。ARM并没有自己垄断CPU的生产和制造，只是进行CPU设计，然后把对应的知识产权授权出去，让其他的厂商来生产ARM架构的CPU。它甚至还允许这些厂商可以基于ARM的架构和指令集，设计属于自己的CPU。像苹果、三星、华为，它们都是拿到了基于ARM体系架构设计和制造CPU的授权。ARM自己只是收取对应的专利授权费用。多个厂商之间的竞争，使得ARM的芯片在市场上价格很便宜。所以，尽管ARM的芯片的出货量远大于Intel，但是收入和利润却比不上Intel。</p></li>
</ul>


<p>不过，ARM并不是开源的。所以，在ARM架构逐渐垄断移动端芯片市场的时候，“开源硬件”也慢慢发展起来了。一方面，MIPS在2019年宣布开源；另一方面，从UC Berkeley发起的RISC-V项目也越来越受到大家的关注。而RISC概念的发明人，图灵奖的得主大卫·帕特森教授从伯克利退休之后，成了RISC-V国际开源实验室的负责人，开始推动RISC-V这个“CPU届的Linux”的开发。可以想见，未来的开源CPU，也多半会像Linux一样，逐渐成为一个业界的主流选择。如果想要“打造一个属于自己CPU”，不可不关注这个项目。</p>

<h2>FPGA和ASIC</h2>

<p>FPGA，也就是现场可编程门阵列（Field-Programmable Gate Array）。看到这个名字，你可能要说了，这里面每个单词单独我都认识，放到一起就不知道是什么意思了。</p>

<p>没关系，我们就从FPGA里面的每一个字符，一个一个来看看它到底是什么意思。</p>

<ul>
<li>P代表Programmable，这个很容易理解。也就是说这是一个可以通过编程来控制的硬件。</li>
<li>G代表Gate也很容易理解，它就代表芯片里面的门电路。我们能够去进行编程组合的就是这样一个一个门电路。</li>
<li>A代表的Array，叫作阵列，说的是在一块FPGA上，密密麻麻列了大量Gate这样的门电路。</li>
<li>最后一个F，不太容易理解。它其实是说，一块FPGA这样的板子，可以进行在“现场”多次地进行编程。它不像PAL（Programmable Array Logic，可编程阵列逻辑）这样更古老的硬件设备，只能“编程”一次，把预先写好的程序一次性烧录到硬件里面，之后就不能再修改了。</li>
</ul>


<p>ASIC（Application-Specific Integrated Circuit），也就是专用集成电路。比如，现在手机里就有专门用在摄像头里的芯片；录音笔里会有专门处理音频的芯片，都是ASIC。</p>

<p>那么，我们能不能用刚才说的FPGA来做ASIC的事情呢？当然是可以的。我们对FPGA进行“编程”，其实就是把FPGA的电路变成了一个ASIC。这样的芯片，往往在成本和功耗上优于需要做通用计算的CPU和GPU。但是，FPGA一样有缺点，那就是它的硬件上有点儿“浪费”。为了实现通用性，FPGA有很多荣誉的硬件。</p>

<h2>HDD和SSD</h2>

<p>硬盘接口：</p>

<ul>
<li>SATA3.0：带宽6Gb/s，理论传输上线768MB/s。</li>
<li>PCI Express接口</li>
</ul>


<p>PCI Express接口上的SSD硬盘性能测试：</p>

<p><img src="http://hongchaozhang.github.io/images/SSD%E6%80%A7%E8%83%BD.png" alt="SSD性能.png" /></p>

<ul>
<li>Seq：顺序读写数据可以达到1GB-2GB/s。</li>
<li>4K：4K大小的随机读写速度只有每秒几十MB，可以算出该硬盘每秒随机读取次数可以达到1万次左右（40M/4K），随机写入可以达到每秒2万次左右。这个每秒读写的次数，我们称之为IOPS。相比较而言，HDD硬盘的IOPS通常也就在100左右（可以通过机械硬盘的转速计算出来。）。</li>
<li>Acc.time</li>
</ul>


<p>无论是顺序读写还是随机读写，SSD都远胜于HDD。但是在使用寿命上，SSD却非常差，这是受它的擦除次数限制。</p>

<p>对于SSD硬盘来说，数据的写入叫作Program。写入不能像机械硬盘一样，通过覆写（Overwrite）来进行的，而是要先去擦除（Erase），然后再写入。</p>

<p>SSD的读取和写入的基本单位，不是一个比特（bit）或者一个字节（byte），而是一个页（Page）。SSD 的擦除单位就更夸张了，我们不仅不能按照比特或者字节来擦除，连按照页来擦除都不行，我们必须按照块来擦除。对SSD来说，最好的存储介质也只有十万次的擦出次数，差一些的只有几千次。</p>

<h3>FTL闪存转换层</h3>

<p>为了提高SSD的使用寿命，我们要的就是想一个办法，让SSD硬盘各个块的擦除次数，均匀分摊到各个块上。这个策略呢，就叫作<strong>磨损均衡</strong>（Wear-Leveling）。实现这个技术的核心办法，和我们前面讲过的虚拟内存一样，就是添加一个间接层，就是FTL这个<strong>闪存转换层</strong>。</p>

<p><img src="http://hongchaozhang.github.io/images/%E9%97%AA%E5%AD%98%E8%BD%AC%E6%8D%A2%E5%B1%82.jpeg" alt="闪存转换层.jpeg" /></p>

<p>当SSD硬盘的存储空间被占用得越来越多，每一次写入新数据，我们都可能没有足够的空白。我们可能不得不去进行垃圾回收，合并一些块里面的页，然后再擦除掉一些页，才能匀出一些空间来。</p>

<p>这个时候，从应用层或者操作系统层面来看，我们可能只是写入了一个4KB或者4MB的数据。但是，实际通过FTL之后，我们可能要去搬运8MB、16MB甚至更多的数据。</p>

<p>我们通过“实际的闪存写入的数据量/系统通过FTL写入的数据量”定义写入放大。可以得到，写入放大的倍数越多，意味着实际的SSD性能也就越差，会远远比不上实际SSD硬盘标称的指标。而解决写入放大的方法：</p>

<ul>
<li>需要我们在后台定时进行垃圾回收，在硬盘比较空闲的时候，就把搬运数据、擦除数据、留出空白的块的工作做完，而不是等实际数据写入的时候，再进行这样的操作。AeroSpike在某个“块”有超过50%的数据碎片时就进行垃圾回收。</li>
<li>不要存储的太满。AeroSpike数据库建议预留50%的空间。</li>
</ul>


<h2>直接内存访问（DMA）</h2>

<p>无论I/O速度如何提升，比起CPU，总还是太慢。SSD硬盘的IOPS可以到2万、4万，但是我们CPU的主频有2GHz以上，也就意味着每秒会有20亿次的操作。</p>

<p>如果我们对于I/O的操作，都是由CPU发出对应的指令，然后等待I/O设备完成操作之后返回，那CPU有大量的时间其实都是在等待I/O设备完成操作。</p>

<p>因此，计算机工程师们，就发明了DMA技术，也就是直接内存访问（Direct Memory Access）技术，来减少CPU等待的时间。</p>

<p>本质上，DMA技术就是我们在主板上放一块独立的芯片。在进行内存和I/O设备的数据传输的时候，我们不再通过CPU来控制数据传输，而直接通过DMA控制器（DMA Controller，简称DMAC）。这块芯片，我们可以认为它其实就是一个协处理器（Co-Processor）。</p>

<p>比如说，我们用千兆网卡或者硬盘传输大量数据的时候，如果都用CPU来搬运的话，肯定忙不过来，所以可以选择DMAC。而当数据传输很慢的时候，DMAC可以等数据到齐了，再发送信号，给到CPU去处理，而不是让CPU在那里忙等待。</p>

<p>今天，各种I/O设备越来越多，数据传输的需求越来越复杂，使用的场景各不相同。加之显示器、网卡、硬盘对于数据传输的需求都不一样，所以各个设备里面都有自己的DMAC芯片了。</p>

<h3>为什么那么快？一起来看Kafka的实现原理</h3>

<p>Kafka是一个用来处理实时数据的管道，我们常常用它来做一个消息队列，或者用来收集和落地海量的日志。作为一个处理实时数据和日志的管道，瓶颈自然也在I/O层面。</p>

<p>Kafka里面会有两种常见的海量数据传输的情况。一种是从网络中接收上游的数据，然后需要落地到本地的磁盘上，确保数据不丢失。另一种情况呢，则是从本地磁盘上读取出来，通过网络发送出去。</p>

<p>Kafka做的事情就是，把这个数据搬运的次数，从上面的四次，变成了两次，并且只有DMA来进行数据搬运，而不需要CPU。</p>

<h2>校验</h2>

<ul>
<li>奇偶校验和校验位</li>
<li>纠错码</li>
<li>纠删码</li>
</ul>


<p>7-4海明码是海明吗的一种：这里的“7”指的是实际有效的数据，一共是7位（Bit）。而这里的“4”，指的是我们额外存储了4位数据，用来纠错。</p>
]]></content>
  </entry>
  
</feed>
